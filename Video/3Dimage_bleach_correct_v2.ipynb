{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b01309ac",
   "metadata": {},
   "source": [
    "GPU-based computation of global statistics (e.g., mean intensity across all pixels).\n",
    "Please update the h5_path accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56b05b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# GPUå¯ç”¨æ€§ãƒã‚§ãƒƒã‚¯\n",
    "try:\n",
    "    import cupy as cp\n",
    "    GPU_AVAILABLE = True\n",
    "    print(\"ğŸš€ GPUå‡¦ç†ãŒåˆ©ç”¨å¯èƒ½ã§ã™\")\n",
    "    \n",
    "    # GPUæƒ…å ±è¡¨ç¤º\n",
    "    gpu_props = cp.cuda.runtime.getDeviceProperties(0)\n",
    "    gpu_name = gpu_props['name'].decode('utf-8')\n",
    "    total_memory_gb = cp.cuda.Device().mem_info[1] / (1024**3)\n",
    "    print(f\"ğŸ® GPU: {gpu_name}, VRAM: {total_memory_gb:.1f}GB\")\n",
    "    \n",
    "except ImportError:\n",
    "    GPU_AVAILABLE = False\n",
    "    print(\"âš ï¸ CPUå‡¦ç†ã‚’ä½¿ç”¨ã—ã¾ã™\")\n",
    "\n",
    "# === ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ ===\n",
    "h5_path = r\"I:\\20240508-174849tdTomato-12mW-3_raw_gzip\\20240508-174849tdTomato-12mW-3_raw_gzip.h5\"\n",
    "dataset_name = \"/default\"\n",
    "output_csv = os.path.splitext(h5_path)[0] + \"_top90_mean.csv\"\n",
    "\n",
    "# é«˜é€ŸåŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
    "offset_value = 100\n",
    "exclude_value = -100\n",
    "chunk_size = 50 if GPU_AVAILABLE else 25  # GPUä½¿ç”¨æ™‚ã¯ã‚ˆã‚Šå¤§ããªãƒãƒ£ãƒ³ã‚¯\n",
    "\n",
    "def process_volume_gpu(vol_chunk, c, offset_value, exclude_value):\n",
    "    \"\"\"GPUç”¨ã®ãƒœãƒªãƒ¥ãƒ¼ãƒ çµ±è¨ˆå‡¦ç†\"\"\"\n",
    "    try:\n",
    "        # GPUã«è»¢é€\n",
    "        vol_gpu = cp.asarray(vol_chunk, dtype=cp.float32)\n",
    "        vol_gpu -= offset_value\n",
    "        \n",
    "        # å„çµ±è¨ˆã®è¨ˆç®—\n",
    "        stats = {}\n",
    "        \n",
    "        # -100é™¤å¤–çµ±è¨ˆ\n",
    "        valid_mask = vol_gpu != exclude_value\n",
    "        valid_vals = vol_gpu[valid_mask]\n",
    "        \n",
    "        # if len(valid_vals) > 0:\n",
    "        #     stats['sum'] = float(cp.sum(valid_vals))\n",
    "        #     stats['mean'] = float(cp.mean(valid_vals))\n",
    "        # else:\n",
    "        #     stats['sum'] = 0.0\n",
    "        #     stats['mean'] = 0.0\n",
    "        \n",
    "        # # æ­£ã®å€¤ã®ã¿ã®çµ±è¨ˆ\n",
    "        # pos_mask = vol_gpu > 0\n",
    "        # pos_vals = vol_gpu[pos_mask]\n",
    "        \n",
    "        # if len(pos_vals) > 0:\n",
    "        #     stats['possum'] = float(cp.sum(pos_vals))\n",
    "        #     stats['posmean'] = float(cp.mean(pos_vals))\n",
    "        # else:\n",
    "        #     stats['possum'] = 0.0\n",
    "        #     stats['posmean'] = 0.0\n",
    "        \n",
    "        # # ãƒãƒ£ãƒ³ãƒãƒ«åˆ¥é–¾å€¤çµ±è¨ˆ\n",
    "        # if c == 0:\n",
    "        #     thresh_mask = vol_gpu > 10\n",
    "        #     thresh_vals = vol_gpu[thresh_mask]\n",
    "        #     stats['posmean_gcamp5_td10'] = float(cp.mean(thresh_vals)) if len(thresh_vals) > 0 else 0.0\n",
    "        # elif c == 1:\n",
    "        #     thresh_mask = vol_gpu > 5\n",
    "        #     thresh_vals = vol_gpu[thresh_mask]\n",
    "        #     stats['posmean_gcamp5_td10'] = float(cp.mean(thresh_vals)) if len(thresh_vals) > 0 else 0.0\n",
    "        # else:\n",
    "        #     stats['posmean_gcamp5_td10'] = 0.0\n",
    "        \n",
    "        # ä¸Šä½10%, 50%, 90%ã®å¹³å‡å€¤\n",
    "        # percentiles = [90, 50, 10]\n",
    "        percentiles = [90]\n",
    "        for p in percentiles:\n",
    "            if len(valid_vals) > 0:\n",
    "                thresh = cp.percentile(valid_vals, p)\n",
    "                top_vals = valid_vals[valid_vals >= thresh]\n",
    "                stats[f'top{p}_mean'] = float(cp.mean(top_vals)) if len(top_vals) > 0 else 0.0\n",
    "            else:\n",
    "                stats[f'top{p}_mean'] = 0.0\n",
    "        \n",
    "        \n",
    "        # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—\n",
    "        del vol_gpu, valid_vals, top_vals, thresh\n",
    "        if 'thresh_vals' in locals():\n",
    "            del thresh_vals\n",
    "        \n",
    "        return stats\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ GPUå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "        # CPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯\n",
    "        return process_volume_cpu(vol_chunk, c, offset_value, exclude_value)\n",
    "\n",
    "def process_volume_cpu(vol_chunk, c, offset_value, exclude_value):\n",
    "    \"\"\"CPUç”¨ã®ãƒœãƒªãƒ¥ãƒ¼ãƒ çµ±è¨ˆå‡¦ç†ï¼ˆãƒ™ã‚¯ãƒˆãƒ«åŒ–æœ€é©åŒ–ï¼‰\"\"\"\n",
    "    vol = vol_chunk.astype(np.float32)\n",
    "    vol -= offset_value\n",
    "    \n",
    "    stats = {}\n",
    "    \n",
    "    # -100é™¤å¤–çµ±è¨ˆï¼ˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼‰\n",
    "    valid_mask = vol != exclude_value\n",
    "    if np.any(valid_mask):\n",
    "        valid_vals = vol[valid_mask]\n",
    "        stats['sum'] = float(np.sum(valid_vals))\n",
    "        stats['mean'] = float(np.mean(valid_vals))\n",
    "    else:\n",
    "        stats['sum'] = 0.0\n",
    "        stats['mean'] = 0.0\n",
    "    \n",
    "    # æ­£ã®å€¤ã®ã¿ã®çµ±è¨ˆï¼ˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼‰\n",
    "    pos_mask = vol > 0\n",
    "    if np.any(pos_mask):\n",
    "        pos_vals = vol[pos_mask]\n",
    "        stats['possum'] = float(np.sum(pos_vals))\n",
    "        stats['posmean'] = float(np.mean(pos_vals))\n",
    "    else:\n",
    "        stats['possum'] = 0.0\n",
    "        stats['posmean'] = 0.0\n",
    "    \n",
    "    # ãƒãƒ£ãƒ³ãƒãƒ«åˆ¥é–¾å€¤çµ±è¨ˆ\n",
    "    if c == 0:\n",
    "        thresh_mask = vol > 10\n",
    "        stats['posmean_gcamp5_td10'] = float(np.mean(vol[thresh_mask])) if np.any(thresh_mask) else 0.0\n",
    "    elif c == 1:\n",
    "        thresh_mask = vol > 5\n",
    "        stats['posmean_gcamp5_td10'] = float(np.mean(vol[thresh_mask])) if np.any(thresh_mask) else 0.0\n",
    "    else:\n",
    "        stats['posmean_gcamp5_td10'] = 0.0\n",
    "    \n",
    "    return stats\n",
    "\n",
    "def process_statistics_optimized():\n",
    "    \"\"\"æœ€é©åŒ–ã•ã‚ŒãŸçµ±è¨ˆå‡¦ç†ï¼ˆãƒãƒ£ãƒ³ã‚¯+GPU/CPUï¼‰\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    with h5py.File(h5_path, \"r\") as f:\n",
    "        dset = f[dataset_name]\n",
    "        t_len, c_len, z_len, y_len, x_len = dset.shape\n",
    "        print(f\"ğŸ“ Dataset shape: {dset.shape}\")\n",
    "        print(f\"ğŸš€ å‡¦ç†ãƒ¢ãƒ¼ãƒ‰: {'GPU' if GPU_AVAILABLE else 'CPU'}\")\n",
    "        print(f\"ğŸ“¦ ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º: {chunk_size}\")\n",
    "        \n",
    "        # çµæœè¾æ›¸ã®åˆæœŸåŒ–\n",
    "        result = {\"frame\": list(range(t_len))}\n",
    "        for c in range(c_len):\n",
    "            # result[f\"ch{c}_sum\"] = []\n",
    "            # result[f\"ch{c}_mean\"] = []\n",
    "            # result[f\"ch{c}_possum\"] = []\n",
    "            # result[f\"ch{c}_posmean\"] = []\n",
    "            # result[f\"ch{c}_posmean_gcamp5_td10\"] = []\n",
    "            result[f\"ch{c}_top90_mean\"] = []\n",
    "            # result[f\"ch{c}_top50_mean\"] = []\n",
    "            # result[f\"ch{c}_top10_mean\"] = []\n",
    "        \n",
    "        # ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ã§ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–\n",
    "        for t_start in tqdm(range(0, t_len, chunk_size), desc=\"ğŸ¯ çµ±è¨ˆè¨ˆç®—å‡¦ç†\"):\n",
    "            t_end = min(t_start + chunk_size, t_len)\n",
    "            \n",
    "            # è¤‡æ•°ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä¸€æ‹¬èª­ã¿è¾¼ã¿\n",
    "            chunk_data = dset[t_start:t_end]  # shape: (chunk_size, c, z, y, x)\n",
    "            \n",
    "            for i, t in enumerate(range(t_start, t_end)):\n",
    "                for c in range(c_len):\n",
    "                    vol_chunk = chunk_data[i, c]  # shape: (z, y, x)\n",
    "                    \n",
    "                    # GPU/CPUå‡¦ç†ã®é¸æŠ\n",
    "                    if GPU_AVAILABLE:\n",
    "                        stats = process_volume_gpu(vol_chunk, c, offset_value, exclude_value)\n",
    "                    else:\n",
    "                        stats = process_volume_cpu(vol_chunk, c, offset_value, exclude_value)\n",
    "                    \n",
    "                    # çµæœã®è“„ç©\n",
    "                    # result[f\"ch{c}_sum\"].append(stats['sum'])\n",
    "                    # result[f\"ch{c}_mean\"].append(stats['mean'])\n",
    "                    # result[f\"ch{c}_possum\"].append(stats['possum'])\n",
    "                    # result[f\"ch{c}_posmean\"].append(stats['posmean'])\n",
    "                    # result[f\"ch{c}_posmean_gcamp5_td10\"].append(stats['posmean_gcamp5_td10'])\n",
    "                    result[f\"ch{c}_top90_mean\"].append(stats['top90_mean'])\n",
    "                    # result[f\"ch{c}_top50_mean\"].append(stats['top50_mean'])\n",
    "                    # result[f\"ch{c}_top10_mean\"].append(stats['top10_mean'])\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "            \n",
    "            # é€²æ—æƒ…å ±è¡¨ç¤º\n",
    "            if t_start % (chunk_size * 10) == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                processed = t_end\n",
    "                fps = processed / elapsed if elapsed > 0 else 0\n",
    "                remaining = t_len - processed\n",
    "                eta_minutes = (remaining / fps / 60) if fps > 0 else 0\n",
    "                \n",
    "                print(f\"  ğŸ“Š é€²æ—: {processed}/{t_len} ({100*processed/t_len:.1f}%)\")\n",
    "                print(f\"  ğŸš€ é€Ÿåº¦: {fps:.1f}ãƒ•ãƒ¬ãƒ¼ãƒ /ç§’, ETA: {eta_minutes:.1f}åˆ†\")\n",
    "            \n",
    "            # GPUãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—\n",
    "            if GPU_AVAILABLE:\n",
    "                try:\n",
    "                    cp.get_default_memory_pool().free_all_blocks()\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    # å‡¦ç†çµæœã‚µãƒãƒªãƒ¼\n",
    "    total_elapsed = time.time() - start_time\n",
    "    average_fps = t_len / total_elapsed if total_elapsed > 0 else 0\n",
    "    \n",
    "    print(f\"\\nğŸ‰ çµ±è¨ˆè¨ˆç®—å®Œäº†!\")\n",
    "    print(f\"ğŸ“Š å‡¦ç†ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {t_len}\")\n",
    "    print(f\"ğŸ”„ å‡¦ç†ãƒãƒ£ãƒ³ãƒãƒ«æ•°: {c_len}\")\n",
    "    print(f\"â±ï¸ ç·å‡¦ç†æ™‚é–“: {total_elapsed:.1f}ç§’ ({total_elapsed/60:.1f}åˆ†)\")\n",
    "    print(f\"ğŸš€ å¹³å‡å‡¦ç†é€Ÿåº¦: {average_fps:.1f}ãƒ•ãƒ¬ãƒ¼ãƒ /ç§’\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# === æœ€é©åŒ–å‡¦ç†å®Ÿè¡Œ ===\n",
    "print(\"ğŸ¯ æœ€é©åŒ–ã•ã‚ŒãŸçµ±è¨ˆè¨ˆç®—ã‚’é–‹å§‹...\")\n",
    "result = process_statistics_optimized()\n",
    "\n",
    "# === ä¿å­˜å‡¦ç† ===\n",
    "print(\"ğŸ’¾ CSVä¿å­˜ä¸­...\")\n",
    "df = pd.DataFrame(result)\n",
    "\n",
    "try:\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"âœ… æœ€é©åŒ–çµ±è¨ˆå‡¦ç†å®Œäº†: {output_csv}\")\n",
    "    print(f\"ğŸ“ˆ å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {df.shape}\")\n",
    "    \n",
    "    # ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º\n",
    "    print(\"\\nğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«:\")\n",
    "    print(df.head())\n",
    "    \n",
    "except PermissionError:\n",
    "    print(\"âŒ æ›¸ãè¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ«ãŒé–‹ã‹ã‚Œã¦ã„ã‚‹ã‹ã€æ›¸ãè¾¼ã¿æ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“:\")\n",
    "    print(\"ğŸ”’ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‰ã˜ã¦ã„ã‚‹ã‹ã€åˆ¥ã®ä¿å­˜å…ˆã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚\")\n",
    "    print(\"ğŸ“„ è©¦è¡Œã—ãŸå‡ºåŠ›å…ˆ:\", output_csv)\n",
    "    \n",
    "    # ä»£æ›¿ä¿å­˜å…ˆã®ææ¡ˆ\n",
    "    alternative_path = output_csv.replace(\".csv\", f\"_backup_{int(time.time())}.csv\")\n",
    "    try:\n",
    "        df.to_csv(alternative_path, index=False)\n",
    "        print(f\"âœ… ä»£æ›¿ãƒ‘ã‚¹ã«ä¿å­˜å®Œäº†: {alternative_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ä»£æ›¿ä¿å­˜ã‚‚å¤±æ•—: {e}\")\n",
    "\n",
    "# === ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ— ===\n",
    "try:\n",
    "    del result, df\n",
    "    if GPU_AVAILABLE:\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "    print(\"ğŸ§¹ ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4deff41",
   "metadata": {},
   "source": [
    "Accelerated fading correction processing (GPU parallel processing) with support for 2 channels. Please modify csv_path, h5_input_path, and h5_output_path as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f6a4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import time\n",
    "import cupy as cp\n",
    "from scipy.signal import savgol_filter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ ===\n",
    "calc_method = \"_top90_mean\"  # ä½¿ç”¨ã™ã‚‹åˆ—ã®ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆtop50_mean, top90_meanãªã©ï¼‰\n",
    "csv_path = r\"I:\\20240508-174849tdTomato-12mW-3_raw_gzip\\20240508-174849tdTomato-12mW-3_raw_gzip_top90_mean.csv\"\n",
    "h5_input_path = r\"I:\\20240508-174849tdTomato-12mW-3_raw_gzip\\20240508-174849tdTomato-12mW-3_raw_gzip.h5\"\n",
    "h5_output_path = fr\"I:\\20240508-174849tdTomato-12mW-3_raw_gzip\\20240508-174849tdTomato-12mW-3_raw_gzip_bleachcorrect_{calc_method}.h5\"\n",
    "offset_value = 100\n",
    "scale_margin = 1.2\n",
    "chunk_size = 60  # ãƒ¡ãƒ¢ãƒªãƒ¼ã‚µã‚¤ã‚ºã«å¿œã˜ã¦è¨­å®š\n",
    "\n",
    "# === è¤ªè‰²é–¢æ•°å®šç¾© ===\n",
    "def double_exp(t, a, b, c, d):\n",
    "    return a * np.exp(-b * t) + c * np.exp(-d * t)\n",
    "\n",
    "# === ãƒãƒ£ãƒ³ãƒãƒ«åˆ¥è¤ªè‰²ã‚«ãƒ¼ãƒ–æ¨å®š ===\n",
    "def estimate_bleach_curves():\n",
    "    \"\"\"å„ãƒãƒ£ãƒ³ãƒãƒ«ã®è¤ªè‰²ã‚«ãƒ¼ãƒ–ã‚’ç‹¬ç«‹ã—ã¦æ¨å®š\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    t = np.arange(len(df))\n",
    "    \n",
    "    \n",
    "    bleach_params = {}\n",
    "    scale_factors = {}\n",
    "    \n",
    "    # ãƒãƒ£ãƒ³ãƒãƒ«æ•°ã®è‡ªå‹•æ¤œå‡º\n",
    "    mean_columns = [col for col in df.columns if col.endswith(calc_method)]\n",
    "    channel_numbers = [int(col.split('_')[0][2:]) for col in mean_columns if col.startswith('ch')]\n",
    "    \n",
    "    print(f\"ğŸ” æ¤œå‡ºã•ã‚ŒãŸãƒãƒ£ãƒ³ãƒãƒ«: {channel_numbers}\")\n",
    "    \n",
    "    for ch_num in channel_numbers:\n",
    "        column_name = f\"ch{ch_num}{calc_method}\"\n",
    "        \n",
    "        if column_name not in df.columns:\n",
    "            print(f\"âš ï¸ åˆ— '{column_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n--- Channel {ch_num} è¤ªè‰²ã‚«ãƒ¼ãƒ–æ¨å®š ---\")\n",
    "        \n",
    "        y_raw = df[column_name].to_numpy()\n",
    "        # SGãƒ•ã‚£ãƒ«ã‚¿é©ç”¨ï¼ˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º13, å¤šé …å¼æ¬¡æ•°1ï¼‰\n",
    "        y_smooth = savgol_filter(y_raw, window_length=13, polyorder=1, mode='interp')\n",
    "        \n",
    "        # åˆæœŸå€¤ã¨ä¸Šé™ã®æ¨å®š\n",
    "        a0 = c0 = y_smooth[0] / 2\n",
    "        p0 = [a0, 0.01, c0, 0.001]\n",
    "        y_max = np.nanmax(y_smooth)\n",
    "        upper_limit = y_max * scale_margin\n",
    "        bounds = ([0, 0, 0, 0], [upper_limit, 1, upper_limit, 1])\n",
    "        \n",
    "        try:\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                popt, _ = curve_fit(double_exp, t, y_smooth, p0=p0, bounds=bounds, maxfev=10000)\n",
    "            \n",
    "            fitted = double_exp(t, *popt)\n",
    "            scale = double_exp(0, *popt) / fitted  # t=0ã§æ­£è¦åŒ–\n",
    "            \n",
    "            bleach_params[ch_num] = popt\n",
    "            scale_factors[ch_num] = scale\n",
    "      \n",
    "\n",
    "            # æ¨ªä¸¦ã³ã§å…¨ãƒãƒ£ãƒ³ãƒãƒ«åˆ†ã®ãƒ—ãƒ­ãƒƒãƒˆã‚’ä½œæˆãƒ»ä¿å­˜\n",
    "            fig, axes = plt.subplots(1, len(channel_numbers), figsize=(6 * len(channel_numbers), 4), sharey=True)\n",
    "            if len(channel_numbers) == 1:\n",
    "                axes = [axes]\n",
    "            for idx, ch in enumerate(channel_numbers):\n",
    "                col_name = f\"ch{ch}{calc_method}\"\n",
    "                y = df[col_name].to_numpy()\n",
    "                if ch in bleach_params:\n",
    "                    fit = double_exp(t, *bleach_params[ch])\n",
    "                    # è¤ªè‰²è£œæ­£å¾Œãƒ‡ãƒ¼ã‚¿\n",
    "                    corrected = y * scale_factors[ch]\n",
    "                else:\n",
    "                    fit = np.ones_like(t) * y[0]\n",
    "                    corrected = y\n",
    "                axes[idx].plot(t, y, 'o', label=f'Ch{ch} Raw')\n",
    "                axes[idx].plot(t, fit, '-', label=f'Ch{ch} Fit')\n",
    "                axes[idx].plot(t, corrected, '--', label=f'Ch{ch} Corrected')\n",
    "                axes[idx].set_title(f'Channel {ch} Bleach Curve')\n",
    "                axes[idx].set_xlabel('Time')\n",
    "                axes[idx].legend()\n",
    "            axes[0].set_ylabel('Intensity')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'bleach_curve_all_channels{calc_method}.png')\n",
    "            plt.show()\n",
    "            \n",
    "            print(f\"âœ… Ch{ch_num} ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°å®Œäº†: a={popt[0]:.2f}, b={popt[1]:.4f}, c={popt[2]:.2f}, d={popt[3]:.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Ch{ch_num} ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°å¤±æ•—: {e}\")\n",
    "            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚¹ã‚±ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼=1ï¼ˆè£œæ­£ãªã—ï¼‰\n",
    "            scale_factors[ch_num] = np.ones_like(t)\n",
    "    \n",
    "    return scale_factors\n",
    "\n",
    "# è¤ªè‰²ã‚«ãƒ¼ãƒ–æ¨å®šå®Ÿè¡Œ\n",
    "scale_factors_all = estimate_bleach_curves()\n",
    "print(\"\\nâœ… å…¨ãƒãƒ£ãƒ³ãƒãƒ«ã®è¤ªè‰²ã‚«ãƒ¼ãƒ–æ¨å®šå®Œäº†\")\n",
    "\n",
    "# GPUç‰ˆï¼ˆãƒãƒ£ãƒ³ãƒãƒ«åˆ¥è£œæ­£å¯¾å¿œï¼‰\n",
    "try:\n",
    "    GPU_AVAILABLE = True\n",
    "    print(\"ğŸš€ GPUå‡¦ç†ãŒåˆ©ç”¨å¯èƒ½ã§ã™\")\n",
    "    \n",
    "    # GPUæƒ…å ±è¡¨ç¤º\n",
    "    gpu_props = cp.cuda.runtime.getDeviceProperties(0)\n",
    "    gpu_name = gpu_props['name'].decode('utf-8')\n",
    "    total_memory_gb = cp.cuda.Device().mem_info[1] / (1024**3)\n",
    "    print(f\"ğŸ® GPU: {gpu_name}\")\n",
    "    print(f\"ğŸ’¾ VRAM: {total_memory_gb:.1f}GB\")\n",
    "    \n",
    "except ImportError:\n",
    "    GPU_AVAILABLE = False\n",
    "    print(\"âš ï¸ CuPyãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚CPUå‡¦ç†ã‚’ä½¿ç”¨ã—ã¾ã™\")\n",
    "\n",
    "def process_with_gpu_multichannel():\n",
    "    \"\"\"ãƒãƒ£ãƒ³ãƒãƒ«åˆ¥è¤ªè‰²è£œæ­£GPUå‡¦ç†ï¼ˆå…¨ãƒœãƒªãƒ¥ãƒ¼ãƒ å¯¾å¿œï¼‰\"\"\"\n",
    "    if not GPU_AVAILABLE:\n",
    "        print(\"âŒ GPUå‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™\")\n",
    "        return\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    with h5py.File(h5_input_path, \"r\") as f_in, h5py.File(h5_output_path, \"w\") as f_out:\n",
    "        dset_in = f_in[\"/default\"]\n",
    "        T_full, C, Z, Y, X = dset_in.shape\n",
    "        \n",
    "        print(f\"ğŸ“ ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (T={T_full}, C={C}, Z={Z}, Y={Y}, X={X})\")\n",
    "        print(f\"ğŸ¯ å‡¦ç†å¯¾è±¡: å…¨ãƒœãƒªãƒ¥ãƒ¼ãƒ ï¼ˆ{T_full}ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰\")\n",
    "        \n",
    "        # å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆï¼ˆå…¨ãƒœãƒªãƒ¥ãƒ¼ãƒ ï¼‰\n",
    "        dset_out = f_out.create_dataset(\n",
    "            \"/default\", \n",
    "            shape=(T_full, C, Z, Y, X),\n",
    "            dtype='uint16',\n",
    "            chunks=(min(chunk_size//4, 20), 1, Z, Y, X),\n",
    "            compression=\"gzip\",\n",
    "            compression_opts=1\n",
    "        )\n",
    "        \n",
    "        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¿½åŠ \n",
    "        dset_out.attrs['processing_mode'] = 'multichannel_bleach_correction_full'\n",
    "        dset_out.attrs['chunk_size'] = chunk_size\n",
    "        dset_out.attrs['offset_value'] = offset_value\n",
    "        dset_out.attrs['processed_frames'] = T_full\n",
    "        dset_out.attrs['frame_range'] = f\"0-{T_full-1}\"\n",
    "        \n",
    "        # ãƒãƒ£ãƒ³ãƒãƒ«åˆ¥ã‚¹ã‚±ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ã®æº–å‚™\n",
    "        scale_factors_gpu = {}\n",
    "        for ch_num in range(C):\n",
    "            if ch_num in scale_factors_all:\n",
    "                # å…¨ãƒ•ãƒ¬ãƒ¼ãƒ åˆ†ã‚’å–å¾—\n",
    "                scale_factors_gpu[ch_num] = cp.asarray(\n",
    "                    scale_factors_all[ch_num], dtype=cp.float32\n",
    "                )\n",
    "                print(f\"âœ… Ch{ch_num}: GPUç”¨ã‚¹ã‚±ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼æº–å‚™å®Œäº†ï¼ˆ{T_full}ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰\")\n",
    "            else:\n",
    "                scale_factors_gpu[ch_num] = cp.ones(T_full, dtype=cp.float32)\n",
    "                print(f\"âš ï¸ Ch{ch_num}: ã‚¹ã‚±ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ãªã—ï¼ˆè£œæ­£ã‚¹ã‚­ãƒƒãƒ—ï¼‰\")\n",
    "        \n",
    "        # ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—ï¼ˆå…¨ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰\n",
    "        for t_start in tqdm(range(0, T_full, chunk_size), desc=\"ğŸ® GPUå¤šãƒãƒ£ãƒ³ãƒãƒ«è¤ªè‰²è£œæ­£ï¼ˆå…¨ãƒœãƒªãƒ¥ãƒ¼ãƒ ï¼‰\"):\n",
    "            t_end = min(t_start + chunk_size, T_full)\n",
    "            current_chunk_size = t_end - t_start\n",
    "            \n",
    "            try:\n",
    "                # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç›£è¦–\n",
    "                memory_before = cp.cuda.Device().mem_info[0] / (1024**3)\n",
    "                \n",
    "                # ãƒãƒ£ãƒ³ãƒãƒ«åˆ¥å‡¦ç†\n",
    "                for c in range(C):\n",
    "                    # CPUã‹ã‚‰GPUã¸ãƒ‡ãƒ¼ã‚¿è»¢é€\n",
    "                    vol_chunk = cp.asarray(\n",
    "                        dset_in[t_start:t_end, c, :, :, :], \n",
    "                        dtype=cp.float32\n",
    "                    )\n",
    "                    \n",
    "                    # ãƒãƒ£ãƒ³ãƒãƒ«å°‚ç”¨ã‚¹ã‚±ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼å–å¾—\n",
    "                    scale_chunk = scale_factors_gpu[c][t_start:t_end]\n",
    "                    \n",
    "                    # GPUä¸Šã§ãƒ™ã‚¯ãƒˆãƒ«åŒ–å‡¦ç†\n",
    "                    vol_chunk -= offset_value  # ã‚ªãƒ•ã‚»ãƒƒãƒˆæ¸›ç®—\n",
    "                    vol_chunk *= scale_chunk.reshape(-1, 1, 1, 1)  # ãƒãƒ£ãƒ³ãƒãƒ«åˆ¥è¤ªè‰²è£œæ­£\n",
    "                    vol_chunk = cp.clip(vol_chunk, 0, 65535)  # ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°\n",
    "                    \n",
    "                    # å‹å¤‰æ›ã¨çµæœä¿å­˜\n",
    "                    vol_chunk = vol_chunk.astype(cp.uint16)\n",
    "                    result = cp.asnumpy(vol_chunk)\n",
    "                    dset_out[t_start:t_end, c, :, :, :] = result\n",
    "                    \n",
    "                    # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆãƒãƒ£ãƒ³ãƒãƒ«æ¯ï¼‰\n",
    "                    del vol_chunk, result\n",
    "                    cp.cuda.Stream.null.synchronize()\n",
    "                \n",
    "                # é€²æ—æƒ…å ±è¡¨ç¤º\n",
    "                if t_start % (chunk_size * 5) == 0:\n",
    "                    memory_after = cp.cuda.Device().mem_info[0] / (1024**3)\n",
    "                    elapsed = time.time() - start_time\n",
    "                    processed_frames = t_end\n",
    "                    fps = processed_frames / elapsed if elapsed > 0 else 0\n",
    "                    remaining_frames = T_full - processed_frames\n",
    "                    eta_minutes = (remaining_frames / fps / 60) if fps > 0 else 0\n",
    "                    \n",
    "                    print(f\"  ğŸ“Š é€²æ—: {processed_frames}/{T_full} ({100*processed_frames/T_full:.1f}%)\")\n",
    "                    print(f\"  ğŸš€ é€Ÿåº¦: {fps:.1f}fps, VRAM: {memory_before:.1f}GB, ETA: {eta_minutes:.1f}åˆ†\")\n",
    "                    \n",
    "            except cp.cuda.memory.OutOfMemoryError:\n",
    "                print(f\"ğŸ’¥ GPU ãƒ¡ãƒ¢ãƒªä¸è¶³ (chunk_size={chunk_size})\")\n",
    "                cp.get_default_memory_pool().free_all_blocks()\n",
    "                continue\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ å‡¦ç†ã‚¨ãƒ©ãƒ¼ (t={t_start}-{t_end}): {e}\")\n",
    "                continue\n",
    "    \n",
    "    # æœ€çµ‚ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—\n",
    "    try:\n",
    "        # è¾æ›¸ã®ã‚­ãƒ¼ã®ãƒªã‚¹ãƒˆã‚’äº‹å‰ã«å–å¾—ã—ã¦ã‹ã‚‰ã‚¤ãƒ†ãƒ¬ãƒ¼ãƒˆ\n",
    "        channel_keys = list(scale_factors_gpu.keys())\n",
    "        for ch_num in channel_keys:\n",
    "            if ch_num in scale_factors_gpu:\n",
    "                del scale_factors_gpu[ch_num]\n",
    "        \n",
    "        # GPU ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "        \n",
    "    except Exception as cleanup_error:\n",
    "        print(f\"âš ï¸ ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {cleanup_error}\")\n",
    "        # å¼·åˆ¶çš„ã«ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«ã‚’ã‚¯ãƒªã‚¢\n",
    "        try:\n",
    "            cp.get_default_memory_pool().free_all_blocks()\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # å‡¦ç†çµæœã‚µãƒãƒªãƒ¼\n",
    "    total_elapsed = time.time() - start_time\n",
    "    average_fps = T_full / total_elapsed if total_elapsed > 0 else 0\n",
    "    \n",
    "    print(f\"\\nğŸ‰ å…¨ãƒœãƒªãƒ¥ãƒ¼ãƒ å¤šãƒãƒ£ãƒ³ãƒãƒ«è¤ªè‰²è£œæ­£GPUå‡¦ç†å®Œäº†!\")\n",
    "    print(f\"ğŸ“Š å‡¦ç†ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {T_full}\")\n",
    "    print(f\"ğŸ”„ å‡¦ç†ãƒãƒ£ãƒ³ãƒãƒ«æ•°: {C}\")\n",
    "    print(f\"â±ï¸  ç·å‡¦ç†æ™‚é–“: {total_elapsed/60:.1f}åˆ†\")\n",
    "    print(f\"ğŸš€ å¹³å‡å‡¦ç†é€Ÿåº¦: {average_fps:.1f}ãƒ•ãƒ¬ãƒ¼ãƒ /ç§’\")\n",
    "    print(f\"ğŸ’¾ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {h5_output_path}\")\n",
    "\n",
    "# === å®Ÿè¡Œ ===\n",
    "if GPU_AVAILABLE and scale_factors_all:\n",
    "    print(\"ğŸ¯ ãƒãƒ£ãƒ³ãƒãƒ«åˆ¥è¤ªè‰²è£œæ­£GPUå‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™ï¼ˆå…¨ãƒœãƒªãƒ¥ãƒ¼ãƒ ï¼‰...\")\n",
    "    process_with_gpu_multichannel()\n",
    "else:\n",
    "    print(\"âš ï¸ GPUå‡¦ç†ã¾ãŸã¯ã‚¹ã‚±ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“\")\n",
    "    print(f\"GPUåˆ©ç”¨å¯èƒ½: {GPU_AVAILABLE}\")\n",
    "    print(f\"ã‚¹ã‚±ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼: {list(scale_factors_all.keys()) if scale_factors_all else 'ãªã—'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350fc5e6",
   "metadata": {},
   "source": [
    "Orthogonal View tiff from hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0121c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# GPUå¯ç”¨æ€§ãƒã‚§ãƒƒã‚¯\n",
    "try:\n",
    "    import cupy as cp\n",
    "    GPU_AVAILABLE = True\n",
    "    print(\"ğŸš€ GPUå‡¦ç†ãŒåˆ©ç”¨å¯èƒ½ã§ã™\")\n",
    "    \n",
    "    # GPUæƒ…å ±è¡¨ç¤º\n",
    "    gpu_props = cp.cuda.runtime.getDeviceProperties(0)\n",
    "    gpu_name = gpu_props['name'].decode('utf-8')\n",
    "    total_memory_gb = cp.cuda.Device().mem_info[1] / (1024**3)\n",
    "    print(f\"ğŸ® GPU: {gpu_name}\")\n",
    "    print(f\"ğŸ’¾ VRAM: {total_memory_gb:.1f}GB\")\n",
    "    \n",
    "except ImportError:\n",
    "    GPU_AVAILABLE = False\n",
    "    print(\"âš ï¸ CPUå‡¦ç†ã‚’ä½¿ç”¨ã—ã¾ã™\")\n",
    "\n",
    "# === ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ ===\n",
    "hdf5_file = h5_output_path\n",
    "output_path = r\"I:\\20240508-174849tdTomato-12mW-3_raw_gzip\\bleachcorrect\"\n",
    "dirname = os.path.splitext(os.path.basename(hdf5_file))[0]\n",
    "chunk_size = 100 if GPU_AVAILABLE else 50  # GPUä½¿ç”¨æ™‚ã¯ã‚ˆã‚Šå¤§ããªãƒãƒ£ãƒ³ã‚¯\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "# === HDF5ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±å–å¾— ===\n",
    "with h5py.File(hdf5_file, 'r') as file:\n",
    "    array = file['default']\n",
    "    total_volumes, channels, z, y, x = array.shape\n",
    "    print(f\"ğŸ“ ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (T={total_volumes}, C={channels}, Z={z}, Y={y}, X={x})\")\n",
    "    print(f\"ğŸ¯ å‡¦ç†å¯¾è±¡: å…¨ãƒœãƒªãƒ¥ãƒ¼ãƒ ï¼ˆ{total_volumes}ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰\")\n",
    "\n",
    "# === å‡ºåŠ›é…åˆ—ã®æº–å‚™ï¼ˆå…¨ãƒœãƒªãƒ¥ãƒ¼ãƒ ï¼‰ ===\n",
    "orthogonal_view = np.zeros((total_volumes, channels, y + z + 3, x + z + 3), dtype='uint16')\n",
    "\n",
    "def process_cpu_chunk(chunk_data, t_start, t_end):\n",
    "    \"\"\"CPUå‡¦ç†ç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°\"\"\"\n",
    "    for i, t in enumerate(range(t_start, t_end)):\n",
    "        for c in range(channels):\n",
    "            data = chunk_data[i, c]  # (Z, Y, X)\n",
    "            \n",
    "            # CPUä¸Šã§æœ€å¤§æŠ•å½±\n",
    "            xy_proj = np.max(data, axis=0)  # (Y, X)\n",
    "            yz_proj = np.max(data, axis=2).T  # (Z, Y)\n",
    "            xz_proj = np.max(data, axis=1)  # (Z, X)\n",
    "            \n",
    "            # ç›´äº¤ãƒ“ãƒ¥ãƒ¼ã¸ã®é…ç½®\n",
    "            orthogonal_view[t, c, 0:y, 0:x] = xy_proj\n",
    "            orthogonal_view[t, c, 0:y, x+3:x+z+3] = yz_proj\n",
    "            orthogonal_view[t, c, y+3:y+z+3, 0:x] = xz_proj\n",
    "            orthogonal_view[t, c, y+z+2, x+z+2] = 1000\n",
    "\n",
    "def process_orthogonal_projections():\n",
    "    \"\"\"ç›´äº¤æŠ•å½±å‡¦ç†ï¼ˆCPU/GPUè‡ªå‹•é¸æŠãƒ»å…¨ãƒœãƒªãƒ¥ãƒ¼ãƒ ï¼‰\"\"\"\n",
    "    use_gpu = GPU_AVAILABLE  # ãƒ­ãƒ¼ã‚«ãƒ«å¤‰æ•°ã¨ã—ã¦å‡¦ç†çŠ¶æ…‹ã‚’ç®¡ç†\n",
    "    \n",
    "    with h5py.File(hdf5_file, 'r') as file:\n",
    "        array = file['default']\n",
    "        \n",
    "        for t_start in tqdm(range(0, total_volumes, chunk_size), \n",
    "                           desc=\"ğŸ® GPUç›´äº¤æŠ•å½±ï¼ˆå…¨ãƒœãƒªãƒ¥ãƒ¼ãƒ ï¼‰\" if use_gpu else \"ğŸ–¥ï¸ CPUç›´äº¤æŠ•å½±ï¼ˆå…¨ãƒœãƒªãƒ¥ãƒ¼ãƒ ï¼‰\"):\n",
    "            t_end = min(t_start + chunk_size, total_volumes)\n",
    "            \n",
    "            # ãƒãƒ£ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿\n",
    "            chunk_data = array[t_start:t_end]  # (chunk_size, C, Z, Y, X)\n",
    "            \n",
    "            if use_gpu:\n",
    "                # GPUå‡¦ç†ã‚’è©¦è¡Œ\n",
    "                try:\n",
    "                    chunk_gpu = cp.asarray(chunk_data)\n",
    "                    \n",
    "                    for i, t in enumerate(range(t_start, t_end)):\n",
    "                        for c in range(channels):\n",
    "                            data_gpu = chunk_gpu[i, c]  # (Z, Y, X)\n",
    "                            \n",
    "                            # GPUä¸Šã§æœ€å¤§æŠ•å½±\n",
    "                            xy_proj = cp.max(data_gpu, axis=0)  # (Y, X)\n",
    "                            yz_proj = cp.max(data_gpu, axis=2).T  # (Z, Y)\n",
    "                            xz_proj = cp.max(data_gpu, axis=1)  # (Z, X)\n",
    "                            \n",
    "                            # CPUå´ã«çµæœã‚’ã‚³ãƒ”ãƒ¼\n",
    "                            orthogonal_view[t, c, 0:y, 0:x] = cp.asnumpy(xy_proj)\n",
    "                            orthogonal_view[t, c, 0:y, x+3:x+z+3] = cp.asnumpy(yz_proj)\n",
    "                            orthogonal_view[t, c, y+3:y+z+3, 0:x] = cp.asnumpy(xz_proj)\n",
    "                            orthogonal_view[t, c, y+z+2, x+z+2] = 1000\n",
    "                    \n",
    "                    # GPUãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—\n",
    "                    del chunk_gpu\n",
    "                    cp.get_default_memory_pool().free_all_blocks()\n",
    "                    \n",
    "                    # é€²æ—æƒ…å ±è¡¨ç¤ºï¼ˆGPUå‡¦ç†ï¼‰\n",
    "                    if t_start % (chunk_size * 5) == 0:\n",
    "                        processed = t_end\n",
    "                        remaining = total_volumes - processed\n",
    "                        progress_pct = 100 * processed / total_volumes\n",
    "                        print(f\"  ğŸ“Š GPUé€²æ—: {processed}/{total_volumes} ({progress_pct:.1f}%)\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"âš ï¸ GPUå‡¦ç†ã‚¨ãƒ©ãƒ¼ã€CPUã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: {e}\")\n",
    "                    use_gpu = False  # ä»Šå¾Œã®ãƒãƒ£ãƒ³ã‚¯ã¯CPUå‡¦ç†\n",
    "                    # CPUå‡¦ç†ã§å†è©¦è¡Œ\n",
    "                    process_cpu_chunk(chunk_data, t_start, t_end)\n",
    "                    \n",
    "            else:\n",
    "                # CPUå‡¦ç†\n",
    "                process_cpu_chunk(chunk_data, t_start, t_end)\n",
    "                \n",
    "                # é€²æ—æƒ…å ±è¡¨ç¤ºï¼ˆCPUå‡¦ç†ï¼‰\n",
    "                if t_start % (chunk_size * 2) == 0:\n",
    "                    processed = t_end\n",
    "                    progress_pct = 100 * processed / total_volumes\n",
    "                    print(f\"  ğŸ“Š CPUé€²æ—: {processed}/{total_volumes} ({progress_pct:.1f}%)\")\n",
    "\n",
    "# === å‡¦ç†å®Ÿè¡Œ ===\n",
    "print(f\"ğŸ¯ å…¨ãƒœãƒªãƒ¥ãƒ¼ãƒ ï¼ˆ{total_volumes}ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰ã®ç›´äº¤æŠ•å½±å‡¦ç†ã‚’é–‹å§‹...\")\n",
    "process_orthogonal_projections()\n",
    "print(\"ğŸ‰ ç›´äº¤æŠ•å½±å‡¦ç†å®Œäº†!\")\n",
    "\n",
    "# === TIFFä¿å­˜ï¼ˆå…¨ãƒœãƒªãƒ¥ãƒ¼ãƒ ï¼‰ ===\n",
    "file_name = f\"orthogonal_view_{dirname}_full.tif\"\n",
    "output_path2 = os.path.join(output_path, file_name)\n",
    "\n",
    "print(\"ğŸ’¾ TIFFä¿å­˜ä¸­...\")\n",
    "print(f\"ğŸ“ ä¿å­˜å…ˆ: {output_path2}\")\n",
    "print(f\"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {orthogonal_view.nbytes / (1024**3):.2f}GB\")\n",
    "\n",
    "try:\n",
    "    tiff.imwrite(\n",
    "        output_path2, \n",
    "        orthogonal_view, \n",
    "        imagej=True, \n",
    "        metadata={'axes': 'TCYX'}, \n",
    "        compression='zlib'\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… å…¨ãƒœãƒªãƒ¥ãƒ¼ãƒ å‡¦ç†å®Œäº†: {output_path2}\")\n",
    "    print(f\"ğŸ“ˆ å‡ºåŠ›å½¢çŠ¶: {orthogonal_view.shape}\")\n",
    "    print(f\"ğŸ“Š å‡¦ç†çµ±è¨ˆ: {total_volumes}/{total_volumes}ãƒœãƒªãƒ¥ãƒ¼ãƒ  (100%)\")\n",
    "    \n",
    "except Exception as save_error:\n",
    "    print(f\"âŒ TIFFä¿å­˜ã‚¨ãƒ©ãƒ¼: {save_error}\")\n",
    "    print(\"ğŸ’¡ ãƒ¡ãƒ¢ãƒªä¸è¶³ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ãƒãƒ£ãƒ³ã‚¯ä¿å­˜ã‚’è©¦ã—ã¾ã™...\")\n",
    "    \n",
    "    # === ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒãƒ£ãƒ³ã‚¯ä¿å­˜ ===\n",
    "    save_chunk_size = 500  # 500ãƒ•ãƒ¬ãƒ¼ãƒ ãšã¤ä¿å­˜\n",
    "    \n",
    "    for save_start in tqdm(range(0, total_volumes, save_chunk_size), desc=\"ğŸ“¦ ãƒãƒ£ãƒ³ã‚¯ä¿å­˜\"):\n",
    "        save_end = min(save_start + save_chunk_size, total_volumes)\n",
    "        chunk_name = f\"orthogonal_view_{dirname}_part{save_start:05d}-{save_end:05d}.tif\"\n",
    "        chunk_path = os.path.join(output_path, chunk_name)\n",
    "        \n",
    "        chunk_data = orthogonal_view[save_start:save_end]\n",
    "        tiff.imwrite(\n",
    "            chunk_path,\n",
    "            chunk_data,\n",
    "            imagej=True,\n",
    "            metadata={'axes': 'TCYX'},\n",
    "            compression='zlib'\n",
    "        )\n",
    "        print(f\"âœ… ä¿å­˜å®Œäº†: {chunk_name}\")\n",
    "    \n",
    "    print(f\"ğŸ“¦ ãƒãƒ£ãƒ³ã‚¯ä¿å­˜å®Œäº†: {output_path}\")\n",
    "\n",
    "# === ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ— ===\n",
    "try:\n",
    "    del orthogonal_view\n",
    "    if GPU_AVAILABLE:\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "    print(\"ğŸ§¹ ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8c3702",
   "metadata": {},
   "source": [
    "Bleach correction processing for multiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ea3c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# ä¸Šä½90%å¹³å‡å€¤è¨ˆç®—ã¨ä¿å­˜\n",
    "##############################################################################\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# GPUå¯ç”¨æ€§ãƒã‚§ãƒƒã‚¯\n",
    "try:\n",
    "    import cupy as cp\n",
    "    GPU_AVAILABLE = True\n",
    "    print(\"ğŸš€ GPUå‡¦ç†ãŒåˆ©ç”¨å¯èƒ½ã§ã™\")\n",
    "    \n",
    "    # GPUæƒ…å ±è¡¨ç¤º\n",
    "    gpu_props = cp.cuda.runtime.getDeviceProperties(0)\n",
    "    gpu_name = gpu_props['name'].decode('utf-8')\n",
    "    total_memory_gb = cp.cuda.Device().mem_info[1] / (1024**3)\n",
    "    print(f\"ğŸ® GPU: {gpu_name}, VRAM: {total_memory_gb:.1f}GB\")\n",
    "    \n",
    "except ImportError:\n",
    "    GPU_AVAILABLE = False\n",
    "    print(\"âš ï¸ CPUå‡¦ç†ã‚’ä½¿ç”¨ã—ã¾ã™\")\n",
    "\n",
    "# === ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆè¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œï¼‰ ===\n",
    "h5_files = [\n",
    "    r\"I:\\20240508-174849tdTomato-12mW-3_raw_gzip\\20240508-174849tdTomato-12mW-3_corrected_size_gpu.h5\"\n",
    "]\n",
    "\n",
    "dataset_name = \"/default\"\n",
    "\n",
    "# é«˜é€ŸåŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
    "offset_value = 100\n",
    "exclude_value = -100\n",
    "chunk_size = 50 if GPU_AVAILABLE else 25  # GPUä½¿ç”¨æ™‚ã¯ã‚ˆã‚Šå¤§ããªãƒãƒ£ãƒ³ã‚¯\n",
    "\n",
    "def process_volume_gpu(vol_chunk, c, offset_value, exclude_value):\n",
    "    \"\"\"GPUç”¨ã®ãƒœãƒªãƒ¥ãƒ¼ãƒ çµ±è¨ˆå‡¦ç†\"\"\"\n",
    "    try:\n",
    "        # GPUã«è»¢é€\n",
    "        vol_gpu = cp.asarray(vol_chunk, dtype=cp.float32)\n",
    "        vol_gpu -= offset_value\n",
    "        \n",
    "        # å„çµ±è¨ˆã®è¨ˆç®—\n",
    "        stats = {}\n",
    "        \n",
    "        # -100é™¤å¤–çµ±è¨ˆ\n",
    "        valid_mask = vol_gpu != exclude_value\n",
    "        valid_vals = vol_gpu[valid_mask]\n",
    "        \n",
    "        # ä¸Šä½90%ã®å¹³å‡å€¤\n",
    "        percentiles = [90]\n",
    "        for p in percentiles:\n",
    "            if len(valid_vals) > 0:\n",
    "                thresh = cp.percentile(valid_vals, p)\n",
    "                top_vals = valid_vals[valid_vals >= thresh]\n",
    "                stats[f'top{p}_mean'] = float(cp.mean(top_vals)) if len(top_vals) > 0 else 0.0\n",
    "            else:\n",
    "                stats[f'top{p}_mean'] = 0.0\n",
    "        \n",
    "        # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—\n",
    "        del vol_gpu, valid_vals, top_vals, thresh\n",
    "        \n",
    "        return stats\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ GPUå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "        # CPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯\n",
    "        return process_volume_cpu(vol_chunk, c, offset_value, exclude_value)\n",
    "\n",
    "def process_volume_cpu(vol_chunk, c, offset_value, exclude_value):\n",
    "    \"\"\"CPUç”¨ã®ãƒœãƒªãƒ¥ãƒ¼ãƒ çµ±è¨ˆå‡¦ç†ï¼ˆãƒ™ã‚¯ãƒˆãƒ«åŒ–æœ€é©åŒ–ï¼‰\"\"\"\n",
    "    vol = vol_chunk.astype(np.float32)\n",
    "    vol -= offset_value\n",
    "    \n",
    "    stats = {}\n",
    "    \n",
    "    # -100é™¤å¤–çµ±è¨ˆï¼ˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼‰\n",
    "    valid_mask = vol != exclude_value\n",
    "    if np.any(valid_mask):\n",
    "        valid_vals = vol[valid_mask]\n",
    "        \n",
    "        # ä¸Šä½90%ã®å¹³å‡å€¤\n",
    "        percentiles = [90]\n",
    "        for p in percentiles:\n",
    "            thresh = np.percentile(valid_vals, p)\n",
    "            top_vals = valid_vals[valid_vals >= thresh]\n",
    "            stats[f'top{p}_mean'] = float(np.mean(top_vals)) if len(top_vals) > 0 else 0.0\n",
    "    else:\n",
    "        stats['top90_mean'] = 0.0\n",
    "    \n",
    "    return stats\n",
    "\n",
    "def process_single_file(h5_path):\n",
    "    \"\"\"å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã®çµ±è¨ˆå‡¦ç†\"\"\"\n",
    "    print(f\"\\nğŸ¯ å‡¦ç†é–‹å§‹: {os.path.basename(h5_path)}\")\n",
    "    \n",
    "    output_csv = os.path.splitext(h5_path)[0] + \"_top90_mean.csv\"\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    with h5py.File(h5_path, \"r\") as f:\n",
    "        dset = f[dataset_name]\n",
    "        t_len, c_len, z_len, y_len, x_len = dset.shape\n",
    "        print(f\"ğŸ“ Dataset shape: {dset.shape}\")\n",
    "        print(f\"ğŸš€ å‡¦ç†ãƒ¢ãƒ¼ãƒ‰: {'GPU' if GPU_AVAILABLE else 'CPU'}\")\n",
    "        print(f\"ğŸ“¦ ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º: {chunk_size}\")\n",
    "        \n",
    "        # çµæœè¾æ›¸ã®åˆæœŸåŒ–\n",
    "        result = {\"frame\": list(range(t_len))}\n",
    "        for c in range(c_len):\n",
    "            result[f\"ch{c}_top90_mean\"] = []\n",
    "        \n",
    "        # ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ã§ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–\n",
    "        for t_start in tqdm(range(0, t_len, chunk_size), desc=\"ğŸ¯ çµ±è¨ˆè¨ˆç®—å‡¦ç†\"):\n",
    "            t_end = min(t_start + chunk_size, t_len)\n",
    "            \n",
    "            # è¤‡æ•°ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä¸€æ‹¬èª­ã¿è¾¼ã¿\n",
    "            chunk_data = dset[t_start:t_end]  # shape: (chunk_size, c, z, y, x)\n",
    "            \n",
    "            for i, t in enumerate(range(t_start, t_end)):\n",
    "                for c in range(c_len):\n",
    "                    vol_chunk = chunk_data[i, c]  # shape: (z, y, x)\n",
    "                    \n",
    "                    # GPU/CPUå‡¦ç†ã®é¸æŠ\n",
    "                    if GPU_AVAILABLE:\n",
    "                        stats = process_volume_gpu(vol_chunk, c, offset_value, exclude_value)\n",
    "                    else:\n",
    "                        stats = process_volume_cpu(vol_chunk, c, offset_value, exclude_value)\n",
    "                    \n",
    "                    # çµæœã®è“„ç©\n",
    "                    result[f\"ch{c}_top90_mean\"].append(stats['top90_mean'])\n",
    "            \n",
    "            # é€²æ—æƒ…å ±è¡¨ç¤º\n",
    "            if t_start % (chunk_size * 10) == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                processed = t_end\n",
    "                fps = processed / elapsed if elapsed > 0 else 0\n",
    "                remaining = t_len - processed\n",
    "                eta_minutes = (remaining / fps / 60) if fps > 0 else 0\n",
    "                \n",
    "                print(f\"  ğŸ“Š é€²æ—: {processed}/{t_len} ({100*processed/t_len:.1f}%)\")\n",
    "                print(f\"  ğŸš€ é€Ÿåº¦: {fps:.1f}ãƒ•ãƒ¬ãƒ¼ãƒ /ç§’, ETA: {eta_minutes:.1f}åˆ†\")\n",
    "            \n",
    "            # GPUãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—\n",
    "            if GPU_AVAILABLE:\n",
    "                try:\n",
    "                    cp.get_default_memory_pool().free_all_blocks()\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    # å‡¦ç†çµæœã‚µãƒãƒªãƒ¼\n",
    "    total_elapsed = time.time() - start_time\n",
    "    average_fps = t_len / total_elapsed if total_elapsed > 0 else 0\n",
    "    \n",
    "    print(f\"\\nğŸ‰ çµ±è¨ˆè¨ˆç®—å®Œäº†!\")\n",
    "    print(f\"ğŸ“Š å‡¦ç†ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {t_len}\")\n",
    "    print(f\"ğŸ”„ å‡¦ç†ãƒãƒ£ãƒ³ãƒãƒ«æ•°: {c_len}\")\n",
    "    print(f\"â±ï¸ ç·å‡¦ç†æ™‚é–“: {total_elapsed:.1f}ç§’ ({total_elapsed/60:.1f}åˆ†)\")\n",
    "    print(f\"ğŸš€ å¹³å‡å‡¦ç†é€Ÿåº¦: {average_fps:.1f}ãƒ•ãƒ¬ãƒ¼ãƒ /ç§’\")\n",
    "    \n",
    "    return result, output_csv\n",
    "\n",
    "def save_results(result, output_csv):\n",
    "    \"\"\"çµæœã®ä¿å­˜å‡¦ç†\"\"\"\n",
    "    print(\"ğŸ’¾ CSVä¿å­˜ä¸­...\")\n",
    "    df = pd.DataFrame(result)\n",
    "\n",
    "    try:\n",
    "        df.to_csv(output_csv, index=False)\n",
    "        print(f\"âœ… æœ€é©åŒ–çµ±è¨ˆå‡¦ç†å®Œäº†: {output_csv}\")\n",
    "        print(f\"ğŸ“ˆ å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {df.shape}\")\n",
    "        \n",
    "        # ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º\n",
    "        print(\"\\nğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«:\")\n",
    "        print(df.head())\n",
    "        \n",
    "    except PermissionError:\n",
    "        print(\"âŒ æ›¸ãè¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ«ãŒé–‹ã‹ã‚Œã¦ã„ã‚‹ã‹ã€æ›¸ãè¾¼ã¿æ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“:\")\n",
    "        print(\"ğŸ”’ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‰ã˜ã¦ã„ã‚‹ã‹ã€åˆ¥ã®ä¿å­˜å…ˆã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚\")\n",
    "        print(\"ğŸ“„ è©¦è¡Œã—ãŸå‡ºåŠ›å…ˆ:\", output_csv)\n",
    "        \n",
    "        # ä»£æ›¿ä¿å­˜å…ˆã®ææ¡ˆ\n",
    "        alternative_path = output_csv.replace(\".csv\", f\"_backup_{int(time.time())}.csv\")\n",
    "        try:\n",
    "            df.to_csv(alternative_path, index=False)\n",
    "            print(f\"âœ… ä»£æ›¿ãƒ‘ã‚¹ã«ä¿å­˜å®Œäº†: {alternative_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ä»£æ›¿ä¿å­˜ã‚‚å¤±æ•—: {e}\")\n",
    "\n",
    "# === è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†å®Ÿè¡Œ ===\n",
    "print(\"ğŸ¯ è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã®æœ€é©åŒ–ã•ã‚ŒãŸçµ±è¨ˆè¨ˆç®—ã‚’é–‹å§‹...\")\n",
    "print(f\"ğŸ“ å‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(h5_files)}\")\n",
    "\n",
    "total_start_time = time.time()\n",
    "processed_files = 0\n",
    "failed_files = []\n",
    "\n",
    "for file_idx, h5_path in enumerate(h5_files, 1):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ğŸ“‚ ãƒ•ã‚¡ã‚¤ãƒ« {file_idx}/{len(h5_files)}: {os.path.basename(h5_path)}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª\n",
    "    if not os.path.exists(h5_path):\n",
    "        print(f\"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {h5_path}\")\n",
    "        failed_files.append(h5_path)\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†\n",
    "        result, output_csv = process_single_file(h5_path)\n",
    "        \n",
    "        # çµæœä¿å­˜\n",
    "        save_results(result, output_csv)\n",
    "        \n",
    "        processed_files += 1\n",
    "        \n",
    "        # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—\n",
    "        del result\n",
    "        if GPU_AVAILABLE:\n",
    "            cp.get_default_memory_pool().free_all_blocks()\n",
    "        \n",
    "        print(f\"âœ… ãƒ•ã‚¡ã‚¤ãƒ« {file_idx} å®Œäº†: {os.path.basename(h5_path)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ãƒ•ã‚¡ã‚¤ãƒ« {file_idx} å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "        failed_files.append(h5_path)\n",
    "        continue\n",
    "\n",
    "# === å…¨ä½“å‡¦ç†çµæœã‚µãƒãƒªãƒ¼ ===\n",
    "total_elapsed = time.time() - total_start_time\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"ğŸ‰ å…¨ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†å®Œäº†!\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"ğŸ“Š å‡¦ç†çµ±è¨ˆ:\")\n",
    "print(f\"  âœ… æˆåŠŸ: {processed_files}/{len(h5_files)} ãƒ•ã‚¡ã‚¤ãƒ«\")\n",
    "print(f\"  âŒ å¤±æ•—: {len(failed_files)} ãƒ•ã‚¡ã‚¤ãƒ«\")\n",
    "print(f\"â±ï¸  ç·å‡¦ç†æ™‚é–“: {total_elapsed/60:.1f}åˆ†\")\n",
    "\n",
    "if failed_files:\n",
    "    print(f\"\\nâš ï¸ å¤±æ•—ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«:\")\n",
    "    for failed_file in failed_files:\n",
    "        print(f\"  â€¢ {failed_file}\")\n",
    "\n",
    "print(\"\\nğŸ§¹ æœ€çµ‚ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—...\")\n",
    "if GPU_AVAILABLE:\n",
    "    try:\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "        print(\"ğŸ§¹ GPU ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(\"ğŸ¯ å…¨å‡¦ç†å®Œäº†!\")\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# è¤ªè‰²è£œæ­£å‡¦ç†\n",
    "########################################################################\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import time\n",
    "import cupy as cp\n",
    "from scipy.signal import savgol_filter\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# === ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆè¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œï¼‰ ===\n",
    "calc_method = \"_top90_mean\"  # ä½¿ç”¨ã™ã‚‹åˆ—ã®ãƒ¡ã‚½ãƒƒãƒ‰\n",
    "\n",
    "# å‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã®å®šç¾©\n",
    "file_configs = [\n",
    "    {\n",
    "        \"name\": \"20240508-174849tdTomato-12mW-3\",\n",
    "        \"csv_path\": r\"I:\\20240508-174849tdTomato-12mW-3_raw_gzip\\20240508-174849tdTomato-12mW-3_corrected_size_gpu_top90_mean.csv\",\n",
    "        \"h5_input_path\": r\"I:\\20240508-174849tdTomato-12mW-3_raw_gzip\\20240508-174849tdTomato-12mW-3_corrected_size_gpu.h5\",\n",
    "        \"h5_output_path\": r\"I:\\20240508-174849tdTomato-12mW-3_raw_gzip\\20240508-174849tdTomato-12mW-3_corrected_size_gpu_bleachcorrect{}.h5\"\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "# å…±é€šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
    "offset_value = 100\n",
    "scale_margin = 1.2\n",
    "chunk_size = 60  # ãƒ¡ãƒ¢ãƒªãƒ¼ã‚µã‚¤ã‚ºã«å¿œã˜ã¦è¨­å®š\n",
    "\n",
    "# === è¤ªè‰²é–¢æ•°å®šç¾© ===\n",
    "def double_exp(t, a, b, c, d):\n",
    "    return a * np.exp(-b * t) + c * np.exp(-d * t)\n",
    "\n",
    "# === ãƒãƒ£ãƒ³ãƒãƒ«åˆ¥è¤ªè‰²ã‚«ãƒ¼ãƒ–æ¨å®š ===\n",
    "def estimate_bleach_curves(csv_path, file_name):\n",
    "    \"\"\"å„ãƒãƒ£ãƒ³ãƒãƒ«ã®è¤ªè‰²ã‚«ãƒ¼ãƒ–ã‚’ç‹¬ç«‹ã—ã¦æ¨å®š\"\"\"\n",
    "    print(f\"\\nğŸ”¬ {file_name} ã®è¤ªè‰²ã‚«ãƒ¼ãƒ–æ¨å®šé–‹å§‹...\")\n",
    "    \n",
    "    # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"âŒ CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_path}\")\n",
    "        return None\n",
    "    \n",
    "    df = pd.read_csv(csv_path)\n",
    "    t = np.arange(len(df))\n",
    "    \n",
    "    bleach_params = {}\n",
    "    scale_factors = {}\n",
    "    \n",
    "    # ãƒãƒ£ãƒ³ãƒãƒ«æ•°ã®è‡ªå‹•æ¤œå‡º\n",
    "    mean_columns = [col for col in df.columns if col.endswith(calc_method)]\n",
    "    channel_numbers = [int(col.split('_')[0][2:]) for col in mean_columns if col.startswith('ch')]\n",
    "    \n",
    "    print(f\"ğŸ” æ¤œå‡ºã•ã‚ŒãŸãƒãƒ£ãƒ³ãƒãƒ«: {channel_numbers}\")\n",
    "    \n",
    "    if not channel_numbers:\n",
    "        print(f\"âš ï¸ æœ‰åŠ¹ãªãƒãƒ£ãƒ³ãƒãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "        return None\n",
    "    \n",
    "    for ch_num in channel_numbers:\n",
    "        column_name = f\"ch{ch_num}{calc_method}\"\n",
    "        \n",
    "        if column_name not in df.columns:\n",
    "            print(f\"âš ï¸ åˆ— '{column_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n--- Channel {ch_num} è¤ªè‰²ã‚«ãƒ¼ãƒ–æ¨å®š ---\")\n",
    "        \n",
    "        y_raw = df[column_name].to_numpy()\n",
    "        # SGãƒ•ã‚£ãƒ«ã‚¿é©ç”¨ï¼ˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º13, å¤šé …å¼æ¬¡æ•°1ï¼‰\n",
    "        y_smooth = savgol_filter(y_raw, window_length=13, polyorder=1, mode='interp')\n",
    "        \n",
    "        # åˆæœŸå€¤ã¨ä¸Šé™ã®æ¨å®š\n",
    "        a0 = c0 = y_smooth[0] / 2\n",
    "        p0 = [a0, 0.01, c0, 0.001]\n",
    "        y_max = np.nanmax(y_smooth)\n",
    "        upper_limit = y_max * scale_margin\n",
    "        bounds = ([0, 0, 0, 0], [upper_limit, 1, upper_limit, 1])\n",
    "        \n",
    "        try:\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                popt, _ = curve_fit(double_exp, t, y_smooth, p0=p0, bounds=bounds, maxfev=10000)\n",
    "            \n",
    "            fitted = double_exp(t, *popt)\n",
    "            scale = double_exp(0, *popt) / fitted  # t=0ã§æ­£è¦åŒ–\n",
    "            \n",
    "            bleach_params[ch_num] = popt\n",
    "            scale_factors[ch_num] = scale\n",
    "            \n",
    "            print(f\"âœ… Ch{ch_num} ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°å®Œäº†: a={popt[0]:.2f}, b={popt[1]:.4f}, c={popt[2]:.2f}, d={popt[3]:.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Ch{ch_num} ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°å¤±æ•—: {e}\")\n",
    "            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚¹ã‚±ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼=1ï¼ˆè£œæ­£ãªã—ï¼‰\n",
    "            scale_factors[ch_num] = np.ones_like(t)\n",
    "    \n",
    "    # ãƒ—ãƒ­ãƒƒãƒˆä½œæˆãƒ»ä¿å­˜\n",
    "    if bleach_params:\n",
    "        try:\n",
    "            fig, axes = plt.subplots(1, len(channel_numbers), figsize=(6 * len(channel_numbers), 4), sharey=True)\n",
    "            if len(channel_numbers) == 1:\n",
    "                axes = [axes]\n",
    "            \n",
    "            for idx, ch in enumerate(channel_numbers):\n",
    "                col_name = f\"ch{ch}{calc_method}\"\n",
    "                y = df[col_name].to_numpy()\n",
    "                if ch in bleach_params:\n",
    "                    fit = double_exp(t, *bleach_params[ch])\n",
    "                    corrected = y * scale_factors[ch]\n",
    "                else:\n",
    "                    fit = np.ones_like(t) * y[0]\n",
    "                    corrected = y\n",
    "                    \n",
    "                axes[idx].plot(t, y, 'o', label=f'Ch{ch} Raw', markersize=2)\n",
    "                axes[idx].plot(t, fit, '-', label=f'Ch{ch} Fit', linewidth=2)\n",
    "                axes[idx].plot(t, corrected, '--', label=f'Ch{ch} Corrected', linewidth=2)\n",
    "                axes[idx].set_title(f'Channel {ch} Bleach Curve')\n",
    "                axes[idx].set_xlabel('Time')\n",
    "                axes[idx].legend()\n",
    "                \n",
    "            axes[0].set_ylabel('Intensity')\n",
    "            plt.suptitle(f'{file_name} - Bleach Correction')\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # ãƒ•ã‚¡ã‚¤ãƒ«åã«å¯¾å¿œã—ãŸä¿å­˜\n",
    "            plot_filename = f'bleach_curve_{file_name}{calc_method}.png'\n",
    "            plt.savefig(plot_filename, dpi=150, bbox_inches='tight')\n",
    "            print(f\"ğŸ“Š ãƒ—ãƒ­ãƒƒãƒˆä¿å­˜: {plot_filename}\")\n",
    "            plt.show()\n",
    "            \n",
    "        except Exception as plot_error:\n",
    "            print(f\"âš ï¸ ãƒ—ãƒ­ãƒƒãƒˆä½œæˆã‚¨ãƒ©ãƒ¼: {plot_error}\")\n",
    "    \n",
    "    return scale_factors\n",
    "\n",
    "# GPUå¯ç”¨æ€§ãƒã‚§ãƒƒã‚¯\n",
    "try:\n",
    "    GPU_AVAILABLE = True\n",
    "    gpu_props = cp.cuda.runtime.getDeviceProperties(0)\n",
    "    gpu_name = gpu_props['name'].decode('utf-8')\n",
    "    total_memory_gb = cp.cuda.Device().mem_info[1] / (1024**3)\n",
    "    print(\"ğŸš€ GPUå‡¦ç†ãŒåˆ©ç”¨å¯èƒ½ã§ã™\")\n",
    "    print(f\"ğŸ® GPU: {gpu_name}\")\n",
    "    print(f\"ğŸ’¾ VRAM: {total_memory_gb:.1f}GB\")\n",
    "except ImportError:\n",
    "    GPU_AVAILABLE = False\n",
    "    print(\"âš ï¸ CuPyãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚CPUå‡¦ç†ã‚’ä½¿ç”¨ã—ã¾ã™\")\n",
    "\n",
    "def process_with_gpu_multichannel(h5_input_path, h5_output_path, scale_factors_all, file_name):\n",
    "    \"\"\"ãƒãƒ£ãƒ³ãƒãƒ«åˆ¥è¤ªè‰²è£œæ­£GPUå‡¦ç†ï¼ˆå…¨ãƒœãƒªãƒ¥ãƒ¼ãƒ å¯¾å¿œï¼‰\"\"\"\n",
    "    if not GPU_AVAILABLE:\n",
    "        print(\"âŒ GPUå‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™\")\n",
    "        return False\n",
    "    \n",
    "    if not scale_factors_all:\n",
    "        print(\"âŒ ã‚¹ã‚±ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"\\nğŸ® {file_name} ã®GPUè¤ªè‰²è£œæ­£å‡¦ç†é–‹å§‹...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        with h5py.File(h5_input_path, \"r\") as f_in, h5py.File(h5_output_path, \"w\") as f_out:\n",
    "            dset_in = f_in[\"/default\"]\n",
    "            T_full, C, Z, Y, X = dset_in.shape\n",
    "            \n",
    "            print(f\"ğŸ“ ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (T={T_full}, C={C}, Z={Z}, Y={Y}, X={X})\")\n",
    "            print(f\"ğŸ¯ å‡¦ç†å¯¾è±¡: å…¨ãƒœãƒªãƒ¥ãƒ¼ãƒ ï¼ˆ{T_full}ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰\")\n",
    "            \n",
    "            # å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆï¼ˆå…¨ãƒœãƒªãƒ¥ãƒ¼ãƒ ï¼‰\n",
    "            dset_out = f_out.create_dataset(\n",
    "                \"/default\", \n",
    "                shape=(T_full, C, Z, Y, X),\n",
    "                dtype='uint16',\n",
    "                chunks=(min(chunk_size//4, 20), 1, Z, Y, X),\n",
    "                compression=\"gzip\",\n",
    "                compression_opts=1\n",
    "            )\n",
    "            \n",
    "            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¿½åŠ \n",
    "            dset_out.attrs['processing_mode'] = 'multichannel_bleach_correction_full'\n",
    "            dset_out.attrs['file_name'] = file_name\n",
    "            dset_out.attrs['chunk_size'] = chunk_size\n",
    "            dset_out.attrs['offset_value'] = offset_value\n",
    "            dset_out.attrs['processed_frames'] = T_full\n",
    "            dset_out.attrs['frame_range'] = f\"0-{T_full-1}\"\n",
    "            \n",
    "            # ãƒãƒ£ãƒ³ãƒãƒ«åˆ¥ã‚¹ã‚±ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ã®æº–å‚™\n",
    "            scale_factors_gpu = {}\n",
    "            for ch_num in range(C):\n",
    "                if ch_num in scale_factors_all:\n",
    "                    # å…¨ãƒ•ãƒ¬ãƒ¼ãƒ åˆ†ã‚’å–å¾—\n",
    "                    scale_factors_gpu[ch_num] = cp.asarray(\n",
    "                        scale_factors_all[ch_num], dtype=cp.float32\n",
    "                    )\n",
    "                    print(f\"âœ… Ch{ch_num}: GPUç”¨ã‚¹ã‚±ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼æº–å‚™å®Œäº†ï¼ˆ{T_full}ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰\")\n",
    "                else:\n",
    "                    scale_factors_gpu[ch_num] = cp.ones(T_full, dtype=cp.float32)\n",
    "                    print(f\"âš ï¸ Ch{ch_num}: ã‚¹ã‚±ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ãªã—ï¼ˆè£œæ­£ã‚¹ã‚­ãƒƒãƒ—ï¼‰\")\n",
    "            \n",
    "            # ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—ï¼ˆå…¨ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰\n",
    "            for t_start in tqdm(range(0, T_full, chunk_size), desc=f\"ğŸ® {file_name} GPUè¤ªè‰²è£œæ­£\"):\n",
    "                t_end = min(t_start + chunk_size, T_full)\n",
    "                current_chunk_size = t_end - t_start\n",
    "                \n",
    "                try:\n",
    "                    # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç›£è¦–\n",
    "                    memory_before = cp.cuda.Device().mem_info[0] / (1024**3)\n",
    "                    \n",
    "                    # ãƒãƒ£ãƒ³ãƒãƒ«åˆ¥å‡¦ç†\n",
    "                    for c in range(C):\n",
    "                        # CPUã‹ã‚‰GPUã¸ãƒ‡ãƒ¼ã‚¿è»¢é€\n",
    "                        vol_chunk = cp.asarray(\n",
    "                            dset_in[t_start:t_end, c, :, :, :], \n",
    "                            dtype=cp.float32\n",
    "                        )\n",
    "                        \n",
    "                        # ãƒãƒ£ãƒ³ãƒãƒ«å°‚ç”¨ã‚¹ã‚±ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼å–å¾—\n",
    "                        scale_chunk = scale_factors_gpu[c][t_start:t_end]\n",
    "                        \n",
    "                        # GPUä¸Šã§ãƒ™ã‚¯ãƒˆãƒ«åŒ–å‡¦ç†\n",
    "                        vol_chunk -= offset_value  # ã‚ªãƒ•ã‚»ãƒƒãƒˆæ¸›ç®—\n",
    "                        vol_chunk *= scale_chunk.reshape(-1, 1, 1, 1)  # ãƒãƒ£ãƒ³ãƒãƒ«åˆ¥è¤ªè‰²è£œæ­£\n",
    "                        vol_chunk = cp.clip(vol_chunk, 0, 65535)  # ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°\n",
    "                        \n",
    "                        # å‹å¤‰æ›ã¨çµæœä¿å­˜\n",
    "                        vol_chunk = vol_chunk.astype(cp.uint16)\n",
    "                        result = cp.asnumpy(vol_chunk)\n",
    "                        dset_out[t_start:t_end, c, :, :, :] = result\n",
    "                        \n",
    "                        # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆãƒãƒ£ãƒ³ãƒãƒ«æ¯ï¼‰\n",
    "                        del vol_chunk, result\n",
    "                        cp.cuda.Stream.null.synchronize()\n",
    "                    \n",
    "                    # é€²æ—æƒ…å ±è¡¨ç¤º\n",
    "                    if t_start % (chunk_size * 5) == 0:\n",
    "                        elapsed = time.time() - start_time\n",
    "                        processed_frames = t_end\n",
    "                        fps = processed_frames / elapsed if elapsed > 0 else 0\n",
    "                        remaining_frames = T_full - processed_frames\n",
    "                        eta_minutes = (remaining_frames / fps / 60) if fps > 0 else 0\n",
    "                        \n",
    "                        print(f\"  ğŸ“Š é€²æ—: {processed_frames}/{T_full} ({100*processed_frames/T_full:.1f}%)\")\n",
    "                        print(f\"  ğŸš€ é€Ÿåº¦: {fps:.1f}fps, VRAM: {memory_before:.1f}GB, ETA: {eta_minutes:.1f}åˆ†\")\n",
    "                        \n",
    "                except cp.cuda.memory.OutOfMemoryError:\n",
    "                    print(f\"ğŸ’¥ GPU ãƒ¡ãƒ¢ãƒªä¸è¶³ (chunk_size={chunk_size})\")\n",
    "                    cp.get_default_memory_pool().free_all_blocks()\n",
    "                    continue\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"âŒ å‡¦ç†ã‚¨ãƒ©ãƒ¼ (t={t_start}-{t_end}): {e}\")\n",
    "                    continue\n",
    "        \n",
    "        # æœ€çµ‚ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—\n",
    "        try:\n",
    "            channel_keys = list(scale_factors_gpu.keys())\n",
    "            for ch_num in channel_keys:\n",
    "                if ch_num in scale_factors_gpu:\n",
    "                    del scale_factors_gpu[ch_num]\n",
    "            cp.get_default_memory_pool().free_all_blocks()\n",
    "        except Exception as cleanup_error:\n",
    "            print(f\"âš ï¸ ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {cleanup_error}\")\n",
    "            try:\n",
    "                cp.get_default_memory_pool().free_all_blocks()\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # å‡¦ç†çµæœã‚µãƒãƒªãƒ¼\n",
    "        total_elapsed = time.time() - start_time\n",
    "        average_fps = T_full / total_elapsed if total_elapsed > 0 else 0\n",
    "        \n",
    "        print(f\"\\nğŸ‰ {file_name} è¤ªè‰²è£œæ­£GPUå‡¦ç†å®Œäº†!\")\n",
    "        print(f\"ğŸ“Š å‡¦ç†ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {T_full}\")\n",
    "        print(f\"ğŸ”„ å‡¦ç†ãƒãƒ£ãƒ³ãƒãƒ«æ•°: {C}\")\n",
    "        print(f\"â±ï¸  ç·å‡¦ç†æ™‚é–“: {total_elapsed/60:.1f}åˆ†\")\n",
    "        print(f\"ğŸš€ å¹³å‡å‡¦ç†é€Ÿåº¦: {average_fps:.1f}ãƒ•ãƒ¬ãƒ¼ãƒ /ç§’\")\n",
    "        print(f\"ğŸ’¾ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {h5_output_path}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ {file_name} å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}\")\n",
    "        return False\n",
    "\n",
    "# === è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†å®Ÿè¡Œ ===\n",
    "print(\"ğŸ¯ è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã®è¤ªè‰²è£œæ­£å‡¦ç†ã‚’é–‹å§‹...\")\n",
    "print(f\"ğŸ“ å‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(file_configs)}\")\n",
    "\n",
    "total_start_time = time.time()\n",
    "processed_files = 0\n",
    "failed_files = []\n",
    "\n",
    "for file_idx, config in enumerate(file_configs, 1):\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"ğŸ“‚ ãƒ•ã‚¡ã‚¤ãƒ« {file_idx}/{len(file_configs)}: {config['name']}\")\n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª\n",
    "    if not os.path.exists(config['csv_path']):\n",
    "        print(f\"âŒ CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {config['csv_path']}\")\n",
    "        failed_files.append(config['name'])\n",
    "        continue\n",
    "        \n",
    "    if not os.path.exists(config['h5_input_path']):\n",
    "        print(f\"âŒ å…¥åŠ›H5ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {config['h5_input_path']}\")\n",
    "        failed_files.append(config['name'])\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # 1. è¤ªè‰²ã‚«ãƒ¼ãƒ–æ¨å®š\n",
    "        scale_factors_all = estimate_bleach_curves(\n",
    "            config['csv_path'], \n",
    "            config['name']\n",
    "        )\n",
    "        \n",
    "        if scale_factors_all is None:\n",
    "            print(f\"âŒ {config['name']}: è¤ªè‰²ã‚«ãƒ¼ãƒ–æ¨å®šã«å¤±æ•—\")\n",
    "            failed_files.append(config['name'])\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nâœ… {config['name']}: å…¨ãƒãƒ£ãƒ³ãƒãƒ«ã®è¤ªè‰²ã‚«ãƒ¼ãƒ–æ¨å®šå®Œäº†\")\n",
    "        \n",
    "        # 2. å‡ºåŠ›ãƒ‘ã‚¹è¨­å®š\n",
    "        h5_output_path = config['h5_output_path'].format(calc_method)\n",
    "        \n",
    "        # 3. GPUè¤ªè‰²è£œæ­£å‡¦ç†\n",
    "        if GPU_AVAILABLE and scale_factors_all:\n",
    "            success = process_with_gpu_multichannel(\n",
    "                config['h5_input_path'],\n",
    "                h5_output_path,\n",
    "                scale_factors_all,\n",
    "                config['name']\n",
    "            )\n",
    "            \n",
    "            if success:\n",
    "                processed_files += 1\n",
    "                print(f\"âœ… ãƒ•ã‚¡ã‚¤ãƒ« {file_idx} å®Œäº†: {config['name']}\")\n",
    "            else:\n",
    "                failed_files.append(config['name'])\n",
    "        else:\n",
    "            print(\"âš ï¸ GPUå‡¦ç†ã¾ãŸã¯ã‚¹ã‚±ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“\")\n",
    "            failed_files.append(config['name'])\n",
    "        \n",
    "        # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—\n",
    "        del scale_factors_all\n",
    "        if GPU_AVAILABLE:\n",
    "            cp.get_default_memory_pool().free_all_blocks()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ãƒ•ã‚¡ã‚¤ãƒ« {file_idx} å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "        failed_files.append(config['name'])\n",
    "        continue\n",
    "\n",
    "# === å…¨ä½“å‡¦ç†çµæœã‚µãƒãƒªãƒ¼ ===\n",
    "total_elapsed = time.time() - total_start_time\n",
    "\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(f\"ğŸ‰ å…¨ãƒ•ã‚¡ã‚¤ãƒ«è¤ªè‰²è£œæ­£å‡¦ç†å®Œäº†!\")\n",
    "print(f\"{'='*100}\")\n",
    "print(f\"ğŸ“Š å‡¦ç†çµ±è¨ˆ:\")\n",
    "print(f\"  âœ… æˆåŠŸ: {processed_files}/{len(file_configs)} ãƒ•ã‚¡ã‚¤ãƒ«\")\n",
    "print(f\"  âŒ å¤±æ•—: {len(failed_files)} ãƒ•ã‚¡ã‚¤ãƒ«\")\n",
    "print(f\"â±ï¸  ç·å‡¦ç†æ™‚é–“: {total_elapsed/60:.1f}åˆ†\")\n",
    "\n",
    "if failed_files:\n",
    "    print(f\"\\nâš ï¸ å¤±æ•—ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«:\")\n",
    "    for failed_file in failed_files:\n",
    "        print(f\"  â€¢ {failed_file}\")\n",
    "\n",
    "print(\"\\nğŸ§¹ æœ€çµ‚ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—...\")\n",
    "if GPU_AVAILABLE:\n",
    "    try:\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "        print(\"ğŸ§¹ GPU ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(\"ğŸ¯ å…¨è¤ªè‰²è£œæ­£å‡¦ç†å®Œäº†!\")\n",
    "\n",
    "########################################################################\n",
    "# MIPç”»åƒã®ç”Ÿæˆ\n",
    "########################################################################\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# GPUå¯ç”¨æ€§ãƒã‚§ãƒƒã‚¯\n",
    "try:\n",
    "    import cupy as cp\n",
    "    GPU_AVAILABLE = True\n",
    "    print(\"ğŸš€ GPUå‡¦ç†ãŒåˆ©ç”¨å¯èƒ½ã§ã™\")\n",
    "    \n",
    "    # GPUæƒ…å ±è¡¨ç¤º\n",
    "    gpu_props = cp.cuda.runtime.getDeviceProperties(0)\n",
    "    gpu_name = gpu_props['name'].decode('utf-8')\n",
    "    total_memory_gb = cp.cuda.Device().mem_info[1] / (1024**3)\n",
    "    print(f\"ğŸ® GPU: {gpu_name}\")\n",
    "    print(f\"ğŸ’¾ VRAM: {total_memory_gb:.1f}GB\")\n",
    "    \n",
    "except ImportError:\n",
    "    GPU_AVAILABLE = False\n",
    "    print(\"âš ï¸ CPUå‡¦ç†ã‚’ä½¿ç”¨ã—ã¾ã™\")\n",
    "\n",
    "# === ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆè¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œï¼‰ ===\n",
    "# å‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã®å®šç¾©\n",
    "# orthogonal_configs = [\n",
    "#     {\n",
    "#         \"name\": \"20240508-200229tdTomato-10mW-4\",\n",
    "#         \"hdf5_file\": r\"I:\\20240508-200229tdTomato-10mW-4_raw_gzip\\20240508-200229tdTomato-10mW-4_raw_gzip_bleachcorrect_top90_mean.h5\",\n",
    "#         \"output_path\": r\"I:\\20240508-200229tdTomato-10mW-4_raw_gzip\\orthogonal_views\"\n",
    "#     },\n",
    "#     {\n",
    "#         \"name\": \"20240516-203245tdTomato-7mW-3\",\n",
    "#         \"hdf5_file\": r\"I:\\20240516-203245tdTomato-7mW-3_raw_gzip\\20240516-203245tdTomato-7mW-3_raw_gzip_bleachcorrect_top90_mean.h5\",\n",
    "#         \"output_path\": r\"I:\\20240516-203245tdTomato-7mW-3_raw_gzip\\orthogonal_views\"\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "\n",
    "orthogonal_configs = [\n",
    "    {\n",
    "        \"name\": \"20240508-174849tdTomato-12mW-3\",\n",
    "        \"hdf5_file\": r\"I:\\20240508-174849tdTomato-12mW-3_raw_gzip\\20240508-174849tdTomato-12mW-3_corrected_size_gpu_bleachcorrect_top90_mean.h5\",\n",
    "        \"output_path\": r\"I:\\20240508-174849tdTomato-12mW-3_raw_gzip\\orthogonal_views\"\n",
    "    }\n",
    "]\n",
    "\n",
    "chunk_size = 100 if GPU_AVAILABLE else 50  # GPUä½¿ç”¨æ™‚ã¯ã‚ˆã‚Šå¤§ããªãƒãƒ£ãƒ³ã‚¯\n",
    "\n",
    "def process_cpu_chunk(chunk_data, t_start, t_end, orthogonal_view, channels, z, y, x):\n",
    "    \"\"\"CPUå‡¦ç†ç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°\"\"\"\n",
    "    for i, t in enumerate(range(t_start, t_end)):\n",
    "        for c in range(channels):\n",
    "            data = chunk_data[i, c]  # (Z, Y, X)\n",
    "            \n",
    "            # CPUä¸Šã§æœ€å¤§æŠ•å½±\n",
    "            xy_proj = np.max(data, axis=0)  # (Y, X)\n",
    "            yz_proj = np.max(data, axis=2).T  # (Z, Y)\n",
    "            xz_proj = np.max(data, axis=1)  # (Z, X)\n",
    "            \n",
    "            # ç›´äº¤ãƒ“ãƒ¥ãƒ¼ã¸ã®é…ç½®\n",
    "            orthogonal_view[t, c, 0:y, 0:x] = xy_proj\n",
    "            orthogonal_view[t, c, 0:y, x+3:x+z+3] = yz_proj\n",
    "            orthogonal_view[t, c, y+3:y+z+3, 0:x] = xz_proj\n",
    "            orthogonal_view[t, c, y+z+2, x+z+2] = 1000\n",
    "\n",
    "def process_orthogonal_projections_single(hdf5_file, output_path, file_name):\n",
    "    \"\"\"å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã®ç›´äº¤æŠ•å½±å‡¦ç†\"\"\"\n",
    "    print(f\"\\nğŸ¯ {file_name} ã®ç›´äº¤æŠ•å½±å‡¦ç†é–‹å§‹...\")\n",
    "    \n",
    "    # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª\n",
    "    if not os.path.exists(hdf5_file):\n",
    "        print(f\"âŒ H5ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {hdf5_file}\")\n",
    "        return False\n",
    "    \n",
    "    # å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆ\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "        print(f\"ğŸ“ å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆ: {output_path}\")\n",
    "    \n",
    "    dirname = os.path.splitext(os.path.basename(hdf5_file))[0]\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # === HDF5ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±å–å¾— ===\n",
    "        with h5py.File(hdf5_file, 'r') as file:\n",
    "            array = file['default']\n",
    "            total_volumes, channels, z, y, x = array.shape\n",
    "            print(f\"ğŸ“ ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (T={total_volumes}, C={channels}, Z={z}, Y={y}, X={x})\")\n",
    "            print(f\"ğŸ¯ å‡¦ç†å¯¾è±¡: å…¨ãƒœãƒªãƒ¥ãƒ¼ãƒ ï¼ˆ{total_volumes}ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰\")\n",
    "        \n",
    "        # === å‡ºåŠ›é…åˆ—ã®æº–å‚™ï¼ˆå…¨ãƒœãƒªãƒ¥ãƒ¼ãƒ ï¼‰ ===\n",
    "        orthogonal_view = np.zeros((total_volumes, channels, y + z + 3, x + z + 3), dtype='uint16')\n",
    "        print(f\"ğŸ’¾ ãƒ¡ãƒ¢ãƒªç¢ºä¿: {orthogonal_view.nbytes / (1024**3):.2f}GB\")\n",
    "        \n",
    "        def process_orthogonal_projections():\n",
    "            \"\"\"ç›´äº¤æŠ•å½±å‡¦ç†ï¼ˆCPU/GPUè‡ªå‹•é¸æŠãƒ»å…¨ãƒœãƒªãƒ¥ãƒ¼ãƒ ï¼‰\"\"\"\n",
    "            use_gpu = GPU_AVAILABLE  # ãƒ­ãƒ¼ã‚«ãƒ«å¤‰æ•°ã¨ã—ã¦å‡¦ç†çŠ¶æ…‹ã‚’ç®¡ç†\n",
    "            \n",
    "            with h5py.File(hdf5_file, 'r') as file:\n",
    "                array = file['default']\n",
    "                \n",
    "                for t_start in tqdm(range(0, total_volumes, chunk_size), \n",
    "                                   desc=f\"ğŸ® {file_name} GPUç›´äº¤æŠ•å½±\" if use_gpu else f\"ğŸ–¥ï¸ {file_name} CPUç›´äº¤æŠ•å½±\"):\n",
    "                    t_end = min(t_start + chunk_size, total_volumes)\n",
    "                    \n",
    "                    # ãƒãƒ£ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿\n",
    "                    chunk_data = array[t_start:t_end]  # (chunk_size, C, Z, Y, X)\n",
    "                    \n",
    "                    if use_gpu:\n",
    "                        # GPUå‡¦ç†ã‚’è©¦è¡Œ\n",
    "                        try:\n",
    "                            chunk_gpu = cp.asarray(chunk_data)\n",
    "                            \n",
    "                            for i, t in enumerate(range(t_start, t_end)):\n",
    "                                for c in range(channels):\n",
    "                                    data_gpu = chunk_gpu[i, c]  # (Z, Y, X)\n",
    "                                    \n",
    "                                    # GPUä¸Šã§æœ€å¤§æŠ•å½±\n",
    "                                    xy_proj = cp.max(data_gpu, axis=0)  # (Y, X)\n",
    "                                    yz_proj = cp.max(data_gpu, axis=2).T  # (Z, Y)\n",
    "                                    xz_proj = cp.max(data_gpu, axis=1)  # (Z, X)\n",
    "                                    \n",
    "                                    # CPUå´ã«çµæœã‚’ã‚³ãƒ”ãƒ¼\n",
    "                                    orthogonal_view[t, c, 0:y, 0:x] = cp.asnumpy(xy_proj)\n",
    "                                    orthogonal_view[t, c, 0:y, x+3:x+z+3] = cp.asnumpy(yz_proj)\n",
    "                                    orthogonal_view[t, c, y+3:y+z+3, 0:x] = cp.asnumpy(xz_proj)\n",
    "                                    orthogonal_view[t, c, y+z+2, x+z+2] = 1000\n",
    "                            \n",
    "                            # GPUãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—\n",
    "                            del chunk_gpu\n",
    "                            cp.get_default_memory_pool().free_all_blocks()\n",
    "                            \n",
    "                            # é€²æ—æƒ…å ±è¡¨ç¤ºï¼ˆGPUå‡¦ç†ï¼‰\n",
    "                            if t_start % (chunk_size * 5) == 0:\n",
    "                                processed = t_end\n",
    "                                progress_pct = 100 * processed / total_volumes\n",
    "                                elapsed = time.time() - start_time\n",
    "                                fps = processed / elapsed if elapsed > 0 else 0\n",
    "                                eta_minutes = ((total_volumes - processed) / fps / 60) if fps > 0 else 0\n",
    "                                print(f\"  ğŸ“Š GPUé€²æ—: {processed}/{total_volumes} ({progress_pct:.1f}%), é€Ÿåº¦: {fps:.1f}fps, ETA: {eta_minutes:.1f}åˆ†\")\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            print(f\"âš ï¸ GPUå‡¦ç†ã‚¨ãƒ©ãƒ¼ã€CPUã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: {e}\")\n",
    "                            use_gpu = False  # ä»Šå¾Œã®ãƒãƒ£ãƒ³ã‚¯ã¯CPUå‡¦ç†\n",
    "                            # CPUå‡¦ç†ã§å†è©¦è¡Œ\n",
    "                            process_cpu_chunk(chunk_data, t_start, t_end, orthogonal_view, channels, z, y, x)\n",
    "                            \n",
    "                    else:\n",
    "                        # CPUå‡¦ç†\n",
    "                        process_cpu_chunk(chunk_data, t_start, t_end, orthogonal_view, channels, z, y, x)\n",
    "                        \n",
    "                        # é€²æ—æƒ…å ±è¡¨ç¤ºï¼ˆCPUå‡¦ç†ï¼‰\n",
    "                        if t_start % (chunk_size * 2) == 0:\n",
    "                            processed = t_end\n",
    "                            progress_pct = 100 * processed / total_volumes\n",
    "                            elapsed = time.time() - start_time\n",
    "                            fps = processed / elapsed if elapsed > 0 else 0\n",
    "                            eta_minutes = ((total_volumes - processed) / fps / 60) if fps > 0 else 0\n",
    "                            print(f\"  ğŸ“Š CPUé€²æ—: {processed}/{total_volumes} ({progress_pct:.1f}%), é€Ÿåº¦: {fps:.1f}fps, ETA: {eta_minutes:.1f}åˆ†\")\n",
    "        \n",
    "        # === å‡¦ç†å®Ÿè¡Œ ===\n",
    "        print(f\"ğŸ¯ å…¨ãƒœãƒªãƒ¥ãƒ¼ãƒ ï¼ˆ{total_volumes}ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰ã®ç›´äº¤æŠ•å½±å‡¦ç†ã‚’é–‹å§‹...\")\n",
    "        process_orthogonal_projections()\n",
    "        print(\"ğŸ‰ ç›´äº¤æŠ•å½±å‡¦ç†å®Œäº†!\")\n",
    "        \n",
    "        # === TIFFä¿å­˜ï¼ˆå…¨ãƒœãƒªãƒ¥ãƒ¼ãƒ ï¼‰ ===\n",
    "        file_name_tiff = f\"orthogonal_view_{dirname}_full.tif\"\n",
    "        output_path_full = os.path.join(output_path, file_name_tiff)\n",
    "        \n",
    "        print(\"ğŸ’¾ TIFFä¿å­˜ä¸­...\")\n",
    "        print(f\"ğŸ“ ä¿å­˜å…ˆ: {output_path_full}\")\n",
    "        print(f\"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {orthogonal_view.nbytes / (1024**3):.2f}GB\")\n",
    "        \n",
    "        try:\n",
    "            tiff.imwrite(\n",
    "                output_path_full, \n",
    "                orthogonal_view, \n",
    "                imagej=True, \n",
    "                metadata={'axes': 'TCYX'}, \n",
    "                compression='zlib'\n",
    "            )\n",
    "            \n",
    "            # å‡¦ç†çµæœã‚µãƒãƒªãƒ¼\n",
    "            total_elapsed = time.time() - start_time\n",
    "            average_fps = total_volumes / total_elapsed if total_elapsed > 0 else 0\n",
    "            \n",
    "            print(f\"âœ… {file_name} å‡¦ç†å®Œäº†: {output_path_full}\")\n",
    "            print(f\"ğŸ“ˆ å‡ºåŠ›å½¢çŠ¶: {orthogonal_view.shape}\")\n",
    "            print(f\"â±ï¸  ç·å‡¦ç†æ™‚é–“: {total_elapsed/60:.1f}åˆ†\")\n",
    "            print(f\"ğŸš€ å¹³å‡å‡¦ç†é€Ÿåº¦: {average_fps:.1f}ãƒ•ãƒ¬ãƒ¼ãƒ /ç§’\")\n",
    "            print(f\"ğŸ“Š å‡¦ç†çµ±è¨ˆ: {total_volumes}/{total_volumes}ãƒœãƒªãƒ¥ãƒ¼ãƒ  (100%)\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as save_error:\n",
    "            print(f\"âŒ TIFFä¿å­˜ã‚¨ãƒ©ãƒ¼: {save_error}\")\n",
    "            print(\"ğŸ’¡ ãƒ¡ãƒ¢ãƒªä¸è¶³ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ãƒãƒ£ãƒ³ã‚¯ä¿å­˜ã‚’è©¦ã—ã¾ã™...\")\n",
    "            \n",
    "            # === ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒãƒ£ãƒ³ã‚¯ä¿å­˜ ===\n",
    "            save_chunk_size = 500  # 500ãƒ•ãƒ¬ãƒ¼ãƒ ãšã¤ä¿å­˜\n",
    "            \n",
    "            for save_start in tqdm(range(0, total_volumes, save_chunk_size), desc=\"ğŸ“¦ ãƒãƒ£ãƒ³ã‚¯ä¿å­˜\"):\n",
    "                save_end = min(save_start + save_chunk_size, total_volumes)\n",
    "                chunk_name = f\"orthogonal_view_{dirname}_part{save_start:05d}-{save_end:05d}.tif\"\n",
    "                chunk_path = os.path.join(output_path, chunk_name)\n",
    "                \n",
    "                chunk_data = orthogonal_view[save_start:save_end]\n",
    "                tiff.imwrite(\n",
    "                    chunk_path,\n",
    "                    chunk_data,\n",
    "                    imagej=True,\n",
    "                    metadata={'axes': 'TCYX'},\n",
    "                    compression='zlib'\n",
    "                )\n",
    "                print(f\"âœ… ä¿å­˜å®Œäº†: {chunk_name}\")\n",
    "            \n",
    "            print(f\"ğŸ“¦ ãƒãƒ£ãƒ³ã‚¯ä¿å­˜å®Œäº†: {output_path}\")\n",
    "            return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ {file_name} å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}\")\n",
    "        return False\n",
    "    \n",
    "    finally:\n",
    "        # === ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ— ===\n",
    "        try:\n",
    "            if 'orthogonal_view' in locals():\n",
    "                del orthogonal_view\n",
    "            if GPU_AVAILABLE:\n",
    "                cp.get_default_memory_pool().free_all_blocks()\n",
    "            print(\"ğŸ§¹ ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# === è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†å®Ÿè¡Œ ===\n",
    "print(\"ğŸ¯ è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã®ç›´äº¤æŠ•å½±å‡¦ç†ã‚’é–‹å§‹...\")\n",
    "print(f\"ğŸ“ å‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(orthogonal_configs)}\")\n",
    "\n",
    "total_start_time = time.time()\n",
    "processed_files = 0\n",
    "failed_files = []\n",
    "\n",
    "for file_idx, config in enumerate(orthogonal_configs, 1):\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"ğŸ“‚ ãƒ•ã‚¡ã‚¤ãƒ« {file_idx}/{len(orthogonal_configs)}: {config['name']}\")\n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª\n",
    "    if not os.path.exists(config['hdf5_file']):\n",
    "        print(f\"âŒ H5ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {config['hdf5_file']}\")\n",
    "        failed_files.append(config['name'])\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†\n",
    "        success = process_orthogonal_projections_single(\n",
    "            config['hdf5_file'],\n",
    "            config['output_path'],\n",
    "            config['name']\n",
    "        )\n",
    "        \n",
    "        if success:\n",
    "            processed_files += 1\n",
    "            print(f\"âœ… ãƒ•ã‚¡ã‚¤ãƒ« {file_idx} å®Œäº†: {config['name']}\")\n",
    "        else:\n",
    "            failed_files.append(config['name'])\n",
    "        \n",
    "        # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—\n",
    "        if GPU_AVAILABLE:\n",
    "            cp.get_default_memory_pool().free_all_blocks()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ãƒ•ã‚¡ã‚¤ãƒ« {file_idx} å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "        failed_files.append(config['name'])\n",
    "        continue\n",
    "\n",
    "# === å…¨ä½“å‡¦ç†çµæœã‚µãƒãƒªãƒ¼ ===\n",
    "total_elapsed = time.time() - total_start_time\n",
    "\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(f\"ğŸ‰ å…¨ãƒ•ã‚¡ã‚¤ãƒ«ç›´äº¤æŠ•å½±å‡¦ç†å®Œäº†!\")\n",
    "print(f\"{'='*100}\")\n",
    "print(f\"ğŸ“Š å‡¦ç†çµ±è¨ˆ:\")\n",
    "print(f\"  âœ… æˆåŠŸ: {processed_files}/{len(orthogonal_configs)} ãƒ•ã‚¡ã‚¤ãƒ«\")\n",
    "print(f\"  âŒ å¤±æ•—: {len(failed_files)} ãƒ•ã‚¡ã‚¤ãƒ«\")\n",
    "print(f\"â±ï¸  ç·å‡¦ç†æ™‚é–“: {total_elapsed/60:.1f}åˆ†\")\n",
    "\n",
    "if failed_files:\n",
    "    print(f\"\\nâš ï¸ å¤±æ•—ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«:\")\n",
    "    for failed_file in failed_files:\n",
    "        print(f\"  â€¢ {failed_file}\")\n",
    "\n",
    "print(\"\\nğŸ§¹ æœ€çµ‚ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—...\")\n",
    "if GPU_AVAILABLE:\n",
    "    try:\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "        print(\"ğŸ§¹ GPU ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(\"ğŸ¯ å…¨ç›´äº¤æŠ•å½±å‡¦ç†å®Œäº†!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd10727",
   "metadata": {},
   "source": [
    "For real-time tracking. Save each volume data as TIFF after bleach correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f437691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# === ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ ===\n",
    "hdf5_file = r\"I:\\20240508-174849tdTomato-12mW-3_raw_gzip\\20240508-174849tdTomato-12mW-3_corrected_size_gpu_bleachcorrect_top90_mean.h5\"\n",
    "output_path = r\"I:\\20240508-174849tdTomato-12mW-3_raw_gzip\\bleachcorrect\\images_resize\"\n",
    "channel_to_save = 0  # ãƒãƒ£ãƒ³ãƒãƒ«0ã®ã¿ä¿å­˜\n",
    "max_volumes = 4900  # ä¿å­˜ã™ã‚‹æœ€å¤§ãƒœãƒªãƒ¥ãƒ¼ãƒ æ•°ï¼ˆ0-4899ã®4900å€‹ï¼‰\n",
    "chunk_size = 50  # I/OåŠ¹ç‡åŒ–ã®ãŸã‚ã®ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º\n",
    "\n",
    "# å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆ\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "    print(f\"ğŸ“ å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆ: {output_path}\")\n",
    "\n",
    "def save_individual_volumes():\n",
    "    \"\"\"ãƒãƒ£ãƒ³ãƒãƒ«0ã®å„ãƒœãƒªãƒ¥ãƒ¼ãƒ ã‚’å€‹åˆ¥TIFFãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ï¼ˆCPUç‰ˆï¼‰\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª\n",
    "    if not os.path.exists(hdf5_file):\n",
    "        print(f\"âŒ H5ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {hdf5_file}\")\n",
    "        return False\n",
    "    \n",
    "    with h5py.File(hdf5_file, 'r') as file:\n",
    "        dset = file['default']\n",
    "        total_volumes, channels, z, y, x = dset.shape\n",
    "        \n",
    "        # ä¿å­˜å¯¾è±¡ãƒœãƒªãƒ¥ãƒ¼ãƒ æ•°ã‚’åˆ¶é™\n",
    "        volumes_to_save = min(max_volumes, total_volumes)\n",
    "        \n",
    "        print(f\"ğŸ“ ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (T={total_volumes}, C={channels}, Z={z}, Y={y}, X={x})\")\n",
    "        print(f\"ğŸ¯ å‡¦ç†å¯¾è±¡: ãƒãƒ£ãƒ³ãƒãƒ«{channel_to_save} ã®0-{volumes_to_save-1}ãƒœãƒªãƒ¥ãƒ¼ãƒ ï¼ˆ{volumes_to_save}å€‹ï¼‰\")\n",
    "        print(f\"ğŸ’¾ å„ãƒœãƒªãƒ¥ãƒ¼ãƒ ã‚µã‚¤ã‚º: ({z}, {y}, {x})\")\n",
    "        \n",
    "        # ãƒãƒ£ãƒ³ãƒãƒ«å­˜åœ¨ç¢ºèª\n",
    "        if channel_to_save >= channels:\n",
    "            print(f\"âŒ ãƒãƒ£ãƒ³ãƒãƒ«{channel_to_save}ã¯å­˜åœ¨ã—ã¾ã›ã‚“ï¼ˆåˆ©ç”¨å¯èƒ½: 0-{channels-1}ï¼‰\")\n",
    "            return False\n",
    "        \n",
    "        # ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ã§I/OåŠ¹ç‡åŒ–\n",
    "        saved_count = 0\n",
    "        failed_count = 0\n",
    "        \n",
    "        for t_start in tqdm(range(0, volumes_to_save, chunk_size), \n",
    "                           desc=f\"ğŸ’¾ Ch{channel_to_save}ãƒœãƒªãƒ¥ãƒ¼ãƒ ä¿å­˜ï¼ˆ0-{volumes_to_save-1}ï¼‰\"):\n",
    "            t_end = min(t_start + chunk_size, volumes_to_save)\n",
    "            \n",
    "            try:\n",
    "                # ãƒãƒ£ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ (chunk_size, Z, Y, X)\n",
    "                chunk_data = dset[t_start:t_end, channel_to_save, :, :, :]\n",
    "                \n",
    "                # å„ãƒœãƒªãƒ¥ãƒ¼ãƒ ã‚’å€‹åˆ¥ã«ä¿å­˜\n",
    "                for i, t in enumerate(range(t_start, t_end)):\n",
    "                    volume_data = chunk_data[i]  # (Z, Y, X)\n",
    "                    \n",
    "                    # ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆï¼ˆã‚¼ãƒ­ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ãªã—ï¼‰\n",
    "                    tiff_filename = f\"corrected_volume_t{t}.tiff\"\n",
    "                    tiff_path = os.path.join(output_path, tiff_filename)\n",
    "                    \n",
    "                    try:\n",
    "                        # TIFFä¿å­˜ï¼ˆCPUå‡¦ç†ï¼‰\n",
    "                        tiff.imwrite(\n",
    "                            tiff_path,\n",
    "                            volume_data,\n",
    "                            imagej=True,\n",
    "                            metadata={'axes': 'ZYX'},\n",
    "                            compression='zlib'\n",
    "                        )\n",
    "                        \n",
    "                        saved_count += 1\n",
    "                        \n",
    "                        # é€²æ—æƒ…å ±ï¼ˆè©³ç´°ï¼‰\n",
    "                        if t % 100 == 0:  # 100ãƒœãƒªãƒ¥ãƒ¼ãƒ æ¯ã«è©³ç´°æƒ…å ±è¡¨ç¤º\n",
    "                            elapsed = time.time() - start_time\n",
    "                            fps = saved_count / elapsed if elapsed > 0 else 0\n",
    "                            remaining = volumes_to_save - saved_count\n",
    "                            eta_minutes = (remaining / fps / 60) if fps > 0 else 0\n",
    "                            \n",
    "                            print(f\"  ğŸ“Š é€²æ—: {saved_count}/{volumes_to_save} ({100*saved_count/volumes_to_save:.1f}%)\")\n",
    "                            print(f\"  ğŸ’¾ é€Ÿåº¦: {fps:.1f}ãƒœãƒªãƒ¥ãƒ¼ãƒ /ç§’, ETA: {eta_minutes:.1f}åˆ†\")\n",
    "                            print(f\"  ğŸ“„ æœ€æ–°ä¿å­˜: {tiff_filename}\")\n",
    "                        \n",
    "                    except Exception as save_error:\n",
    "                        print(f\"âŒ ãƒœãƒªãƒ¥ãƒ¼ãƒ  t{t} ä¿å­˜ã‚¨ãƒ©ãƒ¼: {save_error}\")\n",
    "                        failed_count += 1\n",
    "                        continue\n",
    "                \n",
    "                # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—\n",
    "                del chunk_data\n",
    "                \n",
    "            except Exception as chunk_error:\n",
    "                print(f\"âŒ ãƒãƒ£ãƒ³ã‚¯ t{t_start}-{t_end} èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {chunk_error}\")\n",
    "                failed_count += chunk_size\n",
    "                continue\n",
    "    \n",
    "    # å‡¦ç†çµæœã‚µãƒãƒªãƒ¼\n",
    "    total_elapsed = time.time() - start_time\n",
    "    average_fps = saved_count / total_elapsed if total_elapsed > 0 else 0\n",
    "    \n",
    "    print(f\"\\nğŸ‰ å€‹åˆ¥ãƒœãƒªãƒ¥ãƒ¼ãƒ ä¿å­˜å®Œäº†!\")\n",
    "    print(f\"ğŸ“Š ä¿å­˜çµ±è¨ˆ:\")\n",
    "    print(f\"  âœ… æˆåŠŸ: {saved_count}/{volumes_to_save} ãƒœãƒªãƒ¥ãƒ¼ãƒ \")\n",
    "    print(f\"  âŒ å¤±æ•—: {failed_count} ãƒœãƒªãƒ¥ãƒ¼ãƒ \")\n",
    "    print(f\"â±ï¸  ç·å‡¦ç†æ™‚é–“: {total_elapsed/60:.1f}åˆ†\")\n",
    "    print(f\"ğŸ’¾ å¹³å‡ä¿å­˜é€Ÿåº¦: {average_fps:.1f}ãƒœãƒªãƒ¥ãƒ¼ãƒ /ç§’\")\n",
    "    print(f\"ğŸ“ ä¿å­˜å…ˆ: {output_path}\")\n",
    "    print(f\"ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: corrected_volume_t0.tiff ï½ corrected_volume_t{volumes_to_save-1}.tiff\")\n",
    "    \n",
    "    # ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º\n",
    "    print(f\"\\nğŸ“‹ ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«ä¾‹:\")\n",
    "    sample_files = []\n",
    "    for t in [0, 1, 2, 10, 100, 1000, volumes_to_save//2, volumes_to_save-1]:\n",
    "        if t < volumes_to_save:\n",
    "            filename = f\"corrected_volume_t{t}.tiff\"\n",
    "            filepath = os.path.join(output_path, filename)\n",
    "            if os.path.exists(filepath):\n",
    "                file_size_mb = os.path.getsize(filepath) / (1024**2)\n",
    "                sample_files.append(f\"  ğŸ“„ {filename} ({file_size_mb:.1f}MB)\")\n",
    "    \n",
    "    for sample in sample_files[:10]:  # æœ€å¤§10å€‹è¡¨ç¤º\n",
    "        print(sample)\n",
    "    \n",
    "    if len(sample_files) > 10:\n",
    "        print(f\"  ... ä»– {len(sample_files)-10} ãƒ•ã‚¡ã‚¤ãƒ«\")\n",
    "    \n",
    "    return saved_count == volumes_to_save\n",
    "\n",
    "# === å®Ÿè¡Œ ===\n",
    "print(f\"ğŸ¯ ãƒãƒ£ãƒ³ãƒãƒ«0ã®å€‹åˆ¥ãƒœãƒªãƒ¥ãƒ¼ãƒ ä¿å­˜ã‚’é–‹å§‹ï¼ˆ0-{max_volumes-1}ãƒœãƒªãƒ¥ãƒ¼ãƒ ï¼‰...\")\n",
    "print(\"ğŸ’¡ CPUç‰ˆï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã«æœ€é©åŒ–ï¼‰\")\n",
    "success = save_individual_volumes()\n",
    "\n",
    "if success:\n",
    "    print(\"âœ… æŒ‡å®šç¯„å›²ã®ãƒœãƒªãƒ¥ãƒ¼ãƒ ä¿å­˜ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼\")\n",
    "else:\n",
    "    print(\"âš ï¸ ä¸€éƒ¨ã®ãƒœãƒªãƒ¥ãƒ¼ãƒ ä¿å­˜ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745b1666",
   "metadata": {},
   "source": [
    "For spinning disk confocal microscope data. Make voxel size isotropic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c53289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from scipy.ndimage import zoom\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "\n",
    "# GPUå¯ç”¨æ€§ãƒã‚§ãƒƒã‚¯ï¼ˆå¤§å®¹é‡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ç”¨ï¼‰\n",
    "try:\n",
    "    import cupy as cp\n",
    "    from cupyx.scipy.ndimage import zoom as cp_zoom\n",
    "    GPU_AVAILABLE = True\n",
    "    print(\"ğŸš€ GPUå‡¦ç†ãŒåˆ©ç”¨å¯èƒ½ã§ã™\")\n",
    "    \n",
    "    # GPUæƒ…å ±è¡¨ç¤º\n",
    "    gpu_props = cp.cuda.runtime.getDeviceProperties(0)\n",
    "    gpu_name = gpu_props['name'].decode('utf-8')\n",
    "    total_memory_gb = cp.cuda.Device().mem_info[1] / (1024**3)\n",
    "    print(f\"ğŸ® GPU: {gpu_name}, VRAM: {total_memory_gb:.1f}GB\")\n",
    "    \n",
    "except ImportError:\n",
    "    GPU_AVAILABLE = False\n",
    "    print(\"âš ï¸ CPUå‡¦ç†ã‚’ä½¿ç”¨ã—ã¾ã™ï¼ˆå¤§å®¹é‡ãƒ‡ãƒ¼ã‚¿ã®å ´åˆæ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ï¼‰\")\n",
    "\n",
    "# === ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ ===\n",
    "input_h5_path = r\"I:\\20240911_cam2_007_raw\\20240911_cam2_007_raw.h5\"\n",
    "output_h5_path = r\"I:\\20240911_cam2_007_raw\\20240911_cam2_007_raw_affine.h5\"\n",
    "\n",
    "# ç¾åœ¨ã®voxelã‚µã‚¤ã‚º\n",
    "original_voxel_size = {\n",
    "    'x': 0.43,  # Î¼m\n",
    "    'y': 0.43,  # Î¼m  \n",
    "    'z': 2.0    # Î¼m\n",
    "}\n",
    "\n",
    "# ç›®æ¨™voxelã‚µã‚¤ã‚ºï¼ˆç­‰æ–¹çš„ï¼‰\n",
    "target_voxel_size = 0.43  # Î¼m (xyzå…¨ã¦åŒã˜)\n",
    "\n",
    "# ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºï¼ˆãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã«å¿œã˜ã¦èª¿æ•´ï¼‰\n",
    "chunk_size = 20 if GPU_AVAILABLE else 10\n",
    "\n",
    "def calculate_zoom_factors():\n",
    "    \"\"\"ã‚ºãƒ¼ãƒ å€ç‡ã‚’è¨ˆç®—\"\"\"\n",
    "    zoom_factors = {\n",
    "        'x': original_voxel_size['x'] / target_voxel_size,\n",
    "        'y': original_voxel_size['y'] / target_voxel_size,\n",
    "        'z': original_voxel_size['z'] / target_voxel_size\n",
    "    }\n",
    "    \n",
    "    print(f\"ğŸ“ å…ƒã®voxelã‚µã‚¤ã‚º: x={original_voxel_size['x']}Î¼m, y={original_voxel_size['y']}Î¼m, z={original_voxel_size['z']}Î¼m\")\n",
    "    print(f\"ğŸ¯ ç›®æ¨™voxelã‚µã‚¤ã‚º: {target_voxel_size}Î¼m (ç­‰æ–¹çš„)\")\n",
    "    print(f\"ğŸ” ã‚ºãƒ¼ãƒ å€ç‡: x={zoom_factors['x']:.3f}, y={zoom_factors['y']:.3f}, z={zoom_factors['z']:.3f}\")\n",
    "    \n",
    "    return zoom_factors\n",
    "\n",
    "def calculate_output_shape(input_shape, zoom_factors):\n",
    "    \"\"\"å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã‚’è¨ˆç®—\"\"\"\n",
    "    t, z, y, x = input_shape\n",
    "    \n",
    "    new_z = int(z * zoom_factors['z'])\n",
    "    new_y = int(y * zoom_factors['y'])\n",
    "    new_x = int(x * zoom_factors['x'])\n",
    "    \n",
    "    print(f\"ğŸ“ å…ƒã®ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (T={t}, Z={z}, Y={y}, X={x})\")\n",
    "    print(f\"ğŸ“ å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (T={t}, Z={new_z}, Y={new_y}, X={new_x})\")\n",
    "    print(f\"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºå¤‰åŒ–: {t*z*y*x:,} â†’ {t*new_z*new_y*new_x:,} voxels ({new_z*new_y*new_x/(z*y*x):.2f}å€)\")\n",
    "    \n",
    "    return (t, new_z, new_y, new_x)\n",
    "\n",
    "def process_volume_gpu(volume_data, zoom_factors):\n",
    "    \"\"\"GPUç‰ˆãƒœãƒªãƒ¥ãƒ¼ãƒ è£œé–“å‡¦ç†\"\"\"\n",
    "    try:\n",
    "        # CPUã‹ã‚‰GPUã¸ãƒ‡ãƒ¼ã‚¿è»¢é€\n",
    "        volume_gpu = cp.asarray(volume_data, dtype=cp.float32)\n",
    "        \n",
    "        # 3Dç·šå½¢è£œé–“ï¼ˆZ, Y, Xè»¸ï¼‰\n",
    "        zoom_scales = (zoom_factors['z'], zoom_factors['y'], zoom_factors['x'])\n",
    "        interpolated_gpu = cp_zoom(volume_gpu, zoom_scales, order=1, mode='constant', cval=0)\n",
    "        \n",
    "        # ãƒ‡ãƒ¼ã‚¿å‹ã‚’å…ƒã«æˆ»ã—ã¦CPUã«è»¢é€\n",
    "        result = cp.asnumpy(interpolated_gpu.astype(cp.uint16))\n",
    "        \n",
    "        # GPUãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—\n",
    "        del volume_gpu, interpolated_gpu\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ GPUå‡¦ç†ã‚¨ãƒ©ãƒ¼ã€CPUã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: {e}\")\n",
    "        return process_volume_cpu(volume_data, zoom_factors)\n",
    "\n",
    "def process_volume_cpu(volume_data, zoom_factors):\n",
    "    \"\"\"CPUç‰ˆãƒœãƒªãƒ¥ãƒ¼ãƒ è£œé–“å‡¦ç†\"\"\"\n",
    "    # 3Dç·šå½¢è£œé–“ï¼ˆZ, Y, Xè»¸ï¼‰\n",
    "    zoom_scales = (zoom_factors['z'], zoom_factors['y'], zoom_factors['x'])\n",
    "    interpolated = zoom(volume_data.astype(np.float32), zoom_scales, order=1, mode='constant', cval=0)\n",
    "    \n",
    "    return interpolated.astype(np.uint16)\n",
    "\n",
    "def create_isotropic_voxel_data():\n",
    "    \"\"\"ç­‰æ–¹çš„voxelã‚µã‚¤ã‚ºã®HDF5ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª\n",
    "    if not os.path.exists(input_h5_path):\n",
    "        print(f\"âŒ å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_h5_path}\")\n",
    "        return False\n",
    "    \n",
    "    # ã‚ºãƒ¼ãƒ å€ç‡è¨ˆç®—\n",
    "    zoom_factors = calculate_zoom_factors()\n",
    "    \n",
    "    with h5py.File(input_h5_path, 'r') as f_in:\n",
    "        dset_in = f_in['/default']\n",
    "        input_shape = dset_in.shape  # (T, Z, Y, X)\n",
    "        \n",
    "        # å‡ºåŠ›ã‚µã‚¤ã‚ºè¨ˆç®—\n",
    "        output_shape = calculate_output_shape(input_shape, zoom_factors)\n",
    "        t_len, new_z, new_y, new_x = output_shape\n",
    "        \n",
    "        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æ¨å®š\n",
    "        input_size_gb = (np.prod(input_shape) * 2) / (1024**3)  # uint16 = 2bytes\n",
    "        output_size_gb = (np.prod(output_shape) * 2) / (1024**3)\n",
    "        \n",
    "        print(f\"ğŸ’¾ æ¨å®šãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡:\")\n",
    "        print(f\"  å…¥åŠ›ãƒ‡ãƒ¼ã‚¿: {input_size_gb:.2f}GB\")\n",
    "        print(f\"  å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿: {output_size_gb:.2f}GB\")\n",
    "        print(f\"  å‡¦ç†ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º: {chunk_size}ãƒ•ãƒ¬ãƒ¼ãƒ \")\n",
    "        \n",
    "        # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ\n",
    "        with h5py.File(output_h5_path, 'w') as f_out:\n",
    "            # å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ\n",
    "            dset_out = f_out.create_dataset(\n",
    "                '/default',\n",
    "                shape=output_shape,\n",
    "                dtype='uint16',\n",
    "                chunks=(1, new_z, new_y, new_x),\n",
    "                compression='gzip',\n",
    "                compression_opts=1\n",
    "            )\n",
    "            \n",
    "            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¿½åŠ \n",
    "            dset_out.attrs['original_voxel_size_x_um'] = original_voxel_size['x']\n",
    "            dset_out.attrs['original_voxel_size_y_um'] = original_voxel_size['y']\n",
    "            dset_out.attrs['original_voxel_size_z_um'] = original_voxel_size['z']\n",
    "            dset_out.attrs['target_voxel_size_um'] = target_voxel_size\n",
    "            dset_out.attrs['zoom_factor_x'] = zoom_factors['x']\n",
    "            dset_out.attrs['zoom_factor_y'] = zoom_factors['y']\n",
    "            dset_out.attrs['zoom_factor_z'] = zoom_factors['z']\n",
    "            dset_out.attrs['interpolation_method'] = 'linear'\n",
    "            dset_out.attrs['processing_mode'] = 'isotropic_voxel_resampling'\n",
    "            dset_out.attrs['original_shape'] = input_shape\n",
    "            dset_out.attrs['resampled_shape'] = output_shape\n",
    "            \n",
    "            # ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ã§ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–\n",
    "            processed_frames = 0\n",
    "            \n",
    "            for t_start in tqdm(range(0, t_len, chunk_size), \n",
    "                               desc=f\"ğŸ”„ ç­‰æ–¹çš„voxelå¤‰æ› ({'GPU' if GPU_AVAILABLE else 'CPU'})\"):\n",
    "                t_end = min(t_start + chunk_size, t_len)\n",
    "                \n",
    "                try:\n",
    "                    # ãƒãƒ£ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿\n",
    "                    chunk_data = dset_in[t_start:t_end]  # (chunk_size, Z, Y, X)\n",
    "                    \n",
    "                    # å„ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å€‹åˆ¥ã«å‡¦ç†\n",
    "                    for i, t in enumerate(range(t_start, t_end)):\n",
    "                        volume = chunk_data[i]  # (Z, Y, X)\n",
    "                        \n",
    "                        # GPU/CPUå‡¦ç†ã®é¸æŠ\n",
    "                        if GPU_AVAILABLE:\n",
    "                            resampled_volume = process_volume_gpu(volume, zoom_factors)\n",
    "                        else:\n",
    "                            resampled_volume = process_volume_cpu(volume, zoom_factors)\n",
    "                        \n",
    "                        # çµæœä¿å­˜\n",
    "                        dset_out[t] = resampled_volume\n",
    "                        processed_frames += 1\n",
    "                        \n",
    "                        # é€²æ—æƒ…å ±ï¼ˆè©³ç´°ï¼‰\n",
    "                        if processed_frames % 50 == 0:\n",
    "                            elapsed = time.time() - start_time\n",
    "                            fps = processed_frames / elapsed if elapsed > 0 else 0\n",
    "                            remaining = t_len - processed_frames\n",
    "                            eta_minutes = (remaining / fps / 60) if fps > 0 else 0\n",
    "                            \n",
    "                            print(f\"  ğŸ“Š é€²æ—: {processed_frames}/{t_len} ({100*processed_frames/t_len:.1f}%)\")\n",
    "                            print(f\"  ğŸš€ é€Ÿåº¦: {fps:.1f}ãƒ•ãƒ¬ãƒ¼ãƒ /ç§’, ETA: {eta_minutes:.1f}åˆ†\")\n",
    "                    \n",
    "                    # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—\n",
    "                    del chunk_data\n",
    "                    if GPU_AVAILABLE:\n",
    "                        cp.get_default_memory_pool().free_all_blocks()\n",
    "                        \n",
    "                except Exception as chunk_error:\n",
    "                    print(f\"âŒ ãƒãƒ£ãƒ³ã‚¯ t{t_start}-{t_end} å‡¦ç†ã‚¨ãƒ©ãƒ¼: {chunk_error}\")\n",
    "                    continue\n",
    "    \n",
    "    # å‡¦ç†çµæœã‚µãƒãƒªãƒ¼\n",
    "    total_elapsed = time.time() - start_time\n",
    "    average_fps = processed_frames / total_elapsed if total_elapsed > 0 else 0\n",
    "    \n",
    "    print(f\"\\nğŸ‰ ç­‰æ–¹çš„voxelã‚µã‚¤ã‚ºå¤‰æ›å®Œäº†!\")\n",
    "    print(f\"ğŸ“Š å‡¦ç†çµ±è¨ˆ:\")\n",
    "    print(f\"  âœ… å‡¦ç†ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {processed_frames}/{t_len}\")\n",
    "    print(f\"  â±ï¸  ç·å‡¦ç†æ™‚é–“: {total_elapsed/60:.1f}åˆ†\")\n",
    "    print(f\"  ğŸš€ å¹³å‡å‡¦ç†é€Ÿåº¦: {average_fps:.1f}ãƒ•ãƒ¬ãƒ¼ãƒ /ç§’\")\n",
    "    print(f\"  ğŸ“ voxelã‚µã‚¤ã‚ºå¤‰æ›´: {original_voxel_size} â†’ {target_voxel_size}Î¼m (ç­‰æ–¹çš„)\")\n",
    "    print(f\"  ğŸ“ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {output_h5_path}\")\n",
    "    \n",
    "    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºç¢ºèª\n",
    "    if os.path.exists(output_h5_path):\n",
    "        file_size_gb = os.path.getsize(output_h5_path) / (1024**3)\n",
    "        print(f\"  ğŸ’¾ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size_gb:.2f}GB\")\n",
    "    \n",
    "    return processed_frames == t_len\n",
    "\n",
    "# === å®Ÿè¡Œ ===\n",
    "print(\"ğŸ¯ ã‚¹ãƒ”ãƒ‹ãƒ³ã‚°å…±ç„¦ç‚¹ãƒ‡ãƒ¼ã‚¿ã®ç­‰æ–¹çš„voxelã‚µã‚¤ã‚ºå¤‰æ›ã‚’é–‹å§‹...\")\n",
    "print(f\"ğŸ“‚ å…¥åŠ›: {os.path.basename(input_h5_path)}\")\n",
    "print(f\"ğŸ“‚ å‡ºåŠ›: {os.path.basename(output_h5_path)}\")\n",
    "\n",
    "success = create_isotropic_voxel_data()\n",
    "\n",
    "if success:\n",
    "    print(\"\\nâœ… ç­‰æ–¹çš„voxelã‚µã‚¤ã‚ºå¤‰æ›ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼\")\n",
    "    print(\"ğŸ’¡ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:\")\n",
    "    print(\"   1. å¤‰æ›å¾Œãƒ‡ãƒ¼ã‚¿ã®å“è³ªç¢ºèª\")\n",
    "    print(\"   2. å¿…è¦ã«å¿œã˜ã¦ä¸Šä½90%å¹³å‡å€¤ã®å†è¨ˆç®—\")\n",
    "    print(\"   3. è¤ªè‰²è£œæ­£å‡¦ç†ã®å®Ÿè¡Œ\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\")\n",
    "\n",
    "# === æœ€çµ‚ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ— ===\n",
    "if GPU_AVAILABLE:\n",
    "    try:\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "        print(\"ğŸ§¹ GPU ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0fd45e",
   "metadata": {},
   "source": [
    "For spinning disk confocal microscope data. Compute the top 90% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd878e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# GPUå¯ç”¨æ€§ãƒã‚§ãƒƒã‚¯\n",
    "try:\n",
    "    import cupy as cp\n",
    "    GPU_AVAILABLE = True\n",
    "    print(\"ğŸš€ GPUå‡¦ç†ãŒåˆ©ç”¨å¯èƒ½ã§ã™\")\n",
    "    \n",
    "    # GPUæƒ…å ±è¡¨ç¤º\n",
    "    gpu_props = cp.cuda.runtime.getDeviceProperties(0)\n",
    "    gpu_name = gpu_props['name'].decode('utf-8')\n",
    "    total_memory_gb = cp.cuda.Device().mem_info[1] / (1024**3)\n",
    "    print(f\"ğŸ® GPU: {gpu_name}, VRAM: {total_memory_gb:.1f}GB\")\n",
    "    \n",
    "except ImportError:\n",
    "    GPU_AVAILABLE = False\n",
    "    print(\"âš ï¸ CPUå‡¦ç†ã‚’ä½¿ç”¨ã—ã¾ã™\")\n",
    "\n",
    "# === ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ ===\n",
    "h5_path = r\"I:\\20240911_cam2_007_raw\\20240911_cam2_007_raw_affine.h5\"\n",
    "dataset_name = \"/default\"\n",
    "output_csv = os.path.splitext(h5_path)[0] + \"_top90_mean.csv\"\n",
    "\n",
    "# é«˜é€ŸåŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
    "offset_value = 1600\n",
    "exclude_value = -1600\n",
    "chunk_size = 50 if GPU_AVAILABLE else 25  # GPUä½¿ç”¨æ™‚ã¯ã‚ˆã‚Šå¤§ããªãƒãƒ£ãƒ³ã‚¯\n",
    "\n",
    "def process_volume_gpu(vol_chunk, offset_value, exclude_value):\n",
    "    \"\"\"GPUç”¨ã®ãƒœãƒªãƒ¥ãƒ¼ãƒ çµ±è¨ˆå‡¦ç† (T, Z, Y, X)å½¢çŠ¶å¯¾å¿œ\"\"\"\n",
    "    try:\n",
    "        # GPUã«è»¢é€\n",
    "        vol_gpu = cp.asarray(vol_chunk, dtype=cp.float32)\n",
    "        vol_gpu -= offset_value\n",
    "        \n",
    "        # å„çµ±è¨ˆã®è¨ˆç®—\n",
    "        stats = {}\n",
    "        \n",
    "        # -100é™¤å¤–çµ±è¨ˆ\n",
    "        valid_mask = vol_gpu != exclude_value\n",
    "        valid_vals = vol_gpu[valid_mask]\n",
    "        \n",
    "        # ä¸Šä½90%ã®å¹³å‡å€¤\n",
    "        percentiles = [90]\n",
    "        for p in percentiles:\n",
    "            if len(valid_vals) > 0:\n",
    "                thresh = cp.percentile(valid_vals, p)\n",
    "                top_vals = valid_vals[valid_vals >= thresh]\n",
    "                stats[f'top{p}_mean'] = float(cp.mean(top_vals)) if len(top_vals) > 0 else 0.0\n",
    "            else:\n",
    "                stats[f'top{p}_mean'] = 0.0\n",
    "        \n",
    "        # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—\n",
    "        del vol_gpu, valid_vals, top_vals, thresh\n",
    "        \n",
    "        return stats\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ GPUå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "        # CPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯\n",
    "        return process_volume_cpu(vol_chunk, offset_value, exclude_value)\n",
    "\n",
    "def process_volume_cpu(vol_chunk, offset_value, exclude_value):\n",
    "    \"\"\"CPUç”¨ã®ãƒœãƒªãƒ¥ãƒ¼ãƒ çµ±è¨ˆå‡¦ç† (T, Z, Y, X)å½¢çŠ¶å¯¾å¿œ\"\"\"\n",
    "    vol = vol_chunk.astype(np.float32)\n",
    "    vol -= offset_value\n",
    "    \n",
    "    stats = {}\n",
    "    \n",
    "    # -100é™¤å¤–çµ±è¨ˆï¼ˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼‰\n",
    "    valid_mask = vol != exclude_value\n",
    "    if np.any(valid_mask):\n",
    "        valid_vals = vol[valid_mask]\n",
    "        \n",
    "        # ä¸Šä½90%ã®å¹³å‡å€¤\n",
    "        percentiles = [90]\n",
    "        for p in percentiles:\n",
    "            thresh = np.percentile(valid_vals, p)\n",
    "            top_vals = valid_vals[valid_vals >= thresh]\n",
    "            stats[f'top{p}_mean'] = float(np.mean(top_vals)) if len(top_vals) > 0 else 0.0\n",
    "    else:\n",
    "        stats['top90_mean'] = 0.0\n",
    "    \n",
    "    return stats\n",
    "\n",
    "def process_statistics_optimized():\n",
    "    \"\"\"æœ€é©åŒ–ã•ã‚ŒãŸçµ±è¨ˆå‡¦ç†ï¼ˆãƒãƒ£ãƒ³ã‚¯+GPU/CPUï¼‰- (T, Z, Y, X)å½¢çŠ¶å¯¾å¿œ\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    with h5py.File(h5_path, \"r\") as f:\n",
    "        dset = f[dataset_name]\n",
    "        t_len, z_len, y_len, x_len = dset.shape  # (T, Z, Y, X)\n",
    "        print(f\"ğŸ“ Dataset shape: {dset.shape} (T, Z, Y, X)\")\n",
    "        print(f\"ğŸš€ å‡¦ç†ãƒ¢ãƒ¼ãƒ‰: {'GPU' if GPU_AVAILABLE else 'CPU'}\")\n",
    "        print(f\"ğŸ“¦ ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º: {chunk_size}\")\n",
    "        \n",
    "        # çµæœè¾æ›¸ã®åˆæœŸåŒ–ï¼ˆãƒãƒ£ãƒ³ãƒãƒ«ãªã—ï¼‰\n",
    "        result = {\"frame\": list(range(t_len))}\n",
    "        result[\"top90_mean\"] = []\n",
    "        \n",
    "        # ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ã§ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–\n",
    "        for t_start in tqdm(range(0, t_len, chunk_size), desc=\"ğŸ¯ çµ±è¨ˆè¨ˆç®—å‡¦ç†\"):\n",
    "            t_end = min(t_start + chunk_size, t_len)\n",
    "            \n",
    "            # è¤‡æ•°ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä¸€æ‹¬èª­ã¿è¾¼ã¿ (chunk_size, Z, Y, X)\n",
    "            chunk_data = dset[t_start:t_end]\n",
    "            \n",
    "            for i, t in enumerate(range(t_start, t_end)):\n",
    "                vol_chunk = chunk_data[i]  # shape: (Z, Y, X)\n",
    "                \n",
    "                # GPU/CPUå‡¦ç†ã®é¸æŠ\n",
    "                if GPU_AVAILABLE:\n",
    "                    stats = process_volume_gpu(vol_chunk, offset_value, exclude_value)\n",
    "                else:\n",
    "                    stats = process_volume_cpu(vol_chunk, offset_value, exclude_value)\n",
    "                \n",
    "                # çµæœã®è“„ç©\n",
    "                result[\"top90_mean\"].append(stats['top90_mean'])\n",
    "            \n",
    "            # é€²æ—æƒ…å ±è¡¨ç¤º\n",
    "            if t_start % (chunk_size * 10) == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                processed = t_end\n",
    "                fps = processed / elapsed if elapsed > 0 else 0\n",
    "                remaining = t_len - processed\n",
    "                eta_minutes = (remaining / fps / 60) if fps > 0 else 0\n",
    "                \n",
    "                print(f\"  ğŸ“Š é€²æ—: {processed}/{t_len} ({100*processed/t_len:.1f}%)\")\n",
    "                print(f\"  ğŸš€ é€Ÿåº¦: {fps:.1f}ãƒ•ãƒ¬ãƒ¼ãƒ /ç§’, ETA: {eta_minutes:.1f}åˆ†\")\n",
    "            \n",
    "            # GPUãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—\n",
    "            if GPU_AVAILABLE:\n",
    "                try:\n",
    "                    cp.get_default_memory_pool().free_all_blocks()\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    # å‡¦ç†çµæœã‚µãƒãƒªãƒ¼\n",
    "    total_elapsed = time.time() - start_time\n",
    "    average_fps = t_len / total_elapsed if total_elapsed > 0 else 0\n",
    "    \n",
    "    print(f\"\\nğŸ‰ çµ±è¨ˆè¨ˆç®—å®Œäº†!\")\n",
    "    print(f\"ğŸ“Š å‡¦ç†ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {t_len}\")\n",
    "    print(f\"ğŸ”„ ãƒãƒ£ãƒ³ãƒãƒ«æ•°: 1 (å˜ä¸€ãƒãƒ£ãƒ³ãƒãƒ«)\")\n",
    "    print(f\"â±ï¸ ç·å‡¦ç†æ™‚é–“: {total_elapsed:.1f}ç§’ ({total_elapsed/60:.1f}åˆ†)\")\n",
    "    print(f\"ğŸš€ å¹³å‡å‡¦ç†é€Ÿåº¦: {average_fps:.1f}ãƒ•ãƒ¬ãƒ¼ãƒ /ç§’\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# === æœ€é©åŒ–å‡¦ç†å®Ÿè¡Œ ===\n",
    "print(\"ğŸ¯ æœ€é©åŒ–ã•ã‚ŒãŸçµ±è¨ˆè¨ˆç®—ã‚’é–‹å§‹...\")\n",
    "print(f\"ğŸ“ å‡¦ç†å¯¾è±¡: {os.path.basename(h5_path)}\")\n",
    "result = process_statistics_optimized()\n",
    "\n",
    "# === ä¿å­˜å‡¦ç† ===\n",
    "print(\"ğŸ’¾ CSVä¿å­˜ä¸­...\")\n",
    "df = pd.DataFrame(result)\n",
    "\n",
    "try:\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"âœ… æœ€é©åŒ–çµ±è¨ˆå‡¦ç†å®Œäº†: {output_csv}\")\n",
    "    print(f\"ğŸ“ˆ å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {df.shape}\")\n",
    "    \n",
    "    # ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º\n",
    "    print(\"\\nğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«:\")\n",
    "    print(df.head())\n",
    "    \n",
    "except PermissionError:\n",
    "    print(\"âŒ æ›¸ãè¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ«ãŒé–‹ã‹ã‚Œã¦ã„ã‚‹ã‹ã€æ›¸ãè¾¼ã¿æ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“:\")\n",
    "    print(\"ğŸ”’ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‰ã˜ã¦ã„ã‚‹ã‹ã€åˆ¥ã®ä¿å­˜å…ˆã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚\")\n",
    "    print(\"ğŸ“„ è©¦è¡Œã—ãŸå‡ºåŠ›å…ˆ:\", output_csv)\n",
    "    \n",
    "    # ä»£æ›¿ä¿å­˜å…ˆã®ææ¡ˆ\n",
    "    alternative_path = output_csv.replace(\".csv\", f\"_backup_{int(time.time())}.csv\")\n",
    "    try:\n",
    "        df.to_csv(alternative_path, index=False)\n",
    "        print(f\"âœ… ä»£æ›¿ãƒ‘ã‚¹ã«ä¿å­˜å®Œäº†: {alternative_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ä»£æ›¿ä¿å­˜ã‚‚å¤±æ•—: {e}\")\n",
    "\n",
    "# === ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ— ===\n",
    "try:\n",
    "    del result, df\n",
    "    if GPU_AVAILABLE:\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "    print(\"ğŸ§¹ ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cfdb77",
   "metadata": {},
   "source": [
    "For spinning disk confocal microscope data. Bleach correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b86a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import time\n",
    "import cupy as cp\n",
    "from scipy.signal import savgol_filter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ ===\n",
    "calc_method = \"_top90_mean\"  # ä½¿ç”¨ã™ã‚‹åˆ—ã®ãƒ¡ã‚½ãƒƒãƒ‰\n",
    "csv_path = r\"I:\\20240911_cam2_007_raw\\20240911_cam2_007_raw_top90_mean.csv\"\n",
    "h5_input_path = r\"I:\\20240911_cam2_007_raw\\20240911_cam2_007_raw_affine.h5\"\n",
    "h5_output_path = fr\"I:\\20240911_cam2_007_raw\\20240911_cam2_007_raw_bleachcorrect{calc_method}_affine.h5\"\n",
    "offset_value = 1600\n",
    "scale_margin = 1.2\n",
    "chunk_size = 60  # ãƒ¡ãƒ¢ãƒªãƒ¼ã‚µã‚¤ã‚ºã«å¿œã˜ã¦è¨­å®š\n",
    "\n",
    "# === è¤ªè‰²é–¢æ•°å®šç¾© ===\n",
    "def double_exp(t, a, b, c, d):\n",
    "    return a * np.exp(-b * t) + c * np.exp(-d * t)\n",
    "\n",
    "# === å˜ä¸€ãƒãƒ£ãƒ³ãƒãƒ«è¤ªè‰²ã‚«ãƒ¼ãƒ–æ¨å®š ===\n",
    "def estimate_bleach_curves():\n",
    "    \"\"\"å˜ä¸€ãƒãƒ£ãƒ³ãƒãƒ«ã®è¤ªè‰²ã‚«ãƒ¼ãƒ–ã‚’æ¨å®š\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    t = np.arange(len(df))\n",
    "    \n",
    "    bleach_params = {}\n",
    "    scale_factors = {}\n",
    "    \n",
    "    # å˜ä¸€ãƒãƒ£ãƒ³ãƒãƒ«åˆ—ã®æ¤œå‡º\n",
    "    column_name = \"top90_mean\"  # (T, Z, Y, X)å½¢çŠ¶ã§ã¯å˜ä¸€ãƒãƒ£ãƒ³ãƒãƒ«\n",
    "    \n",
    "    if column_name not in df.columns:\n",
    "        print(f\"âŒ åˆ— '{column_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\")\n",
    "        return None\n",
    "        \n",
    "    print(f\"\\n--- å˜ä¸€ãƒãƒ£ãƒ³ãƒãƒ«è¤ªè‰²ã‚«ãƒ¼ãƒ–æ¨å®š ---\")\n",
    "    \n",
    "    y_raw = df[column_name].to_numpy()\n",
    "    # SGãƒ•ã‚£ãƒ«ã‚¿é©ç”¨ï¼ˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º13, å¤šé …å¼æ¬¡æ•°1ï¼‰\n",
    "    y_smooth = savgol_filter(y_raw, window_length=13, polyorder=1, mode='interp')\n",
    "    \n",
    "    # åˆæœŸå€¤ã¨ä¸Šé™ã®æ¨å®š\n",
    "    a0 = c0 = y_smooth[0] / 2\n",
    "    p0 = [a0, 0.01, c0, 0.001]\n",
    "    y_max = np.nanmax(y_smooth)\n",
    "    upper_limit = y_max * scale_margin\n",
    "    bounds = ([0, 0, 0, 0], [upper_limit, 1, upper_limit, 1])\n",
    "    \n",
    "    try:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            popt, _ = curve_fit(double_exp, t, y_smooth, p0=p0, bounds=bounds, maxfev=10000)\n",
    "        \n",
    "        fitted = double_exp(t, *popt)\n",
    "        scale = double_exp(0, *popt) / fitted  # t=0ã§æ­£è¦åŒ–\n",
    "        \n",
    "        bleach_params[0] = popt  # ãƒãƒ£ãƒ³ãƒãƒ«0ã¨ã—ã¦ä¿å­˜\n",
    "        scale_factors[0] = scale\n",
    "        \n",
    "        # ãƒ—ãƒ­ãƒƒãƒˆä½œæˆãƒ»ä¿å­˜ï¼ˆå˜ä¸€ãƒãƒ£ãƒ³ãƒãƒ«ï¼‰\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "        \n",
    "        fit = double_exp(t, *popt)\n",
    "        corrected = y_raw * scale\n",
    "        \n",
    "        ax.plot(t, y_raw, 'o', label='Raw Data', markersize=2, alpha=0.7)\n",
    "        ax.plot(t, fit, '-', label='Fitted Curve', linewidth=2, color='red')\n",
    "        ax.plot(t, corrected, '--', label='Corrected Data', linewidth=2, color='green')\n",
    "        ax.set_title('Single Channel Bleach Curve')\n",
    "        ax.set_xlabel('Time (frames)')\n",
    "        ax.set_ylabel('Intensity')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'bleach_curve_single_channel{calc_method}.png', dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"âœ… è¤ªè‰²è£œæ­£ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°å®Œäº†: a={popt[0]:.2f}, b={popt[1]:.4f}, c={popt[2]:.2f}, d={popt[3]:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°å¤±æ•—: {e}\")\n",
    "        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚¹ã‚±ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼=1ï¼ˆè£œæ­£ãªã—ï¼‰\n",
    "        scale_factors[0] = np.ones_like(t)\n",
    "    \n",
    "    return scale_factors\n",
    "\n",
    "# è¤ªè‰²ã‚«ãƒ¼ãƒ–æ¨å®šå®Ÿè¡Œ\n",
    "scale_factors_all = estimate_bleach_curves()\n",
    "if scale_factors_all:\n",
    "    print(\"\\nâœ… è¤ªè‰²ã‚«ãƒ¼ãƒ–æ¨å®šå®Œäº†\")\n",
    "else:\n",
    "    print(\"\\nâŒ è¤ªè‰²ã‚«ãƒ¼ãƒ–æ¨å®šã«å¤±æ•—ã—ã¾ã—ãŸ\")\n",
    "\n",
    "# GPUç‰ˆï¼ˆå˜ä¸€ãƒãƒ£ãƒ³ãƒãƒ«å¯¾å¿œï¼‰\n",
    "try:\n",
    "    GPU_AVAILABLE = True\n",
    "    print(\"ğŸš€ GPUå‡¦ç†ãŒåˆ©ç”¨å¯èƒ½ã§ã™\")\n",
    "    \n",
    "    # GPUæƒ…å ±è¡¨ç¤º\n",
    "    gpu_props = cp.cuda.runtime.getDeviceProperties(0)\n",
    "    gpu_name = gpu_props['name'].decode('utf-8')\n",
    "    total_memory_gb = cp.cuda.Device().mem_info[1] / (1024**3)\n",
    "    print(f\"ğŸ® GPU: {gpu_name}\")\n",
    "    print(f\"ğŸ’¾ VRAM: {total_memory_gb:.1f}GB\")\n",
    "    \n",
    "except ImportError:\n",
    "    GPU_AVAILABLE = False\n",
    "    print(\"âš ï¸ CuPyãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚CPUå‡¦ç†ã‚’ä½¿ç”¨ã—ã¾ã™\")\n",
    "\n",
    "def process_with_gpu_single_channel():\n",
    "    \"\"\"å˜ä¸€ãƒãƒ£ãƒ³ãƒãƒ«è¤ªè‰²è£œæ­£GPUå‡¦ç†ï¼ˆ(T, Z, Y, X)å½¢çŠ¶å¯¾å¿œï¼‰\"\"\"\n",
    "    if not GPU_AVAILABLE:\n",
    "        print(\"âŒ GPUå‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™\")\n",
    "        return\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    with h5py.File(h5_input_path, \"r\") as f_in, h5py.File(h5_output_path, \"w\") as f_out:\n",
    "        dset_in = f_in[\"/default\"]\n",
    "        T_full, Z, Y, X = dset_in.shape  # (T, Z, Y, X)\n",
    "        \n",
    "        print(f\"ğŸ“ ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (T={T_full}, Z={Z}, Y={Y}, X={X})\")\n",
    "        print(f\"ğŸ¯ å‡¦ç†å¯¾è±¡: å…¨ãƒœãƒªãƒ¥ãƒ¼ãƒ ï¼ˆ{T_full}ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰\")\n",
    "        \n",
    "        # å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆï¼ˆå…¨ãƒœãƒªãƒ¥ãƒ¼ãƒ ï¼‰\n",
    "        dset_out = f_out.create_dataset(\n",
    "            \"/default\", \n",
    "            shape=(T_full, Z, Y, X),  # å˜ä¸€ãƒãƒ£ãƒ³ãƒãƒ«\n",
    "            dtype='uint16',\n",
    "            chunks=(min(chunk_size//4, 20), Z, Y, X),\n",
    "            compression=\"gzip\",\n",
    "            compression_opts=1\n",
    "        )\n",
    "        \n",
    "        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¿½åŠ \n",
    "        dset_out.attrs['processing_mode'] = 'single_channel_bleach_correction_full'\n",
    "        dset_out.attrs['chunk_size'] = chunk_size\n",
    "        dset_out.attrs['offset_value'] = offset_value\n",
    "        dset_out.attrs['processed_frames'] = T_full\n",
    "        dset_out.attrs['frame_range'] = f\"0-{T_full-1}\"\n",
    "        \n",
    "        # ã‚¹ã‚±ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ã®æº–å‚™\n",
    "        if 0 in scale_factors_all:\n",
    "            scale_factors_gpu = cp.asarray(scale_factors_all[0], dtype=cp.float32)\n",
    "            print(f\"âœ… GPUç”¨ã‚¹ã‚±ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼æº–å‚™å®Œäº†ï¼ˆ{T_full}ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰\")\n",
    "        else:\n",
    "            scale_factors_gpu = cp.ones(T_full, dtype=cp.float32)\n",
    "            print(f\"âš ï¸ ã‚¹ã‚±ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ãªã—ï¼ˆè£œæ­£ã‚¹ã‚­ãƒƒãƒ—ï¼‰\")\n",
    "        \n",
    "        # ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—ï¼ˆå…¨ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰\n",
    "        for t_start in tqdm(range(0, T_full, chunk_size), desc=\"ğŸ® GPUå˜ä¸€ãƒãƒ£ãƒ³ãƒãƒ«è¤ªè‰²è£œæ­£ï¼ˆå…¨ãƒœãƒªãƒ¥ãƒ¼ãƒ ï¼‰\"):\n",
    "            t_end = min(t_start + chunk_size, T_full)\n",
    "            current_chunk_size = t_end - t_start\n",
    "            \n",
    "            try:\n",
    "                # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç›£è¦–\n",
    "                memory_before = cp.cuda.Device().mem_info[0] / (1024**3)\n",
    "                \n",
    "                # CPUã‹ã‚‰GPUã¸ãƒ‡ãƒ¼ã‚¿è»¢é€\n",
    "                vol_chunk = cp.asarray(\n",
    "                    dset_in[t_start:t_end, :, :, :],  # (chunk_size, Z, Y, X)\n",
    "                    dtype=cp.float32\n",
    "                )\n",
    "                \n",
    "                # ã‚¹ã‚±ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼å–å¾—\n",
    "                scale_chunk = scale_factors_gpu[t_start:t_end]\n",
    "                \n",
    "                # GPUä¸Šã§ãƒ™ã‚¯ãƒˆãƒ«åŒ–å‡¦ç†\n",
    "                vol_chunk -= offset_value  # ã‚ªãƒ•ã‚»ãƒƒãƒˆæ¸›ç®—\n",
    "                vol_chunk *= scale_chunk.reshape(-1, 1, 1, 1)  # è¤ªè‰²è£œæ­£\n",
    "                vol_chunk = cp.clip(vol_chunk, 0, 65535)  # ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°\n",
    "                \n",
    "                # å‹å¤‰æ›ã¨çµæœä¿å­˜\n",
    "                vol_chunk = vol_chunk.astype(cp.uint16)\n",
    "                result = cp.asnumpy(vol_chunk)\n",
    "                dset_out[t_start:t_end, :, :, :] = result\n",
    "                \n",
    "                # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—\n",
    "                del vol_chunk, result\n",
    "                cp.cuda.Stream.null.synchronize()\n",
    "                \n",
    "                # é€²æ—æƒ…å ±è¡¨ç¤º\n",
    "                if t_start % (chunk_size * 5) == 0:\n",
    "                    elapsed = time.time() - start_time\n",
    "                    processed_frames = t_end\n",
    "                    fps = processed_frames / elapsed if elapsed > 0 else 0\n",
    "                    remaining_frames = T_full - processed_frames\n",
    "                    eta_minutes = (remaining_frames / fps / 60) if fps > 0 else 0\n",
    "                    \n",
    "                    print(f\"  ğŸ“Š é€²æ—: {processed_frames}/{T_full} ({100*processed_frames/T_full:.1f}%)\")\n",
    "                    print(f\"  ğŸš€ é€Ÿåº¦: {fps:.1f}fps, VRAM: {memory_before:.1f}GB, ETA: {eta_minutes:.1f}åˆ†\")\n",
    "                    \n",
    "            except cp.cuda.memory.OutOfMemoryError:\n",
    "                print(f\"ğŸ’¥ GPU ãƒ¡ãƒ¢ãƒªä¸è¶³ (chunk_size={chunk_size})\")\n",
    "                cp.get_default_memory_pool().free_all_blocks()\n",
    "                continue\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ å‡¦ç†ã‚¨ãƒ©ãƒ¼ (t={t_start}-{t_end}): {e}\")\n",
    "                continue\n",
    "    \n",
    "    # æœ€çµ‚ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—\n",
    "    try:\n",
    "        del scale_factors_gpu\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "        \n",
    "    except Exception as cleanup_error:\n",
    "        print(f\"âš ï¸ ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {cleanup_error}\")\n",
    "        try:\n",
    "            cp.get_default_memory_pool().free_all_blocks()\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # å‡¦ç†çµæœã‚µãƒãƒªãƒ¼\n",
    "    total_elapsed = time.time() - start_time\n",
    "    average_fps = T_full / total_elapsed if total_elapsed > 0 else 0\n",
    "    \n",
    "    print(f\"\\nğŸ‰ å…¨ãƒœãƒªãƒ¥ãƒ¼ãƒ å˜ä¸€ãƒãƒ£ãƒ³ãƒãƒ«è¤ªè‰²è£œæ­£GPUå‡¦ç†å®Œäº†!\")\n",
    "    print(f\"ğŸ“Š å‡¦ç†ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {T_full}\")\n",
    "    print(f\"ğŸ”„ ãƒãƒ£ãƒ³ãƒãƒ«æ•°: 1 (å˜ä¸€ãƒãƒ£ãƒ³ãƒãƒ«)\")\n",
    "    print(f\"â±ï¸  ç·å‡¦ç†æ™‚é–“: {total_elapsed/60:.1f}åˆ†\")\n",
    "    print(f\"ğŸš€ å¹³å‡å‡¦ç†é€Ÿåº¦: {average_fps:.1f}ãƒ•ãƒ¬ãƒ¼ãƒ /ç§’\")\n",
    "    print(f\"ğŸ’¾ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {h5_output_path}\")\n",
    "\n",
    "# === å®Ÿè¡Œ ===\n",
    "if GPU_AVAILABLE and scale_factors_all:\n",
    "    print(\"ğŸ¯ å˜ä¸€ãƒãƒ£ãƒ³ãƒãƒ«è¤ªè‰²è£œæ­£GPUå‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™ï¼ˆå…¨ãƒœãƒªãƒ¥ãƒ¼ãƒ ï¼‰...\")\n",
    "    process_with_gpu_single_channel()\n",
    "else:\n",
    "    print(\"âš ï¸ GPUå‡¦ç†ã¾ãŸã¯ã‚¹ã‚±ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“\")\n",
    "    print(f\"GPUåˆ©ç”¨å¯èƒ½: {GPU_AVAILABLE}\")\n",
    "    print(f\"ã‚¹ã‚±ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼: {list(scale_factors_all.keys()) if scale_factors_all else 'ãªã—'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eecd143",
   "metadata": {},
   "source": [
    "Create MIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42ec2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(f\"ç¾åœ¨ã®æ™‚åˆ»ã¯ {time.strftime('%Y-%m-%d %H:%M:%S')} ã§ã™ã€‚\")\n",
    "\n",
    "# GPUå¯ç”¨æ€§ãƒã‚§ãƒƒã‚¯\n",
    "try:\n",
    "    import cupy as cp\n",
    "    GPU_AVAILABLE = True\n",
    "    print(\"ğŸš€ GPUå‡¦ç†ãŒåˆ©ç”¨å¯èƒ½ã§ã™\")\n",
    "    \n",
    "    # GPUæƒ…å ±è¡¨ç¤º\n",
    "    gpu_props = cp.cuda.runtime.getDeviceProperties(0)\n",
    "    gpu_name = gpu_props['name'].decode('utf-8')\n",
    "    total_memory_gb = cp.cuda.Device().mem_info[1] / (1024**3)\n",
    "    print(f\"ğŸ® GPU: {gpu_name}\")\n",
    "    print(f\"ğŸ’¾ VRAM: {total_memory_gb:.1f}GB\")\n",
    "    \n",
    "except ImportError:\n",
    "    GPU_AVAILABLE = False\n",
    "    print(\"âš ï¸ CPUå‡¦ç†ã‚’ä½¿ç”¨ã—ã¾ã™\")\n",
    "\n",
    "# === ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ ===\n",
    "calc_method = \"_top90_mean\"  # ä½¿ç”¨ã™ã‚‹åˆ—ã®ãƒ¡ã‚½ãƒƒãƒ‰\n",
    "hdf5_file = fr\"I:\\20240911_cam2_007_raw\\20240911_cam2_007_raw_bleachcorrect{calc_method}_affine.h5\"\n",
    "output_path = r\"I:\\20240911_cam2_007_raw\\orthogonal_views\"\n",
    "dirname = os.path.splitext(os.path.basename(hdf5_file))[0]\n",
    "chunk_size = 100 if GPU_AVAILABLE else 50  # GPUä½¿ç”¨æ™‚ã¯ã‚ˆã‚Šå¤§ããªãƒãƒ£ãƒ³ã‚¯\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "# === HDF5ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±å–å¾— ===\n",
    "with h5py.File(hdf5_file, 'r') as file:\n",
    "    array = file['default']\n",
    "    total_volumes, z, y, x = array.shape  # (T, Z, Y, X) - å˜ä¸€ãƒãƒ£ãƒ³ãƒãƒ«\n",
    "    print(f\"ğŸ“ ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (T={total_volumes}, Z={z}, Y={y}, X={x})\")\n",
    "    print(f\"ğŸ¯ å‡¦ç†å¯¾è±¡: å…¨ãƒœãƒªãƒ¥ãƒ¼ãƒ ï¼ˆ{total_volumes}ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰\")\n",
    "\n",
    "# === å‡ºåŠ›é…åˆ—ã®æº–å‚™ï¼ˆå…¨ãƒœãƒªãƒ¥ãƒ¼ãƒ ãƒ»å˜ä¸€ãƒãƒ£ãƒ³ãƒãƒ«ï¼‰ ===\n",
    "orthogonal_view = np.zeros((total_volumes, y + z + 3, x + z + 3), dtype='uint16')  # ãƒãƒ£ãƒ³ãƒãƒ«æ¬¡å…ƒå‰Šé™¤\n",
    "\n",
    "def process_cpu_chunk(chunk_data, t_start, t_end):\n",
    "    \"\"\"CPUå‡¦ç†ç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ï¼ˆå˜ä¸€ãƒãƒ£ãƒ³ãƒãƒ«å¯¾å¿œï¼‰\"\"\"\n",
    "    for i, t in enumerate(range(t_start, t_end)):\n",
    "        data = chunk_data[i]  # (Z, Y, X) - ãƒãƒ£ãƒ³ãƒãƒ«ãƒ«ãƒ¼ãƒ—å‰Šé™¤\n",
    "        \n",
    "        # CPUä¸Šã§æœ€å¤§æŠ•å½±\n",
    "        xy_proj = np.max(data, axis=0)  # (Y, X)\n",
    "        yz_proj = np.max(data, axis=2).T  # (Z, Y)\n",
    "        xz_proj = np.max(data, axis=1)  # (Z, X)\n",
    "        \n",
    "        # ç›´äº¤ãƒ“ãƒ¥ãƒ¼ã¸ã®é…ç½®ï¼ˆãƒãƒ£ãƒ³ãƒãƒ«æ¬¡å…ƒãªã—ï¼‰\n",
    "        orthogonal_view[t, 0:y, 0:x] = xy_proj\n",
    "        orthogonal_view[t, 0:y, x+3:x+z+3] = yz_proj\n",
    "        orthogonal_view[t, y+3:y+z+3, 0:x] = xz_proj\n",
    "        orthogonal_view[t, y+z+2, x+z+2] = 1000\n",
    "\n",
    "def process_orthogonal_projections():\n",
    "    \"\"\"ç›´äº¤æŠ•å½±å‡¦ç†ï¼ˆCPU/GPUè‡ªå‹•é¸æŠãƒ»å…¨ãƒœãƒªãƒ¥ãƒ¼ãƒ ãƒ»å˜ä¸€ãƒãƒ£ãƒ³ãƒãƒ«ï¼‰\"\"\"\n",
    "    use_gpu = GPU_AVAILABLE  # ãƒ­ãƒ¼ã‚«ãƒ«å¤‰æ•°ã¨ã—ã¦å‡¦ç†çŠ¶æ…‹ã‚’ç®¡ç†\n",
    "    \n",
    "    with h5py.File(hdf5_file, 'r') as file:\n",
    "        array = file['default']\n",
    "        \n",
    "        for t_start in tqdm(range(0, total_volumes, chunk_size), \n",
    "                           desc=\"ğŸ® GPUç›´äº¤æŠ•å½±ï¼ˆå…¨ãƒœãƒªãƒ¥ãƒ¼ãƒ ãƒ»å˜ä¸€ãƒãƒ£ãƒ³ãƒãƒ«ï¼‰\" if use_gpu else \"ğŸ–¥ï¸ CPUç›´äº¤æŠ•å½±ï¼ˆå…¨ãƒœãƒªãƒ¥ãƒ¼ãƒ ãƒ»å˜ä¸€ãƒãƒ£ãƒ³ãƒãƒ«ï¼‰\"):\n",
    "            t_end = min(t_start + chunk_size, total_volumes)\n",
    "            \n",
    "            # ãƒãƒ£ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿\n",
    "            chunk_data = array[t_start:t_end]  # (chunk_size, Z, Y, X)\n",
    "            \n",
    "            if use_gpu:\n",
    "                # GPUå‡¦ç†ã‚’è©¦è¡Œ\n",
    "                try:\n",
    "                    chunk_gpu = cp.asarray(chunk_data)\n",
    "                    \n",
    "                    for i, t in enumerate(range(t_start, t_end)):\n",
    "                        data_gpu = chunk_gpu[i]  # (Z, Y, X) - ãƒãƒ£ãƒ³ãƒãƒ«ãƒ«ãƒ¼ãƒ—å‰Šé™¤\n",
    "                        \n",
    "                        # GPUä¸Šã§æœ€å¤§æŠ•å½±\n",
    "                        xy_proj = cp.max(data_gpu, axis=0)  # (Y, X)\n",
    "                        yz_proj = cp.max(data_gpu, axis=2).T  # (Z, Y)\n",
    "                        xz_proj = cp.max(data_gpu, axis=1)  # (Z, X)\n",
    "                        \n",
    "                        # CPUå´ã«çµæœã‚’ã‚³ãƒ”ãƒ¼ï¼ˆãƒãƒ£ãƒ³ãƒãƒ«æ¬¡å…ƒãªã—ï¼‰\n",
    "                        orthogonal_view[t, 0:y, 0:x] = cp.asnumpy(xy_proj)\n",
    "                        orthogonal_view[t, 0:y, x+3:x+z+3] = cp.asnumpy(yz_proj)\n",
    "                        orthogonal_view[t, y+3:y+z+3, 0:x] = cp.asnumpy(xz_proj)\n",
    "                        orthogonal_view[t, y+z+2, x+z+2] = 1000\n",
    "                    \n",
    "                    # GPUãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—\n",
    "                    del chunk_gpu\n",
    "                    cp.get_default_memory_pool().free_all_blocks()\n",
    "                    \n",
    "                    # é€²æ—æƒ…å ±è¡¨ç¤ºï¼ˆGPUå‡¦ç†ï¼‰\n",
    "                    if t_start % (chunk_size * 5) == 0:\n",
    "                        processed = t_end\n",
    "                        remaining = total_volumes - processed\n",
    "                        progress_pct = 100 * processed / total_volumes\n",
    "                        print(f\"  ğŸ“Š GPUé€²æ—: {processed}/{total_volumes} ({progress_pct:.1f}%)\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"âš ï¸ GPUå‡¦ç†ã‚¨ãƒ©ãƒ¼ã€CPUã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: {e}\")\n",
    "                    use_gpu = False  # ä»Šå¾Œã®ãƒãƒ£ãƒ³ã‚¯ã¯CPUå‡¦ç†\n",
    "                    # CPUå‡¦ç†ã§å†è©¦è¡Œ\n",
    "                    process_cpu_chunk(chunk_data, t_start, t_end)\n",
    "                    \n",
    "            else:\n",
    "                # CPUå‡¦ç†\n",
    "                process_cpu_chunk(chunk_data, t_start, t_end)\n",
    "                \n",
    "                # é€²æ—æƒ…å ±è¡¨ç¤ºï¼ˆCPUå‡¦ç†ï¼‰\n",
    "                if t_start % (chunk_size * 2) == 0:\n",
    "                    processed = t_end\n",
    "                    progress_pct = 100 * processed / total_volumes\n",
    "                    print(f\"  ğŸ“Š CPUé€²æ—: {processed}/{total_volumes} ({progress_pct:.1f}%)\")\n",
    "\n",
    "# === å‡¦ç†å®Ÿè¡Œ ===\n",
    "print(f\"ğŸ¯ å…¨ãƒœãƒªãƒ¥ãƒ¼ãƒ ï¼ˆ{total_volumes}ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰ã®å˜ä¸€ãƒãƒ£ãƒ³ãƒãƒ«ç›´äº¤æŠ•å½±å‡¦ç†ã‚’é–‹å§‹...\")\n",
    "process_orthogonal_projections()\n",
    "print(\"ğŸ‰ ç›´äº¤æŠ•å½±å‡¦ç†å®Œäº†!\")\n",
    "\n",
    "# === TIFFä¿å­˜ï¼ˆå…¨ãƒœãƒªãƒ¥ãƒ¼ãƒ ãƒ»å˜ä¸€ãƒãƒ£ãƒ³ãƒãƒ«ï¼‰ ===\n",
    "file_name = f\"orthogonal_view_{dirname}_full_affine.tif\"\n",
    "output_path2 = os.path.join(output_path, file_name)\n",
    "\n",
    "print(\"ğŸ’¾ TIFFä¿å­˜ä¸­...\")\n",
    "print(f\"ğŸ“ ä¿å­˜å…ˆ: {output_path2}\")\n",
    "print(f\"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {orthogonal_view.nbytes / (1024**3):.2f}GB\")\n",
    "\n",
    "try:\n",
    "    tiff.imwrite(\n",
    "        output_path2, \n",
    "        orthogonal_view, \n",
    "        imagej=True, \n",
    "        metadata={'axes': 'TYX'},  # ãƒãƒ£ãƒ³ãƒãƒ«æ¬¡å…ƒå‰Šé™¤\n",
    "        compression='zlib'\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… å…¨ãƒœãƒªãƒ¥ãƒ¼ãƒ å‡¦ç†å®Œäº†: {output_path2}\")\n",
    "    print(f\"ğŸ“ˆ å‡ºåŠ›å½¢çŠ¶: {orthogonal_view.shape}\")\n",
    "    print(f\"ğŸ“Š å‡¦ç†çµ±è¨ˆ: {total_volumes}/{total_volumes}ãƒœãƒªãƒ¥ãƒ¼ãƒ  (100%)\")\n",
    "    \n",
    "except Exception as save_error:\n",
    "    print(f\"âŒ TIFFä¿å­˜ã‚¨ãƒ©ãƒ¼: {save_error}\")\n",
    "    print(\"ğŸ’¡ ãƒ¡ãƒ¢ãƒªä¸è¶³ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ãƒãƒ£ãƒ³ã‚¯ä¿å­˜ã‚’è©¦ã—ã¾ã™...\")\n",
    "    \n",
    "    # === ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒãƒ£ãƒ³ã‚¯ä¿å­˜ ===\n",
    "    save_chunk_size = 500  # 500ãƒ•ãƒ¬ãƒ¼ãƒ ãšã¤ä¿å­˜\n",
    "    \n",
    "    for save_start in tqdm(range(0, total_volumes, save_chunk_size), desc=\"ğŸ“¦ ãƒãƒ£ãƒ³ã‚¯ä¿å­˜\"):\n",
    "        save_end = min(save_start + save_chunk_size, total_volumes)\n",
    "        chunk_name = f\"orthogonal_view_{dirname}_part{save_start:05d}-{save_end:05d}.tif\"\n",
    "        chunk_path = os.path.join(output_path, chunk_name)\n",
    "        \n",
    "        chunk_data = orthogonal_view[save_start:save_end]\n",
    "        tiff.imwrite(\n",
    "            chunk_path,\n",
    "            chunk_data,\n",
    "            imagej=True,\n",
    "            metadata={'axes': 'TYX'},  # ãƒãƒ£ãƒ³ãƒãƒ«æ¬¡å…ƒå‰Šé™¤\n",
    "            compression='zlib'\n",
    "        )\n",
    "        print(f\"âœ… ä¿å­˜å®Œäº†: {chunk_name}\")\n",
    "    \n",
    "    print(f\"ğŸ“¦ ãƒãƒ£ãƒ³ã‚¯ä¿å­˜å®Œäº†: {output_path}\")\n",
    "\n",
    "# === ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ— ===\n",
    "try:\n",
    "    del orthogonal_view\n",
    "    if GPU_AVAILABLE:\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "    print(\"ğŸ§¹ ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†\")\n",
    "except:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
