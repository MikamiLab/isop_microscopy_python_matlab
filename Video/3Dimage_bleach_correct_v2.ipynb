{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b01309ac",
   "metadata": {},
   "source": [
    "GPU-based computation of global statistics (e.g., mean intensity across all pixels).\n",
    "Please update the h5_path accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56b05b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# GPU可用性チェック\n",
    "try:\n",
    "    import cupy as cp\n",
    "    GPU_AVAILABLE = True\n",
    "    print(\"🚀 GPU処理が利用可能です\")\n",
    "    \n",
    "    # GPU情報表示\n",
    "    gpu_props = cp.cuda.runtime.getDeviceProperties(0)\n",
    "    gpu_name = gpu_props['name'].decode('utf-8')\n",
    "    total_memory_gb = cp.cuda.Device().mem_info[1] / (1024**3)\n",
    "    print(f\"🎮 GPU: {gpu_name}, VRAM: {total_memory_gb:.1f}GB\")\n",
    "    \n",
    "except ImportError:\n",
    "    GPU_AVAILABLE = False\n",
    "    print(\"⚠️ CPU処理を使用します\")\n",
    "\n",
    "# === パラメータ ===\n",
    "h5_path = r\"I:\\20240508-174849tdTomato-12mW-3_raw_gzip\\20240508-174849tdTomato-12mW-3_raw_gzip.h5\"\n",
    "dataset_name = \"/default\"\n",
    "output_csv = os.path.splitext(h5_path)[0] + \"_top90_mean.csv\"\n",
    "\n",
    "# 高速化パラメータ\n",
    "offset_value = 100\n",
    "exclude_value = -100\n",
    "chunk_size = 50 if GPU_AVAILABLE else 25  # GPU使用時はより大きなチャンク\n",
    "\n",
    "def process_volume_gpu(vol_chunk, c, offset_value, exclude_value):\n",
    "    \"\"\"GPU用のボリューム統計処理\"\"\"\n",
    "    try:\n",
    "        # GPUに転送\n",
    "        vol_gpu = cp.asarray(vol_chunk, dtype=cp.float32)\n",
    "        vol_gpu -= offset_value\n",
    "        \n",
    "        # 各統計の計算\n",
    "        stats = {}\n",
    "        \n",
    "        # -100除外統計\n",
    "        valid_mask = vol_gpu != exclude_value\n",
    "        valid_vals = vol_gpu[valid_mask]\n",
    "        \n",
    "        # if len(valid_vals) > 0:\n",
    "        #     stats['sum'] = float(cp.sum(valid_vals))\n",
    "        #     stats['mean'] = float(cp.mean(valid_vals))\n",
    "        # else:\n",
    "        #     stats['sum'] = 0.0\n",
    "        #     stats['mean'] = 0.0\n",
    "        \n",
    "        # # 正の値のみの統計\n",
    "        # pos_mask = vol_gpu > 0\n",
    "        # pos_vals = vol_gpu[pos_mask]\n",
    "        \n",
    "        # if len(pos_vals) > 0:\n",
    "        #     stats['possum'] = float(cp.sum(pos_vals))\n",
    "        #     stats['posmean'] = float(cp.mean(pos_vals))\n",
    "        # else:\n",
    "        #     stats['possum'] = 0.0\n",
    "        #     stats['posmean'] = 0.0\n",
    "        \n",
    "        # # チャンネル別閾値統計\n",
    "        # if c == 0:\n",
    "        #     thresh_mask = vol_gpu > 10\n",
    "        #     thresh_vals = vol_gpu[thresh_mask]\n",
    "        #     stats['posmean_gcamp5_td10'] = float(cp.mean(thresh_vals)) if len(thresh_vals) > 0 else 0.0\n",
    "        # elif c == 1:\n",
    "        #     thresh_mask = vol_gpu > 5\n",
    "        #     thresh_vals = vol_gpu[thresh_mask]\n",
    "        #     stats['posmean_gcamp5_td10'] = float(cp.mean(thresh_vals)) if len(thresh_vals) > 0 else 0.0\n",
    "        # else:\n",
    "        #     stats['posmean_gcamp5_td10'] = 0.0\n",
    "        \n",
    "        # 上位10%, 50%, 90%の平均値\n",
    "        # percentiles = [90, 50, 10]\n",
    "        percentiles = [90]\n",
    "        for p in percentiles:\n",
    "            if len(valid_vals) > 0:\n",
    "                thresh = cp.percentile(valid_vals, p)\n",
    "                top_vals = valid_vals[valid_vals >= thresh]\n",
    "                stats[f'top{p}_mean'] = float(cp.mean(top_vals)) if len(top_vals) > 0 else 0.0\n",
    "            else:\n",
    "                stats[f'top{p}_mean'] = 0.0\n",
    "        \n",
    "        \n",
    "        # メモリクリーンアップ\n",
    "        del vol_gpu, valid_vals, top_vals, thresh\n",
    "        if 'thresh_vals' in locals():\n",
    "            del thresh_vals\n",
    "        \n",
    "        return stats\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ GPU処理エラー: {e}\")\n",
    "        # CPUフォールバック\n",
    "        return process_volume_cpu(vol_chunk, c, offset_value, exclude_value)\n",
    "\n",
    "def process_volume_cpu(vol_chunk, c, offset_value, exclude_value):\n",
    "    \"\"\"CPU用のボリューム統計処理（ベクトル化最適化）\"\"\"\n",
    "    vol = vol_chunk.astype(np.float32)\n",
    "    vol -= offset_value\n",
    "    \n",
    "    stats = {}\n",
    "    \n",
    "    # -100除外統計（ベクトル化）\n",
    "    valid_mask = vol != exclude_value\n",
    "    if np.any(valid_mask):\n",
    "        valid_vals = vol[valid_mask]\n",
    "        stats['sum'] = float(np.sum(valid_vals))\n",
    "        stats['mean'] = float(np.mean(valid_vals))\n",
    "    else:\n",
    "        stats['sum'] = 0.0\n",
    "        stats['mean'] = 0.0\n",
    "    \n",
    "    # 正の値のみの統計（ベクトル化）\n",
    "    pos_mask = vol > 0\n",
    "    if np.any(pos_mask):\n",
    "        pos_vals = vol[pos_mask]\n",
    "        stats['possum'] = float(np.sum(pos_vals))\n",
    "        stats['posmean'] = float(np.mean(pos_vals))\n",
    "    else:\n",
    "        stats['possum'] = 0.0\n",
    "        stats['posmean'] = 0.0\n",
    "    \n",
    "    # チャンネル別閾値統計\n",
    "    if c == 0:\n",
    "        thresh_mask = vol > 10\n",
    "        stats['posmean_gcamp5_td10'] = float(np.mean(vol[thresh_mask])) if np.any(thresh_mask) else 0.0\n",
    "    elif c == 1:\n",
    "        thresh_mask = vol > 5\n",
    "        stats['posmean_gcamp5_td10'] = float(np.mean(vol[thresh_mask])) if np.any(thresh_mask) else 0.0\n",
    "    else:\n",
    "        stats['posmean_gcamp5_td10'] = 0.0\n",
    "    \n",
    "    return stats\n",
    "\n",
    "def process_statistics_optimized():\n",
    "    \"\"\"最適化された統計処理（チャンク+GPU/CPU）\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    with h5py.File(h5_path, \"r\") as f:\n",
    "        dset = f[dataset_name]\n",
    "        t_len, c_len, z_len, y_len, x_len = dset.shape\n",
    "        print(f\"📐 Dataset shape: {dset.shape}\")\n",
    "        print(f\"🚀 処理モード: {'GPU' if GPU_AVAILABLE else 'CPU'}\")\n",
    "        print(f\"📦 チャンクサイズ: {chunk_size}\")\n",
    "        \n",
    "        # 結果辞書の初期化\n",
    "        result = {\"frame\": list(range(t_len))}\n",
    "        for c in range(c_len):\n",
    "            # result[f\"ch{c}_sum\"] = []\n",
    "            # result[f\"ch{c}_mean\"] = []\n",
    "            # result[f\"ch{c}_possum\"] = []\n",
    "            # result[f\"ch{c}_posmean\"] = []\n",
    "            # result[f\"ch{c}_posmean_gcamp5_td10\"] = []\n",
    "            result[f\"ch{c}_top90_mean\"] = []\n",
    "            # result[f\"ch{c}_top50_mean\"] = []\n",
    "            # result[f\"ch{c}_top10_mean\"] = []\n",
    "        \n",
    "        # チャンク処理でメモリ効率化\n",
    "        for t_start in tqdm(range(0, t_len, chunk_size), desc=\"🎯 統計計算処理\"):\n",
    "            t_end = min(t_start + chunk_size, t_len)\n",
    "            \n",
    "            # 複数フレームを一括読み込み\n",
    "            chunk_data = dset[t_start:t_end]  # shape: (chunk_size, c, z, y, x)\n",
    "            \n",
    "            for i, t in enumerate(range(t_start, t_end)):\n",
    "                for c in range(c_len):\n",
    "                    vol_chunk = chunk_data[i, c]  # shape: (z, y, x)\n",
    "                    \n",
    "                    # GPU/CPU処理の選択\n",
    "                    if GPU_AVAILABLE:\n",
    "                        stats = process_volume_gpu(vol_chunk, c, offset_value, exclude_value)\n",
    "                    else:\n",
    "                        stats = process_volume_cpu(vol_chunk, c, offset_value, exclude_value)\n",
    "                    \n",
    "                    # 結果の蓄積\n",
    "                    # result[f\"ch{c}_sum\"].append(stats['sum'])\n",
    "                    # result[f\"ch{c}_mean\"].append(stats['mean'])\n",
    "                    # result[f\"ch{c}_possum\"].append(stats['possum'])\n",
    "                    # result[f\"ch{c}_posmean\"].append(stats['posmean'])\n",
    "                    # result[f\"ch{c}_posmean_gcamp5_td10\"].append(stats['posmean_gcamp5_td10'])\n",
    "                    result[f\"ch{c}_top90_mean\"].append(stats['top90_mean'])\n",
    "                    # result[f\"ch{c}_top50_mean\"].append(stats['top50_mean'])\n",
    "                    # result[f\"ch{c}_top10_mean\"].append(stats['top10_mean'])\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "            \n",
    "            # 進捗情報表示\n",
    "            if t_start % (chunk_size * 10) == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                processed = t_end\n",
    "                fps = processed / elapsed if elapsed > 0 else 0\n",
    "                remaining = t_len - processed\n",
    "                eta_minutes = (remaining / fps / 60) if fps > 0 else 0\n",
    "                \n",
    "                print(f\"  📊 進捗: {processed}/{t_len} ({100*processed/t_len:.1f}%)\")\n",
    "                print(f\"  🚀 速度: {fps:.1f}フレーム/秒, ETA: {eta_minutes:.1f}分\")\n",
    "            \n",
    "            # GPUメモリクリーンアップ\n",
    "            if GPU_AVAILABLE:\n",
    "                try:\n",
    "                    cp.get_default_memory_pool().free_all_blocks()\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    # 処理結果サマリー\n",
    "    total_elapsed = time.time() - start_time\n",
    "    average_fps = t_len / total_elapsed if total_elapsed > 0 else 0\n",
    "    \n",
    "    print(f\"\\n🎉 統計計算完了!\")\n",
    "    print(f\"📊 処理フレーム数: {t_len}\")\n",
    "    print(f\"🔄 処理チャンネル数: {c_len}\")\n",
    "    print(f\"⏱️ 総処理時間: {total_elapsed:.1f}秒 ({total_elapsed/60:.1f}分)\")\n",
    "    print(f\"🚀 平均処理速度: {average_fps:.1f}フレーム/秒\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# === 最適化処理実行 ===\n",
    "print(\"🎯 最適化された統計計算を開始...\")\n",
    "result = process_statistics_optimized()\n",
    "\n",
    "# === 保存処理 ===\n",
    "print(\"💾 CSV保存中...\")\n",
    "df = pd.DataFrame(result)\n",
    "\n",
    "try:\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"✅ 最適化統計処理完了: {output_csv}\")\n",
    "    print(f\"📈 出力データ形状: {df.shape}\")\n",
    "    \n",
    "    # データサンプル表示\n",
    "    print(\"\\n📊 データサンプル:\")\n",
    "    print(df.head())\n",
    "    \n",
    "except PermissionError:\n",
    "    print(\"❌ 書き込みに失敗しました。ファイルが開かれているか、書き込み権限がありません:\")\n",
    "    print(\"🔒 ファイルを閉じているか、別の保存先を指定してください。\")\n",
    "    print(\"📄 試行した出力先:\", output_csv)\n",
    "    \n",
    "    # 代替保存先の提案\n",
    "    alternative_path = output_csv.replace(\".csv\", f\"_backup_{int(time.time())}.csv\")\n",
    "    try:\n",
    "        df.to_csv(alternative_path, index=False)\n",
    "        print(f\"✅ 代替パスに保存完了: {alternative_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 代替保存も失敗: {e}\")\n",
    "\n",
    "# === メモリクリーンアップ ===\n",
    "try:\n",
    "    del result, df\n",
    "    if GPU_AVAILABLE:\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "    print(\"🧹 メモリクリーンアップ完了\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4deff41",
   "metadata": {},
   "source": [
    "Accelerated fading correction processing (GPU parallel processing) with support for 2 channels. Please modify csv_path, h5_input_path, and h5_output_path as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f6a4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import time\n",
    "import cupy as cp\n",
    "from scipy.signal import savgol_filter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === パラメータ ===\n",
    "calc_method = \"_top90_mean\"  # 使用する列のメソッド（top50_mean, top90_meanなど）\n",
    "csv_path = r\"I:\\20240508-174849tdTomato-12mW-3_raw_gzip\\20240508-174849tdTomato-12mW-3_raw_gzip_top90_mean.csv\"\n",
    "h5_input_path = r\"I:\\20240508-174849tdTomato-12mW-3_raw_gzip\\20240508-174849tdTomato-12mW-3_raw_gzip.h5\"\n",
    "h5_output_path = fr\"I:\\20240508-174849tdTomato-12mW-3_raw_gzip\\20240508-174849tdTomato-12mW-3_raw_gzip_bleachcorrect_{calc_method}.h5\"\n",
    "offset_value = 100\n",
    "scale_margin = 1.2\n",
    "chunk_size = 60  # メモリーサイズに応じて設定\n",
    "\n",
    "# === 褪色関数定義 ===\n",
    "def double_exp(t, a, b, c, d):\n",
    "    return a * np.exp(-b * t) + c * np.exp(-d * t)\n",
    "\n",
    "# === チャンネル別褪色カーブ推定 ===\n",
    "def estimate_bleach_curves():\n",
    "    \"\"\"各チャンネルの褪色カーブを独立して推定\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    t = np.arange(len(df))\n",
    "    \n",
    "    \n",
    "    bleach_params = {}\n",
    "    scale_factors = {}\n",
    "    \n",
    "    # チャンネル数の自動検出\n",
    "    mean_columns = [col for col in df.columns if col.endswith(calc_method)]\n",
    "    channel_numbers = [int(col.split('_')[0][2:]) for col in mean_columns if col.startswith('ch')]\n",
    "    \n",
    "    print(f\"🔍 検出されたチャンネル: {channel_numbers}\")\n",
    "    \n",
    "    for ch_num in channel_numbers:\n",
    "        column_name = f\"ch{ch_num}{calc_method}\"\n",
    "        \n",
    "        if column_name not in df.columns:\n",
    "            print(f\"⚠️ 列 '{column_name}' が見つかりません。スキップします。\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n--- Channel {ch_num} 褪色カーブ推定 ---\")\n",
    "        \n",
    "        y_raw = df[column_name].to_numpy()\n",
    "        # SGフィルタ適用（ウィンドウサイズ13, 多項式次数1）\n",
    "        y_smooth = savgol_filter(y_raw, window_length=13, polyorder=1, mode='interp')\n",
    "        \n",
    "        # 初期値と上限の推定\n",
    "        a0 = c0 = y_smooth[0] / 2\n",
    "        p0 = [a0, 0.01, c0, 0.001]\n",
    "        y_max = np.nanmax(y_smooth)\n",
    "        upper_limit = y_max * scale_margin\n",
    "        bounds = ([0, 0, 0, 0], [upper_limit, 1, upper_limit, 1])\n",
    "        \n",
    "        try:\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                popt, _ = curve_fit(double_exp, t, y_smooth, p0=p0, bounds=bounds, maxfev=10000)\n",
    "            \n",
    "            fitted = double_exp(t, *popt)\n",
    "            scale = double_exp(0, *popt) / fitted  # t=0で正規化\n",
    "            \n",
    "            bleach_params[ch_num] = popt\n",
    "            scale_factors[ch_num] = scale\n",
    "      \n",
    "\n",
    "            # 横並びで全チャンネル分のプロットを作成・保存\n",
    "            fig, axes = plt.subplots(1, len(channel_numbers), figsize=(6 * len(channel_numbers), 4), sharey=True)\n",
    "            if len(channel_numbers) == 1:\n",
    "                axes = [axes]\n",
    "            for idx, ch in enumerate(channel_numbers):\n",
    "                col_name = f\"ch{ch}{calc_method}\"\n",
    "                y = df[col_name].to_numpy()\n",
    "                if ch in bleach_params:\n",
    "                    fit = double_exp(t, *bleach_params[ch])\n",
    "                    # 褪色補正後データ\n",
    "                    corrected = y * scale_factors[ch]\n",
    "                else:\n",
    "                    fit = np.ones_like(t) * y[0]\n",
    "                    corrected = y\n",
    "                axes[idx].plot(t, y, 'o', label=f'Ch{ch} Raw')\n",
    "                axes[idx].plot(t, fit, '-', label=f'Ch{ch} Fit')\n",
    "                axes[idx].plot(t, corrected, '--', label=f'Ch{ch} Corrected')\n",
    "                axes[idx].set_title(f'Channel {ch} Bleach Curve')\n",
    "                axes[idx].set_xlabel('Time')\n",
    "                axes[idx].legend()\n",
    "            axes[0].set_ylabel('Intensity')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'bleach_curve_all_channels{calc_method}.png')\n",
    "            plt.show()\n",
    "            \n",
    "            print(f\"✅ Ch{ch_num} フィッティング完了: a={popt[0]:.2f}, b={popt[1]:.4f}, c={popt[2]:.2f}, d={popt[3]:.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Ch{ch_num} フィッティング失敗: {e}\")\n",
    "            # フォールバック: スケールファクター=1（補正なし）\n",
    "            scale_factors[ch_num] = np.ones_like(t)\n",
    "    \n",
    "    return scale_factors\n",
    "\n",
    "# 褪色カーブ推定実行\n",
    "scale_factors_all = estimate_bleach_curves()\n",
    "print(\"\\n✅ 全チャンネルの褪色カーブ推定完了\")\n",
    "\n",
    "# GPU版（チャンネル別補正対応）\n",
    "try:\n",
    "    GPU_AVAILABLE = True\n",
    "    print(\"🚀 GPU処理が利用可能です\")\n",
    "    \n",
    "    # GPU情報表示\n",
    "    gpu_props = cp.cuda.runtime.getDeviceProperties(0)\n",
    "    gpu_name = gpu_props['name'].decode('utf-8')\n",
    "    total_memory_gb = cp.cuda.Device().mem_info[1] / (1024**3)\n",
    "    print(f\"🎮 GPU: {gpu_name}\")\n",
    "    print(f\"💾 VRAM: {total_memory_gb:.1f}GB\")\n",
    "    \n",
    "except ImportError:\n",
    "    GPU_AVAILABLE = False\n",
    "    print(\"⚠️ CuPyが利用できません。CPU処理を使用します\")\n",
    "\n",
    "def process_with_gpu_multichannel():\n",
    "    \"\"\"チャンネル別褪色補正GPU処理（全ボリューム対応）\"\"\"\n",
    "    if not GPU_AVAILABLE:\n",
    "        print(\"❌ GPU処理をスキップします\")\n",
    "        return\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    with h5py.File(h5_input_path, \"r\") as f_in, h5py.File(h5_output_path, \"w\") as f_out:\n",
    "        dset_in = f_in[\"/default\"]\n",
    "        T_full, C, Z, Y, X = dset_in.shape\n",
    "        \n",
    "        print(f\"📐 データ形状: (T={T_full}, C={C}, Z={Z}, Y={Y}, X={X})\")\n",
    "        print(f\"🎯 処理対象: 全ボリューム（{T_full}フレーム）\")\n",
    "        \n",
    "        # 出力データセット作成（全ボリューム）\n",
    "        dset_out = f_out.create_dataset(\n",
    "            \"/default\", \n",
    "            shape=(T_full, C, Z, Y, X),\n",
    "            dtype='uint16',\n",
    "            chunks=(min(chunk_size//4, 20), 1, Z, Y, X),\n",
    "            compression=\"gzip\",\n",
    "            compression_opts=1\n",
    "        )\n",
    "        \n",
    "        # メタデータ追加\n",
    "        dset_out.attrs['processing_mode'] = 'multichannel_bleach_correction_full'\n",
    "        dset_out.attrs['chunk_size'] = chunk_size\n",
    "        dset_out.attrs['offset_value'] = offset_value\n",
    "        dset_out.attrs['processed_frames'] = T_full\n",
    "        dset_out.attrs['frame_range'] = f\"0-{T_full-1}\"\n",
    "        \n",
    "        # チャンネル別スケールファクターの準備\n",
    "        scale_factors_gpu = {}\n",
    "        for ch_num in range(C):\n",
    "            if ch_num in scale_factors_all:\n",
    "                # 全フレーム分を取得\n",
    "                scale_factors_gpu[ch_num] = cp.asarray(\n",
    "                    scale_factors_all[ch_num], dtype=cp.float32\n",
    "                )\n",
    "                print(f\"✅ Ch{ch_num}: GPU用スケールファクター準備完了（{T_full}フレーム）\")\n",
    "            else:\n",
    "                scale_factors_gpu[ch_num] = cp.ones(T_full, dtype=cp.float32)\n",
    "                print(f\"⚠️ Ch{ch_num}: スケールファクターなし（補正スキップ）\")\n",
    "        \n",
    "        # チャンク処理メインループ（全フレーム）\n",
    "        for t_start in tqdm(range(0, T_full, chunk_size), desc=\"🎮 GPU多チャンネル褪色補正（全ボリューム）\"):\n",
    "            t_end = min(t_start + chunk_size, T_full)\n",
    "            current_chunk_size = t_end - t_start\n",
    "            \n",
    "            try:\n",
    "                # メモリ使用量監視\n",
    "                memory_before = cp.cuda.Device().mem_info[0] / (1024**3)\n",
    "                \n",
    "                # チャンネル別処理\n",
    "                for c in range(C):\n",
    "                    # CPUからGPUへデータ転送\n",
    "                    vol_chunk = cp.asarray(\n",
    "                        dset_in[t_start:t_end, c, :, :, :], \n",
    "                        dtype=cp.float32\n",
    "                    )\n",
    "                    \n",
    "                    # チャンネル専用スケールファクター取得\n",
    "                    scale_chunk = scale_factors_gpu[c][t_start:t_end]\n",
    "                    \n",
    "                    # GPU上でベクトル化処理\n",
    "                    vol_chunk -= offset_value  # オフセット減算\n",
    "                    vol_chunk *= scale_chunk.reshape(-1, 1, 1, 1)  # チャンネル別褪色補正\n",
    "                    vol_chunk = cp.clip(vol_chunk, 0, 65535)  # クリッピング\n",
    "                    \n",
    "                    # 型変換と結果保存\n",
    "                    vol_chunk = vol_chunk.astype(cp.uint16)\n",
    "                    result = cp.asnumpy(vol_chunk)\n",
    "                    dset_out[t_start:t_end, c, :, :, :] = result\n",
    "                    \n",
    "                    # メモリクリーンアップ（チャンネル毎）\n",
    "                    del vol_chunk, result\n",
    "                    cp.cuda.Stream.null.synchronize()\n",
    "                \n",
    "                # 進捗情報表示\n",
    "                if t_start % (chunk_size * 5) == 0:\n",
    "                    memory_after = cp.cuda.Device().mem_info[0] / (1024**3)\n",
    "                    elapsed = time.time() - start_time\n",
    "                    processed_frames = t_end\n",
    "                    fps = processed_frames / elapsed if elapsed > 0 else 0\n",
    "                    remaining_frames = T_full - processed_frames\n",
    "                    eta_minutes = (remaining_frames / fps / 60) if fps > 0 else 0\n",
    "                    \n",
    "                    print(f\"  📊 進捗: {processed_frames}/{T_full} ({100*processed_frames/T_full:.1f}%)\")\n",
    "                    print(f\"  🚀 速度: {fps:.1f}fps, VRAM: {memory_before:.1f}GB, ETA: {eta_minutes:.1f}分\")\n",
    "                    \n",
    "            except cp.cuda.memory.OutOfMemoryError:\n",
    "                print(f\"💥 GPU メモリ不足 (chunk_size={chunk_size})\")\n",
    "                cp.get_default_memory_pool().free_all_blocks()\n",
    "                continue\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"❌ 処理エラー (t={t_start}-{t_end}): {e}\")\n",
    "                continue\n",
    "    \n",
    "    # 最終メモリクリーンアップ\n",
    "    try:\n",
    "        # 辞書のキーのリストを事前に取得してからイテレート\n",
    "        channel_keys = list(scale_factors_gpu.keys())\n",
    "        for ch_num in channel_keys:\n",
    "            if ch_num in scale_factors_gpu:\n",
    "                del scale_factors_gpu[ch_num]\n",
    "        \n",
    "        # GPU メモリプールのクリーンアップ\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "        \n",
    "    except Exception as cleanup_error:\n",
    "        print(f\"⚠️ メモリクリーンアップ中にエラー: {cleanup_error}\")\n",
    "        # 強制的にメモリプールをクリア\n",
    "        try:\n",
    "            cp.get_default_memory_pool().free_all_blocks()\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # 処理結果サマリー\n",
    "    total_elapsed = time.time() - start_time\n",
    "    average_fps = T_full / total_elapsed if total_elapsed > 0 else 0\n",
    "    \n",
    "    print(f\"\\n🎉 全ボリューム多チャンネル褪色補正GPU処理完了!\")\n",
    "    print(f\"📊 処理フレーム数: {T_full}\")\n",
    "    print(f\"🔄 処理チャンネル数: {C}\")\n",
    "    print(f\"⏱️  総処理時間: {total_elapsed/60:.1f}分\")\n",
    "    print(f\"🚀 平均処理速度: {average_fps:.1f}フレーム/秒\")\n",
    "    print(f\"💾 出力ファイル: {h5_output_path}\")\n",
    "\n",
    "# === 実行 ===\n",
    "if GPU_AVAILABLE and scale_factors_all:\n",
    "    print(\"🎯 チャンネル別褪色補正GPU処理を開始します（全ボリューム）...\")\n",
    "    process_with_gpu_multichannel()\n",
    "else:\n",
    "    print(\"⚠️ GPU処理またはスケールファクターが利用できません\")\n",
    "    print(f\"GPU利用可能: {GPU_AVAILABLE}\")\n",
    "    print(f\"スケールファクター: {list(scale_factors_all.keys()) if scale_factors_all else 'なし'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350fc5e6",
   "metadata": {},
   "source": [
    "Orthogonal View tiff from hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0121c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# GPU可用性チェック\n",
    "try:\n",
    "    import cupy as cp\n",
    "    GPU_AVAILABLE = True\n",
    "    print(\"🚀 GPU処理が利用可能です\")\n",
    "    \n",
    "    # GPU情報表示\n",
    "    gpu_props = cp.cuda.runtime.getDeviceProperties(0)\n",
    "    gpu_name = gpu_props['name'].decode('utf-8')\n",
    "    total_memory_gb = cp.cuda.Device().mem_info[1] / (1024**3)\n",
    "    print(f\"🎮 GPU: {gpu_name}\")\n",
    "    print(f\"💾 VRAM: {total_memory_gb:.1f}GB\")\n",
    "    \n",
    "except ImportError:\n",
    "    GPU_AVAILABLE = False\n",
    "    print(\"⚠️ CPU処理を使用します\")\n",
    "\n",
    "# === パラメータ ===\n",
    "hdf5_file = h5_output_path\n",
    "output_path = r\"I:\\20240508-174849tdTomato-12mW-3_raw_gzip\\bleachcorrect\"\n",
    "dirname = os.path.splitext(os.path.basename(hdf5_file))[0]\n",
    "chunk_size = 100 if GPU_AVAILABLE else 50  # GPU使用時はより大きなチャンク\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "# === HDF5ファイル情報取得 ===\n",
    "with h5py.File(hdf5_file, 'r') as file:\n",
    "    array = file['default']\n",
    "    total_volumes, channels, z, y, x = array.shape\n",
    "    print(f\"📐 データ形状: (T={total_volumes}, C={channels}, Z={z}, Y={y}, X={x})\")\n",
    "    print(f\"🎯 処理対象: 全ボリューム（{total_volumes}フレーム）\")\n",
    "\n",
    "# === 出力配列の準備（全ボリューム） ===\n",
    "orthogonal_view = np.zeros((total_volumes, channels, y + z + 3, x + z + 3), dtype='uint16')\n",
    "\n",
    "def process_cpu_chunk(chunk_data, t_start, t_end):\n",
    "    \"\"\"CPU処理用のヘルパー関数\"\"\"\n",
    "    for i, t in enumerate(range(t_start, t_end)):\n",
    "        for c in range(channels):\n",
    "            data = chunk_data[i, c]  # (Z, Y, X)\n",
    "            \n",
    "            # CPU上で最大投影\n",
    "            xy_proj = np.max(data, axis=0)  # (Y, X)\n",
    "            yz_proj = np.max(data, axis=2).T  # (Z, Y)\n",
    "            xz_proj = np.max(data, axis=1)  # (Z, X)\n",
    "            \n",
    "            # 直交ビューへの配置\n",
    "            orthogonal_view[t, c, 0:y, 0:x] = xy_proj\n",
    "            orthogonal_view[t, c, 0:y, x+3:x+z+3] = yz_proj\n",
    "            orthogonal_view[t, c, y+3:y+z+3, 0:x] = xz_proj\n",
    "            orthogonal_view[t, c, y+z+2, x+z+2] = 1000\n",
    "\n",
    "def process_orthogonal_projections():\n",
    "    \"\"\"直交投影処理（CPU/GPU自動選択・全ボリューム）\"\"\"\n",
    "    use_gpu = GPU_AVAILABLE  # ローカル変数として処理状態を管理\n",
    "    \n",
    "    with h5py.File(hdf5_file, 'r') as file:\n",
    "        array = file['default']\n",
    "        \n",
    "        for t_start in tqdm(range(0, total_volumes, chunk_size), \n",
    "                           desc=\"🎮 GPU直交投影（全ボリューム）\" if use_gpu else \"🖥️ CPU直交投影（全ボリューム）\"):\n",
    "            t_end = min(t_start + chunk_size, total_volumes)\n",
    "            \n",
    "            # チャンクデータ読み込み\n",
    "            chunk_data = array[t_start:t_end]  # (chunk_size, C, Z, Y, X)\n",
    "            \n",
    "            if use_gpu:\n",
    "                # GPU処理を試行\n",
    "                try:\n",
    "                    chunk_gpu = cp.asarray(chunk_data)\n",
    "                    \n",
    "                    for i, t in enumerate(range(t_start, t_end)):\n",
    "                        for c in range(channels):\n",
    "                            data_gpu = chunk_gpu[i, c]  # (Z, Y, X)\n",
    "                            \n",
    "                            # GPU上で最大投影\n",
    "                            xy_proj = cp.max(data_gpu, axis=0)  # (Y, X)\n",
    "                            yz_proj = cp.max(data_gpu, axis=2).T  # (Z, Y)\n",
    "                            xz_proj = cp.max(data_gpu, axis=1)  # (Z, X)\n",
    "                            \n",
    "                            # CPU側に結果をコピー\n",
    "                            orthogonal_view[t, c, 0:y, 0:x] = cp.asnumpy(xy_proj)\n",
    "                            orthogonal_view[t, c, 0:y, x+3:x+z+3] = cp.asnumpy(yz_proj)\n",
    "                            orthogonal_view[t, c, y+3:y+z+3, 0:x] = cp.asnumpy(xz_proj)\n",
    "                            orthogonal_view[t, c, y+z+2, x+z+2] = 1000\n",
    "                    \n",
    "                    # GPUメモリクリーンアップ\n",
    "                    del chunk_gpu\n",
    "                    cp.get_default_memory_pool().free_all_blocks()\n",
    "                    \n",
    "                    # 進捗情報表示（GPU処理）\n",
    "                    if t_start % (chunk_size * 5) == 0:\n",
    "                        processed = t_end\n",
    "                        remaining = total_volumes - processed\n",
    "                        progress_pct = 100 * processed / total_volumes\n",
    "                        print(f\"  📊 GPU進捗: {processed}/{total_volumes} ({progress_pct:.1f}%)\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ GPU処理エラー、CPUにフォールバック: {e}\")\n",
    "                    use_gpu = False  # 今後のチャンクはCPU処理\n",
    "                    # CPU処理で再試行\n",
    "                    process_cpu_chunk(chunk_data, t_start, t_end)\n",
    "                    \n",
    "            else:\n",
    "                # CPU処理\n",
    "                process_cpu_chunk(chunk_data, t_start, t_end)\n",
    "                \n",
    "                # 進捗情報表示（CPU処理）\n",
    "                if t_start % (chunk_size * 2) == 0:\n",
    "                    processed = t_end\n",
    "                    progress_pct = 100 * processed / total_volumes\n",
    "                    print(f\"  📊 CPU進捗: {processed}/{total_volumes} ({progress_pct:.1f}%)\")\n",
    "\n",
    "# === 処理実行 ===\n",
    "print(f\"🎯 全ボリューム（{total_volumes}フレーム）の直交投影処理を開始...\")\n",
    "process_orthogonal_projections()\n",
    "print(\"🎉 直交投影処理完了!\")\n",
    "\n",
    "# === TIFF保存（全ボリューム） ===\n",
    "file_name = f\"orthogonal_view_{dirname}_full.tif\"\n",
    "output_path2 = os.path.join(output_path, file_name)\n",
    "\n",
    "print(\"💾 TIFF保存中...\")\n",
    "print(f\"📁 保存先: {output_path2}\")\n",
    "print(f\"📊 データサイズ: {orthogonal_view.nbytes / (1024**3):.2f}GB\")\n",
    "\n",
    "try:\n",
    "    tiff.imwrite(\n",
    "        output_path2, \n",
    "        orthogonal_view, \n",
    "        imagej=True, \n",
    "        metadata={'axes': 'TCYX'}, \n",
    "        compression='zlib'\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ 全ボリューム処理完了: {output_path2}\")\n",
    "    print(f\"📈 出力形状: {orthogonal_view.shape}\")\n",
    "    print(f\"📊 処理統計: {total_volumes}/{total_volumes}ボリューム (100%)\")\n",
    "    \n",
    "except Exception as save_error:\n",
    "    print(f\"❌ TIFF保存エラー: {save_error}\")\n",
    "    print(\"💡 メモリ不足の可能性があります。チャンク保存を試します...\")\n",
    "    \n",
    "    # === フォールバック: チャンク保存 ===\n",
    "    save_chunk_size = 500  # 500フレームずつ保存\n",
    "    \n",
    "    for save_start in tqdm(range(0, total_volumes, save_chunk_size), desc=\"📦 チャンク保存\"):\n",
    "        save_end = min(save_start + save_chunk_size, total_volumes)\n",
    "        chunk_name = f\"orthogonal_view_{dirname}_part{save_start:05d}-{save_end:05d}.tif\"\n",
    "        chunk_path = os.path.join(output_path, chunk_name)\n",
    "        \n",
    "        chunk_data = orthogonal_view[save_start:save_end]\n",
    "        tiff.imwrite(\n",
    "            chunk_path,\n",
    "            chunk_data,\n",
    "            imagej=True,\n",
    "            metadata={'axes': 'TCYX'},\n",
    "            compression='zlib'\n",
    "        )\n",
    "        print(f\"✅ 保存完了: {chunk_name}\")\n",
    "    \n",
    "    print(f\"📦 チャンク保存完了: {output_path}\")\n",
    "\n",
    "# === メモリクリーンアップ ===\n",
    "try:\n",
    "    del orthogonal_view\n",
    "    if GPU_AVAILABLE:\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "    print(\"🧹 メモリクリーンアップ完了\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8c3702",
   "metadata": {},
   "source": [
    "Bleach correction processing for multiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ea3c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# 上位90%平均値計算と保存\n",
    "##############################################################################\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# GPU可用性チェック\n",
    "try:\n",
    "    import cupy as cp\n",
    "    GPU_AVAILABLE = True\n",
    "    print(\"🚀 GPU処理が利用可能です\")\n",
    "    \n",
    "    # GPU情報表示\n",
    "    gpu_props = cp.cuda.runtime.getDeviceProperties(0)\n",
    "    gpu_name = gpu_props['name'].decode('utf-8')\n",
    "    total_memory_gb = cp.cuda.Device().mem_info[1] / (1024**3)\n",
    "    print(f\"🎮 GPU: {gpu_name}, VRAM: {total_memory_gb:.1f}GB\")\n",
    "    \n",
    "except ImportError:\n",
    "    GPU_AVAILABLE = False\n",
    "    print(\"⚠️ CPU処理を使用します\")\n",
    "\n",
    "# === パラメータ（複数ファイル対応） ===\n",
    "h5_files = [\n",
    "    r\"I:\\20240508-174849tdTomato-12mW-3_raw_gzip\\20240508-174849tdTomato-12mW-3_corrected_size_gpu.h5\"\n",
    "]\n",
    "\n",
    "dataset_name = \"/default\"\n",
    "\n",
    "# 高速化パラメータ\n",
    "offset_value = 100\n",
    "exclude_value = -100\n",
    "chunk_size = 50 if GPU_AVAILABLE else 25  # GPU使用時はより大きなチャンク\n",
    "\n",
    "def process_volume_gpu(vol_chunk, c, offset_value, exclude_value):\n",
    "    \"\"\"GPU用のボリューム統計処理\"\"\"\n",
    "    try:\n",
    "        # GPUに転送\n",
    "        vol_gpu = cp.asarray(vol_chunk, dtype=cp.float32)\n",
    "        vol_gpu -= offset_value\n",
    "        \n",
    "        # 各統計の計算\n",
    "        stats = {}\n",
    "        \n",
    "        # -100除外統計\n",
    "        valid_mask = vol_gpu != exclude_value\n",
    "        valid_vals = vol_gpu[valid_mask]\n",
    "        \n",
    "        # 上位90%の平均値\n",
    "        percentiles = [90]\n",
    "        for p in percentiles:\n",
    "            if len(valid_vals) > 0:\n",
    "                thresh = cp.percentile(valid_vals, p)\n",
    "                top_vals = valid_vals[valid_vals >= thresh]\n",
    "                stats[f'top{p}_mean'] = float(cp.mean(top_vals)) if len(top_vals) > 0 else 0.0\n",
    "            else:\n",
    "                stats[f'top{p}_mean'] = 0.0\n",
    "        \n",
    "        # メモリクリーンアップ\n",
    "        del vol_gpu, valid_vals, top_vals, thresh\n",
    "        \n",
    "        return stats\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ GPU処理エラー: {e}\")\n",
    "        # CPUフォールバック\n",
    "        return process_volume_cpu(vol_chunk, c, offset_value, exclude_value)\n",
    "\n",
    "def process_volume_cpu(vol_chunk, c, offset_value, exclude_value):\n",
    "    \"\"\"CPU用のボリューム統計処理（ベクトル化最適化）\"\"\"\n",
    "    vol = vol_chunk.astype(np.float32)\n",
    "    vol -= offset_value\n",
    "    \n",
    "    stats = {}\n",
    "    \n",
    "    # -100除外統計（ベクトル化）\n",
    "    valid_mask = vol != exclude_value\n",
    "    if np.any(valid_mask):\n",
    "        valid_vals = vol[valid_mask]\n",
    "        \n",
    "        # 上位90%の平均値\n",
    "        percentiles = [90]\n",
    "        for p in percentiles:\n",
    "            thresh = np.percentile(valid_vals, p)\n",
    "            top_vals = valid_vals[valid_vals >= thresh]\n",
    "            stats[f'top{p}_mean'] = float(np.mean(top_vals)) if len(top_vals) > 0 else 0.0\n",
    "    else:\n",
    "        stats['top90_mean'] = 0.0\n",
    "    \n",
    "    return stats\n",
    "\n",
    "def process_single_file(h5_path):\n",
    "    \"\"\"単一ファイルの統計処理\"\"\"\n",
    "    print(f\"\\n🎯 処理開始: {os.path.basename(h5_path)}\")\n",
    "    \n",
    "    output_csv = os.path.splitext(h5_path)[0] + \"_top90_mean.csv\"\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    with h5py.File(h5_path, \"r\") as f:\n",
    "        dset = f[dataset_name]\n",
    "        t_len, c_len, z_len, y_len, x_len = dset.shape\n",
    "        print(f\"📐 Dataset shape: {dset.shape}\")\n",
    "        print(f\"🚀 処理モード: {'GPU' if GPU_AVAILABLE else 'CPU'}\")\n",
    "        print(f\"📦 チャンクサイズ: {chunk_size}\")\n",
    "        \n",
    "        # 結果辞書の初期化\n",
    "        result = {\"frame\": list(range(t_len))}\n",
    "        for c in range(c_len):\n",
    "            result[f\"ch{c}_top90_mean\"] = []\n",
    "        \n",
    "        # チャンク処理でメモリ効率化\n",
    "        for t_start in tqdm(range(0, t_len, chunk_size), desc=\"🎯 統計計算処理\"):\n",
    "            t_end = min(t_start + chunk_size, t_len)\n",
    "            \n",
    "            # 複数フレームを一括読み込み\n",
    "            chunk_data = dset[t_start:t_end]  # shape: (chunk_size, c, z, y, x)\n",
    "            \n",
    "            for i, t in enumerate(range(t_start, t_end)):\n",
    "                for c in range(c_len):\n",
    "                    vol_chunk = chunk_data[i, c]  # shape: (z, y, x)\n",
    "                    \n",
    "                    # GPU/CPU処理の選択\n",
    "                    if GPU_AVAILABLE:\n",
    "                        stats = process_volume_gpu(vol_chunk, c, offset_value, exclude_value)\n",
    "                    else:\n",
    "                        stats = process_volume_cpu(vol_chunk, c, offset_value, exclude_value)\n",
    "                    \n",
    "                    # 結果の蓄積\n",
    "                    result[f\"ch{c}_top90_mean\"].append(stats['top90_mean'])\n",
    "            \n",
    "            # 進捗情報表示\n",
    "            if t_start % (chunk_size * 10) == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                processed = t_end\n",
    "                fps = processed / elapsed if elapsed > 0 else 0\n",
    "                remaining = t_len - processed\n",
    "                eta_minutes = (remaining / fps / 60) if fps > 0 else 0\n",
    "                \n",
    "                print(f\"  📊 進捗: {processed}/{t_len} ({100*processed/t_len:.1f}%)\")\n",
    "                print(f\"  🚀 速度: {fps:.1f}フレーム/秒, ETA: {eta_minutes:.1f}分\")\n",
    "            \n",
    "            # GPUメモリクリーンアップ\n",
    "            if GPU_AVAILABLE:\n",
    "                try:\n",
    "                    cp.get_default_memory_pool().free_all_blocks()\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    # 処理結果サマリー\n",
    "    total_elapsed = time.time() - start_time\n",
    "    average_fps = t_len / total_elapsed if total_elapsed > 0 else 0\n",
    "    \n",
    "    print(f\"\\n🎉 統計計算完了!\")\n",
    "    print(f\"📊 処理フレーム数: {t_len}\")\n",
    "    print(f\"🔄 処理チャンネル数: {c_len}\")\n",
    "    print(f\"⏱️ 総処理時間: {total_elapsed:.1f}秒 ({total_elapsed/60:.1f}分)\")\n",
    "    print(f\"🚀 平均処理速度: {average_fps:.1f}フレーム/秒\")\n",
    "    \n",
    "    return result, output_csv\n",
    "\n",
    "def save_results(result, output_csv):\n",
    "    \"\"\"結果の保存処理\"\"\"\n",
    "    print(\"💾 CSV保存中...\")\n",
    "    df = pd.DataFrame(result)\n",
    "\n",
    "    try:\n",
    "        df.to_csv(output_csv, index=False)\n",
    "        print(f\"✅ 最適化統計処理完了: {output_csv}\")\n",
    "        print(f\"📈 出力データ形状: {df.shape}\")\n",
    "        \n",
    "        # データサンプル表示\n",
    "        print(\"\\n📊 データサンプル:\")\n",
    "        print(df.head())\n",
    "        \n",
    "    except PermissionError:\n",
    "        print(\"❌ 書き込みに失敗しました。ファイルが開かれているか、書き込み権限がありません:\")\n",
    "        print(\"🔒 ファイルを閉じているか、別の保存先を指定してください。\")\n",
    "        print(\"📄 試行した出力先:\", output_csv)\n",
    "        \n",
    "        # 代替保存先の提案\n",
    "        alternative_path = output_csv.replace(\".csv\", f\"_backup_{int(time.time())}.csv\")\n",
    "        try:\n",
    "            df.to_csv(alternative_path, index=False)\n",
    "            print(f\"✅ 代替パスに保存完了: {alternative_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 代替保存も失敗: {e}\")\n",
    "\n",
    "# === 複数ファイル処理実行 ===\n",
    "print(\"🎯 複数ファイルの最適化された統計計算を開始...\")\n",
    "print(f\"📁 処理対象ファイル数: {len(h5_files)}\")\n",
    "\n",
    "total_start_time = time.time()\n",
    "processed_files = 0\n",
    "failed_files = []\n",
    "\n",
    "for file_idx, h5_path in enumerate(h5_files, 1):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"📂 ファイル {file_idx}/{len(h5_files)}: {os.path.basename(h5_path)}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # ファイル存在確認\n",
    "    if not os.path.exists(h5_path):\n",
    "        print(f\"❌ ファイルが見つかりません: {h5_path}\")\n",
    "        failed_files.append(h5_path)\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # 単一ファイル処理\n",
    "        result, output_csv = process_single_file(h5_path)\n",
    "        \n",
    "        # 結果保存\n",
    "        save_results(result, output_csv)\n",
    "        \n",
    "        processed_files += 1\n",
    "        \n",
    "        # メモリクリーンアップ\n",
    "        del result\n",
    "        if GPU_AVAILABLE:\n",
    "            cp.get_default_memory_pool().free_all_blocks()\n",
    "        \n",
    "        print(f\"✅ ファイル {file_idx} 完了: {os.path.basename(h5_path)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ ファイル {file_idx} 処理エラー: {e}\")\n",
    "        failed_files.append(h5_path)\n",
    "        continue\n",
    "\n",
    "# === 全体処理結果サマリー ===\n",
    "total_elapsed = time.time() - total_start_time\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"🎉 全ファイル処理完了!\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"📊 処理統計:\")\n",
    "print(f\"  ✅ 成功: {processed_files}/{len(h5_files)} ファイル\")\n",
    "print(f\"  ❌ 失敗: {len(failed_files)} ファイル\")\n",
    "print(f\"⏱️  総処理時間: {total_elapsed/60:.1f}分\")\n",
    "\n",
    "if failed_files:\n",
    "    print(f\"\\n⚠️ 失敗したファイル:\")\n",
    "    for failed_file in failed_files:\n",
    "        print(f\"  • {failed_file}\")\n",
    "\n",
    "print(\"\\n🧹 最終メモリクリーンアップ...\")\n",
    "if GPU_AVAILABLE:\n",
    "    try:\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "        print(\"🧹 GPU メモリクリーンアップ完了\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(\"🎯 全処理完了!\")\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# 褪色補正処理\n",
    "########################################################################\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import time\n",
    "import cupy as cp\n",
    "from scipy.signal import savgol_filter\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# === パラメータ（複数ファイル対応） ===\n",
    "calc_method = \"_top90_mean\"  # 使用する列のメソッド\n",
    "\n",
    "# 処理対象ファイルの定義\n",
    "file_configs = [\n",
    "    {\n",
    "        \"name\": \"20240508-174849tdTomato-12mW-3\",\n",
    "        \"csv_path\": r\"I:\\20240508-174849tdTomato-12mW-3_raw_gzip\\20240508-174849tdTomato-12mW-3_corrected_size_gpu_top90_mean.csv\",\n",
    "        \"h5_input_path\": r\"I:\\20240508-174849tdTomato-12mW-3_raw_gzip\\20240508-174849tdTomato-12mW-3_corrected_size_gpu.h5\",\n",
    "        \"h5_output_path\": r\"I:\\20240508-174849tdTomato-12mW-3_raw_gzip\\20240508-174849tdTomato-12mW-3_corrected_size_gpu_bleachcorrect{}.h5\"\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "# 共通パラメータ\n",
    "offset_value = 100\n",
    "scale_margin = 1.2\n",
    "chunk_size = 60  # メモリーサイズに応じて設定\n",
    "\n",
    "# === 褪色関数定義 ===\n",
    "def double_exp(t, a, b, c, d):\n",
    "    return a * np.exp(-b * t) + c * np.exp(-d * t)\n",
    "\n",
    "# === チャンネル別褪色カーブ推定 ===\n",
    "def estimate_bleach_curves(csv_path, file_name):\n",
    "    \"\"\"各チャンネルの褪色カーブを独立して推定\"\"\"\n",
    "    print(f\"\\n🔬 {file_name} の褪色カーブ推定開始...\")\n",
    "    \n",
    "    # ファイル存在確認\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"❌ CSVファイルが見つかりません: {csv_path}\")\n",
    "        return None\n",
    "    \n",
    "    df = pd.read_csv(csv_path)\n",
    "    t = np.arange(len(df))\n",
    "    \n",
    "    bleach_params = {}\n",
    "    scale_factors = {}\n",
    "    \n",
    "    # チャンネル数の自動検出\n",
    "    mean_columns = [col for col in df.columns if col.endswith(calc_method)]\n",
    "    channel_numbers = [int(col.split('_')[0][2:]) for col in mean_columns if col.startswith('ch')]\n",
    "    \n",
    "    print(f\"🔍 検出されたチャンネル: {channel_numbers}\")\n",
    "    \n",
    "    if not channel_numbers:\n",
    "        print(f\"⚠️ 有効なチャンネルが見つかりません\")\n",
    "        return None\n",
    "    \n",
    "    for ch_num in channel_numbers:\n",
    "        column_name = f\"ch{ch_num}{calc_method}\"\n",
    "        \n",
    "        if column_name not in df.columns:\n",
    "            print(f\"⚠️ 列 '{column_name}' が見つかりません。スキップします。\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n--- Channel {ch_num} 褪色カーブ推定 ---\")\n",
    "        \n",
    "        y_raw = df[column_name].to_numpy()\n",
    "        # SGフィルタ適用（ウィンドウサイズ13, 多項式次数1）\n",
    "        y_smooth = savgol_filter(y_raw, window_length=13, polyorder=1, mode='interp')\n",
    "        \n",
    "        # 初期値と上限の推定\n",
    "        a0 = c0 = y_smooth[0] / 2\n",
    "        p0 = [a0, 0.01, c0, 0.001]\n",
    "        y_max = np.nanmax(y_smooth)\n",
    "        upper_limit = y_max * scale_margin\n",
    "        bounds = ([0, 0, 0, 0], [upper_limit, 1, upper_limit, 1])\n",
    "        \n",
    "        try:\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                popt, _ = curve_fit(double_exp, t, y_smooth, p0=p0, bounds=bounds, maxfev=10000)\n",
    "            \n",
    "            fitted = double_exp(t, *popt)\n",
    "            scale = double_exp(0, *popt) / fitted  # t=0で正規化\n",
    "            \n",
    "            bleach_params[ch_num] = popt\n",
    "            scale_factors[ch_num] = scale\n",
    "            \n",
    "            print(f\"✅ Ch{ch_num} フィッティング完了: a={popt[0]:.2f}, b={popt[1]:.4f}, c={popt[2]:.2f}, d={popt[3]:.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Ch{ch_num} フィッティング失敗: {e}\")\n",
    "            # フォールバック: スケールファクター=1（補正なし）\n",
    "            scale_factors[ch_num] = np.ones_like(t)\n",
    "    \n",
    "    # プロット作成・保存\n",
    "    if bleach_params:\n",
    "        try:\n",
    "            fig, axes = plt.subplots(1, len(channel_numbers), figsize=(6 * len(channel_numbers), 4), sharey=True)\n",
    "            if len(channel_numbers) == 1:\n",
    "                axes = [axes]\n",
    "            \n",
    "            for idx, ch in enumerate(channel_numbers):\n",
    "                col_name = f\"ch{ch}{calc_method}\"\n",
    "                y = df[col_name].to_numpy()\n",
    "                if ch in bleach_params:\n",
    "                    fit = double_exp(t, *bleach_params[ch])\n",
    "                    corrected = y * scale_factors[ch]\n",
    "                else:\n",
    "                    fit = np.ones_like(t) * y[0]\n",
    "                    corrected = y\n",
    "                    \n",
    "                axes[idx].plot(t, y, 'o', label=f'Ch{ch} Raw', markersize=2)\n",
    "                axes[idx].plot(t, fit, '-', label=f'Ch{ch} Fit', linewidth=2)\n",
    "                axes[idx].plot(t, corrected, '--', label=f'Ch{ch} Corrected', linewidth=2)\n",
    "                axes[idx].set_title(f'Channel {ch} Bleach Curve')\n",
    "                axes[idx].set_xlabel('Time')\n",
    "                axes[idx].legend()\n",
    "                \n",
    "            axes[0].set_ylabel('Intensity')\n",
    "            plt.suptitle(f'{file_name} - Bleach Correction')\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # ファイル名に対応した保存\n",
    "            plot_filename = f'bleach_curve_{file_name}{calc_method}.png'\n",
    "            plt.savefig(plot_filename, dpi=150, bbox_inches='tight')\n",
    "            print(f\"📊 プロット保存: {plot_filename}\")\n",
    "            plt.show()\n",
    "            \n",
    "        except Exception as plot_error:\n",
    "            print(f\"⚠️ プロット作成エラー: {plot_error}\")\n",
    "    \n",
    "    return scale_factors\n",
    "\n",
    "# GPU可用性チェック\n",
    "try:\n",
    "    GPU_AVAILABLE = True\n",
    "    gpu_props = cp.cuda.runtime.getDeviceProperties(0)\n",
    "    gpu_name = gpu_props['name'].decode('utf-8')\n",
    "    total_memory_gb = cp.cuda.Device().mem_info[1] / (1024**3)\n",
    "    print(\"🚀 GPU処理が利用可能です\")\n",
    "    print(f\"🎮 GPU: {gpu_name}\")\n",
    "    print(f\"💾 VRAM: {total_memory_gb:.1f}GB\")\n",
    "except ImportError:\n",
    "    GPU_AVAILABLE = False\n",
    "    print(\"⚠️ CuPyが利用できません。CPU処理を使用します\")\n",
    "\n",
    "def process_with_gpu_multichannel(h5_input_path, h5_output_path, scale_factors_all, file_name):\n",
    "    \"\"\"チャンネル別褪色補正GPU処理（全ボリューム対応）\"\"\"\n",
    "    if not GPU_AVAILABLE:\n",
    "        print(\"❌ GPU処理をスキップします\")\n",
    "        return False\n",
    "    \n",
    "    if not scale_factors_all:\n",
    "        print(\"❌ スケールファクターが利用できません\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"\\n🎮 {file_name} のGPU褪色補正処理開始...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        with h5py.File(h5_input_path, \"r\") as f_in, h5py.File(h5_output_path, \"w\") as f_out:\n",
    "            dset_in = f_in[\"/default\"]\n",
    "            T_full, C, Z, Y, X = dset_in.shape\n",
    "            \n",
    "            print(f\"📐 データ形状: (T={T_full}, C={C}, Z={Z}, Y={Y}, X={X})\")\n",
    "            print(f\"🎯 処理対象: 全ボリューム（{T_full}フレーム）\")\n",
    "            \n",
    "            # 出力データセット作成（全ボリューム）\n",
    "            dset_out = f_out.create_dataset(\n",
    "                \"/default\", \n",
    "                shape=(T_full, C, Z, Y, X),\n",
    "                dtype='uint16',\n",
    "                chunks=(min(chunk_size//4, 20), 1, Z, Y, X),\n",
    "                compression=\"gzip\",\n",
    "                compression_opts=1\n",
    "            )\n",
    "            \n",
    "            # メタデータ追加\n",
    "            dset_out.attrs['processing_mode'] = 'multichannel_bleach_correction_full'\n",
    "            dset_out.attrs['file_name'] = file_name\n",
    "            dset_out.attrs['chunk_size'] = chunk_size\n",
    "            dset_out.attrs['offset_value'] = offset_value\n",
    "            dset_out.attrs['processed_frames'] = T_full\n",
    "            dset_out.attrs['frame_range'] = f\"0-{T_full-1}\"\n",
    "            \n",
    "            # チャンネル別スケールファクターの準備\n",
    "            scale_factors_gpu = {}\n",
    "            for ch_num in range(C):\n",
    "                if ch_num in scale_factors_all:\n",
    "                    # 全フレーム分を取得\n",
    "                    scale_factors_gpu[ch_num] = cp.asarray(\n",
    "                        scale_factors_all[ch_num], dtype=cp.float32\n",
    "                    )\n",
    "                    print(f\"✅ Ch{ch_num}: GPU用スケールファクター準備完了（{T_full}フレーム）\")\n",
    "                else:\n",
    "                    scale_factors_gpu[ch_num] = cp.ones(T_full, dtype=cp.float32)\n",
    "                    print(f\"⚠️ Ch{ch_num}: スケールファクターなし（補正スキップ）\")\n",
    "            \n",
    "            # チャンク処理メインループ（全フレーム）\n",
    "            for t_start in tqdm(range(0, T_full, chunk_size), desc=f\"🎮 {file_name} GPU褪色補正\"):\n",
    "                t_end = min(t_start + chunk_size, T_full)\n",
    "                current_chunk_size = t_end - t_start\n",
    "                \n",
    "                try:\n",
    "                    # メモリ使用量監視\n",
    "                    memory_before = cp.cuda.Device().mem_info[0] / (1024**3)\n",
    "                    \n",
    "                    # チャンネル別処理\n",
    "                    for c in range(C):\n",
    "                        # CPUからGPUへデータ転送\n",
    "                        vol_chunk = cp.asarray(\n",
    "                            dset_in[t_start:t_end, c, :, :, :], \n",
    "                            dtype=cp.float32\n",
    "                        )\n",
    "                        \n",
    "                        # チャンネル専用スケールファクター取得\n",
    "                        scale_chunk = scale_factors_gpu[c][t_start:t_end]\n",
    "                        \n",
    "                        # GPU上でベクトル化処理\n",
    "                        vol_chunk -= offset_value  # オフセット減算\n",
    "                        vol_chunk *= scale_chunk.reshape(-1, 1, 1, 1)  # チャンネル別褪色補正\n",
    "                        vol_chunk = cp.clip(vol_chunk, 0, 65535)  # クリッピング\n",
    "                        \n",
    "                        # 型変換と結果保存\n",
    "                        vol_chunk = vol_chunk.astype(cp.uint16)\n",
    "                        result = cp.asnumpy(vol_chunk)\n",
    "                        dset_out[t_start:t_end, c, :, :, :] = result\n",
    "                        \n",
    "                        # メモリクリーンアップ（チャンネル毎）\n",
    "                        del vol_chunk, result\n",
    "                        cp.cuda.Stream.null.synchronize()\n",
    "                    \n",
    "                    # 進捗情報表示\n",
    "                    if t_start % (chunk_size * 5) == 0:\n",
    "                        elapsed = time.time() - start_time\n",
    "                        processed_frames = t_end\n",
    "                        fps = processed_frames / elapsed if elapsed > 0 else 0\n",
    "                        remaining_frames = T_full - processed_frames\n",
    "                        eta_minutes = (remaining_frames / fps / 60) if fps > 0 else 0\n",
    "                        \n",
    "                        print(f\"  📊 進捗: {processed_frames}/{T_full} ({100*processed_frames/T_full:.1f}%)\")\n",
    "                        print(f\"  🚀 速度: {fps:.1f}fps, VRAM: {memory_before:.1f}GB, ETA: {eta_minutes:.1f}分\")\n",
    "                        \n",
    "                except cp.cuda.memory.OutOfMemoryError:\n",
    "                    print(f\"💥 GPU メモリ不足 (chunk_size={chunk_size})\")\n",
    "                    cp.get_default_memory_pool().free_all_blocks()\n",
    "                    continue\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"❌ 処理エラー (t={t_start}-{t_end}): {e}\")\n",
    "                    continue\n",
    "        \n",
    "        # 最終メモリクリーンアップ\n",
    "        try:\n",
    "            channel_keys = list(scale_factors_gpu.keys())\n",
    "            for ch_num in channel_keys:\n",
    "                if ch_num in scale_factors_gpu:\n",
    "                    del scale_factors_gpu[ch_num]\n",
    "            cp.get_default_memory_pool().free_all_blocks()\n",
    "        except Exception as cleanup_error:\n",
    "            print(f\"⚠️ メモリクリーンアップ中にエラー: {cleanup_error}\")\n",
    "            try:\n",
    "                cp.get_default_memory_pool().free_all_blocks()\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # 処理結果サマリー\n",
    "        total_elapsed = time.time() - start_time\n",
    "        average_fps = T_full / total_elapsed if total_elapsed > 0 else 0\n",
    "        \n",
    "        print(f\"\\n🎉 {file_name} 褪色補正GPU処理完了!\")\n",
    "        print(f\"📊 処理フレーム数: {T_full}\")\n",
    "        print(f\"🔄 処理チャンネル数: {C}\")\n",
    "        print(f\"⏱️  総処理時間: {total_elapsed/60:.1f}分\")\n",
    "        print(f\"🚀 平均処理速度: {average_fps:.1f}フレーム/秒\")\n",
    "        print(f\"💾 出力ファイル: {h5_output_path}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ {file_name} 処理中にエラーが発生: {e}\")\n",
    "        return False\n",
    "\n",
    "# === 複数ファイル処理実行 ===\n",
    "print(\"🎯 複数ファイルの褪色補正処理を開始...\")\n",
    "print(f\"📁 処理対象ファイル数: {len(file_configs)}\")\n",
    "\n",
    "total_start_time = time.time()\n",
    "processed_files = 0\n",
    "failed_files = []\n",
    "\n",
    "for file_idx, config in enumerate(file_configs, 1):\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"📂 ファイル {file_idx}/{len(file_configs)}: {config['name']}\")\n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    # ファイル存在確認\n",
    "    if not os.path.exists(config['csv_path']):\n",
    "        print(f\"❌ CSVファイルが見つかりません: {config['csv_path']}\")\n",
    "        failed_files.append(config['name'])\n",
    "        continue\n",
    "        \n",
    "    if not os.path.exists(config['h5_input_path']):\n",
    "        print(f\"❌ 入力H5ファイルが見つかりません: {config['h5_input_path']}\")\n",
    "        failed_files.append(config['name'])\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # 1. 褪色カーブ推定\n",
    "        scale_factors_all = estimate_bleach_curves(\n",
    "            config['csv_path'], \n",
    "            config['name']\n",
    "        )\n",
    "        \n",
    "        if scale_factors_all is None:\n",
    "            print(f\"❌ {config['name']}: 褪色カーブ推定に失敗\")\n",
    "            failed_files.append(config['name'])\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n✅ {config['name']}: 全チャンネルの褪色カーブ推定完了\")\n",
    "        \n",
    "        # 2. 出力パス設定\n",
    "        h5_output_path = config['h5_output_path'].format(calc_method)\n",
    "        \n",
    "        # 3. GPU褪色補正処理\n",
    "        if GPU_AVAILABLE and scale_factors_all:\n",
    "            success = process_with_gpu_multichannel(\n",
    "                config['h5_input_path'],\n",
    "                h5_output_path,\n",
    "                scale_factors_all,\n",
    "                config['name']\n",
    "            )\n",
    "            \n",
    "            if success:\n",
    "                processed_files += 1\n",
    "                print(f\"✅ ファイル {file_idx} 完了: {config['name']}\")\n",
    "            else:\n",
    "                failed_files.append(config['name'])\n",
    "        else:\n",
    "            print(\"⚠️ GPU処理またはスケールファクターが利用できません\")\n",
    "            failed_files.append(config['name'])\n",
    "        \n",
    "        # メモリクリーンアップ\n",
    "        del scale_factors_all\n",
    "        if GPU_AVAILABLE:\n",
    "            cp.get_default_memory_pool().free_all_blocks()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ ファイル {file_idx} 処理エラー: {e}\")\n",
    "        failed_files.append(config['name'])\n",
    "        continue\n",
    "\n",
    "# === 全体処理結果サマリー ===\n",
    "total_elapsed = time.time() - total_start_time\n",
    "\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(f\"🎉 全ファイル褪色補正処理完了!\")\n",
    "print(f\"{'='*100}\")\n",
    "print(f\"📊 処理統計:\")\n",
    "print(f\"  ✅ 成功: {processed_files}/{len(file_configs)} ファイル\")\n",
    "print(f\"  ❌ 失敗: {len(failed_files)} ファイル\")\n",
    "print(f\"⏱️  総処理時間: {total_elapsed/60:.1f}分\")\n",
    "\n",
    "if failed_files:\n",
    "    print(f\"\\n⚠️ 失敗したファイル:\")\n",
    "    for failed_file in failed_files:\n",
    "        print(f\"  • {failed_file}\")\n",
    "\n",
    "print(\"\\n🧹 最終メモリクリーンアップ...\")\n",
    "if GPU_AVAILABLE:\n",
    "    try:\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "        print(\"🧹 GPU メモリクリーンアップ完了\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(\"🎯 全褪色補正処理完了!\")\n",
    "\n",
    "########################################################################\n",
    "# MIP画像の生成\n",
    "########################################################################\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# GPU可用性チェック\n",
    "try:\n",
    "    import cupy as cp\n",
    "    GPU_AVAILABLE = True\n",
    "    print(\"🚀 GPU処理が利用可能です\")\n",
    "    \n",
    "    # GPU情報表示\n",
    "    gpu_props = cp.cuda.runtime.getDeviceProperties(0)\n",
    "    gpu_name = gpu_props['name'].decode('utf-8')\n",
    "    total_memory_gb = cp.cuda.Device().mem_info[1] / (1024**3)\n",
    "    print(f\"🎮 GPU: {gpu_name}\")\n",
    "    print(f\"💾 VRAM: {total_memory_gb:.1f}GB\")\n",
    "    \n",
    "except ImportError:\n",
    "    GPU_AVAILABLE = False\n",
    "    print(\"⚠️ CPU処理を使用します\")\n",
    "\n",
    "# === パラメータ（複数ファイル対応） ===\n",
    "# 処理対象ファイルの定義\n",
    "# orthogonal_configs = [\n",
    "#     {\n",
    "#         \"name\": \"20240508-200229tdTomato-10mW-4\",\n",
    "#         \"hdf5_file\": r\"I:\\20240508-200229tdTomato-10mW-4_raw_gzip\\20240508-200229tdTomato-10mW-4_raw_gzip_bleachcorrect_top90_mean.h5\",\n",
    "#         \"output_path\": r\"I:\\20240508-200229tdTomato-10mW-4_raw_gzip\\orthogonal_views\"\n",
    "#     },\n",
    "#     {\n",
    "#         \"name\": \"20240516-203245tdTomato-7mW-3\",\n",
    "#         \"hdf5_file\": r\"I:\\20240516-203245tdTomato-7mW-3_raw_gzip\\20240516-203245tdTomato-7mW-3_raw_gzip_bleachcorrect_top90_mean.h5\",\n",
    "#         \"output_path\": r\"I:\\20240516-203245tdTomato-7mW-3_raw_gzip\\orthogonal_views\"\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "\n",
    "orthogonal_configs = [\n",
    "    {\n",
    "        \"name\": \"20240508-174849tdTomato-12mW-3\",\n",
    "        \"hdf5_file\": r\"I:\\20240508-174849tdTomato-12mW-3_raw_gzip\\20240508-174849tdTomato-12mW-3_corrected_size_gpu_bleachcorrect_top90_mean.h5\",\n",
    "        \"output_path\": r\"I:\\20240508-174849tdTomato-12mW-3_raw_gzip\\orthogonal_views\"\n",
    "    }\n",
    "]\n",
    "\n",
    "chunk_size = 100 if GPU_AVAILABLE else 50  # GPU使用時はより大きなチャンク\n",
    "\n",
    "def process_cpu_chunk(chunk_data, t_start, t_end, orthogonal_view, channels, z, y, x):\n",
    "    \"\"\"CPU処理用のヘルパー関数\"\"\"\n",
    "    for i, t in enumerate(range(t_start, t_end)):\n",
    "        for c in range(channels):\n",
    "            data = chunk_data[i, c]  # (Z, Y, X)\n",
    "            \n",
    "            # CPU上で最大投影\n",
    "            xy_proj = np.max(data, axis=0)  # (Y, X)\n",
    "            yz_proj = np.max(data, axis=2).T  # (Z, Y)\n",
    "            xz_proj = np.max(data, axis=1)  # (Z, X)\n",
    "            \n",
    "            # 直交ビューへの配置\n",
    "            orthogonal_view[t, c, 0:y, 0:x] = xy_proj\n",
    "            orthogonal_view[t, c, 0:y, x+3:x+z+3] = yz_proj\n",
    "            orthogonal_view[t, c, y+3:y+z+3, 0:x] = xz_proj\n",
    "            orthogonal_view[t, c, y+z+2, x+z+2] = 1000\n",
    "\n",
    "def process_orthogonal_projections_single(hdf5_file, output_path, file_name):\n",
    "    \"\"\"単一ファイルの直交投影処理\"\"\"\n",
    "    print(f\"\\n🎯 {file_name} の直交投影処理開始...\")\n",
    "    \n",
    "    # ファイル存在確認\n",
    "    if not os.path.exists(hdf5_file):\n",
    "        print(f\"❌ H5ファイルが見つかりません: {hdf5_file}\")\n",
    "        return False\n",
    "    \n",
    "    # 出力フォルダ作成\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "        print(f\"📁 出力フォルダ作成: {output_path}\")\n",
    "    \n",
    "    dirname = os.path.splitext(os.path.basename(hdf5_file))[0]\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # === HDF5ファイル情報取得 ===\n",
    "        with h5py.File(hdf5_file, 'r') as file:\n",
    "            array = file['default']\n",
    "            total_volumes, channels, z, y, x = array.shape\n",
    "            print(f\"📐 データ形状: (T={total_volumes}, C={channels}, Z={z}, Y={y}, X={x})\")\n",
    "            print(f\"🎯 処理対象: 全ボリューム（{total_volumes}フレーム）\")\n",
    "        \n",
    "        # === 出力配列の準備（全ボリューム） ===\n",
    "        orthogonal_view = np.zeros((total_volumes, channels, y + z + 3, x + z + 3), dtype='uint16')\n",
    "        print(f\"💾 メモリ確保: {orthogonal_view.nbytes / (1024**3):.2f}GB\")\n",
    "        \n",
    "        def process_orthogonal_projections():\n",
    "            \"\"\"直交投影処理（CPU/GPU自動選択・全ボリューム）\"\"\"\n",
    "            use_gpu = GPU_AVAILABLE  # ローカル変数として処理状態を管理\n",
    "            \n",
    "            with h5py.File(hdf5_file, 'r') as file:\n",
    "                array = file['default']\n",
    "                \n",
    "                for t_start in tqdm(range(0, total_volumes, chunk_size), \n",
    "                                   desc=f\"🎮 {file_name} GPU直交投影\" if use_gpu else f\"🖥️ {file_name} CPU直交投影\"):\n",
    "                    t_end = min(t_start + chunk_size, total_volumes)\n",
    "                    \n",
    "                    # チャンクデータ読み込み\n",
    "                    chunk_data = array[t_start:t_end]  # (chunk_size, C, Z, Y, X)\n",
    "                    \n",
    "                    if use_gpu:\n",
    "                        # GPU処理を試行\n",
    "                        try:\n",
    "                            chunk_gpu = cp.asarray(chunk_data)\n",
    "                            \n",
    "                            for i, t in enumerate(range(t_start, t_end)):\n",
    "                                for c in range(channels):\n",
    "                                    data_gpu = chunk_gpu[i, c]  # (Z, Y, X)\n",
    "                                    \n",
    "                                    # GPU上で最大投影\n",
    "                                    xy_proj = cp.max(data_gpu, axis=0)  # (Y, X)\n",
    "                                    yz_proj = cp.max(data_gpu, axis=2).T  # (Z, Y)\n",
    "                                    xz_proj = cp.max(data_gpu, axis=1)  # (Z, X)\n",
    "                                    \n",
    "                                    # CPU側に結果をコピー\n",
    "                                    orthogonal_view[t, c, 0:y, 0:x] = cp.asnumpy(xy_proj)\n",
    "                                    orthogonal_view[t, c, 0:y, x+3:x+z+3] = cp.asnumpy(yz_proj)\n",
    "                                    orthogonal_view[t, c, y+3:y+z+3, 0:x] = cp.asnumpy(xz_proj)\n",
    "                                    orthogonal_view[t, c, y+z+2, x+z+2] = 1000\n",
    "                            \n",
    "                            # GPUメモリクリーンアップ\n",
    "                            del chunk_gpu\n",
    "                            cp.get_default_memory_pool().free_all_blocks()\n",
    "                            \n",
    "                            # 進捗情報表示（GPU処理）\n",
    "                            if t_start % (chunk_size * 5) == 0:\n",
    "                                processed = t_end\n",
    "                                progress_pct = 100 * processed / total_volumes\n",
    "                                elapsed = time.time() - start_time\n",
    "                                fps = processed / elapsed if elapsed > 0 else 0\n",
    "                                eta_minutes = ((total_volumes - processed) / fps / 60) if fps > 0 else 0\n",
    "                                print(f\"  📊 GPU進捗: {processed}/{total_volumes} ({progress_pct:.1f}%), 速度: {fps:.1f}fps, ETA: {eta_minutes:.1f}分\")\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            print(f\"⚠️ GPU処理エラー、CPUにフォールバック: {e}\")\n",
    "                            use_gpu = False  # 今後のチャンクはCPU処理\n",
    "                            # CPU処理で再試行\n",
    "                            process_cpu_chunk(chunk_data, t_start, t_end, orthogonal_view, channels, z, y, x)\n",
    "                            \n",
    "                    else:\n",
    "                        # CPU処理\n",
    "                        process_cpu_chunk(chunk_data, t_start, t_end, orthogonal_view, channels, z, y, x)\n",
    "                        \n",
    "                        # 進捗情報表示（CPU処理）\n",
    "                        if t_start % (chunk_size * 2) == 0:\n",
    "                            processed = t_end\n",
    "                            progress_pct = 100 * processed / total_volumes\n",
    "                            elapsed = time.time() - start_time\n",
    "                            fps = processed / elapsed if elapsed > 0 else 0\n",
    "                            eta_minutes = ((total_volumes - processed) / fps / 60) if fps > 0 else 0\n",
    "                            print(f\"  📊 CPU進捗: {processed}/{total_volumes} ({progress_pct:.1f}%), 速度: {fps:.1f}fps, ETA: {eta_minutes:.1f}分\")\n",
    "        \n",
    "        # === 処理実行 ===\n",
    "        print(f\"🎯 全ボリューム（{total_volumes}フレーム）の直交投影処理を開始...\")\n",
    "        process_orthogonal_projections()\n",
    "        print(\"🎉 直交投影処理完了!\")\n",
    "        \n",
    "        # === TIFF保存（全ボリューム） ===\n",
    "        file_name_tiff = f\"orthogonal_view_{dirname}_full.tif\"\n",
    "        output_path_full = os.path.join(output_path, file_name_tiff)\n",
    "        \n",
    "        print(\"💾 TIFF保存中...\")\n",
    "        print(f\"📁 保存先: {output_path_full}\")\n",
    "        print(f\"📊 データサイズ: {orthogonal_view.nbytes / (1024**3):.2f}GB\")\n",
    "        \n",
    "        try:\n",
    "            tiff.imwrite(\n",
    "                output_path_full, \n",
    "                orthogonal_view, \n",
    "                imagej=True, \n",
    "                metadata={'axes': 'TCYX'}, \n",
    "                compression='zlib'\n",
    "            )\n",
    "            \n",
    "            # 処理結果サマリー\n",
    "            total_elapsed = time.time() - start_time\n",
    "            average_fps = total_volumes / total_elapsed if total_elapsed > 0 else 0\n",
    "            \n",
    "            print(f\"✅ {file_name} 処理完了: {output_path_full}\")\n",
    "            print(f\"📈 出力形状: {orthogonal_view.shape}\")\n",
    "            print(f\"⏱️  総処理時間: {total_elapsed/60:.1f}分\")\n",
    "            print(f\"🚀 平均処理速度: {average_fps:.1f}フレーム/秒\")\n",
    "            print(f\"📊 処理統計: {total_volumes}/{total_volumes}ボリューム (100%)\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as save_error:\n",
    "            print(f\"❌ TIFF保存エラー: {save_error}\")\n",
    "            print(\"💡 メモリ不足の可能性があります。チャンク保存を試します...\")\n",
    "            \n",
    "            # === フォールバック: チャンク保存 ===\n",
    "            save_chunk_size = 500  # 500フレームずつ保存\n",
    "            \n",
    "            for save_start in tqdm(range(0, total_volumes, save_chunk_size), desc=\"📦 チャンク保存\"):\n",
    "                save_end = min(save_start + save_chunk_size, total_volumes)\n",
    "                chunk_name = f\"orthogonal_view_{dirname}_part{save_start:05d}-{save_end:05d}.tif\"\n",
    "                chunk_path = os.path.join(output_path, chunk_name)\n",
    "                \n",
    "                chunk_data = orthogonal_view[save_start:save_end]\n",
    "                tiff.imwrite(\n",
    "                    chunk_path,\n",
    "                    chunk_data,\n",
    "                    imagej=True,\n",
    "                    metadata={'axes': 'TCYX'},\n",
    "                    compression='zlib'\n",
    "                )\n",
    "                print(f\"✅ 保存完了: {chunk_name}\")\n",
    "            \n",
    "            print(f\"📦 チャンク保存完了: {output_path}\")\n",
    "            return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ {file_name} 処理中にエラーが発生: {e}\")\n",
    "        return False\n",
    "    \n",
    "    finally:\n",
    "        # === メモリクリーンアップ ===\n",
    "        try:\n",
    "            if 'orthogonal_view' in locals():\n",
    "                del orthogonal_view\n",
    "            if GPU_AVAILABLE:\n",
    "                cp.get_default_memory_pool().free_all_blocks()\n",
    "            print(\"🧹 メモリクリーンアップ完了\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# === 複数ファイル処理実行 ===\n",
    "print(\"🎯 複数ファイルの直交投影処理を開始...\")\n",
    "print(f\"📁 処理対象ファイル数: {len(orthogonal_configs)}\")\n",
    "\n",
    "total_start_time = time.time()\n",
    "processed_files = 0\n",
    "failed_files = []\n",
    "\n",
    "for file_idx, config in enumerate(orthogonal_configs, 1):\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"📂 ファイル {file_idx}/{len(orthogonal_configs)}: {config['name']}\")\n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    # ファイル存在確認\n",
    "    if not os.path.exists(config['hdf5_file']):\n",
    "        print(f\"❌ H5ファイルが見つかりません: {config['hdf5_file']}\")\n",
    "        failed_files.append(config['name'])\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # 単一ファイル処理\n",
    "        success = process_orthogonal_projections_single(\n",
    "            config['hdf5_file'],\n",
    "            config['output_path'],\n",
    "            config['name']\n",
    "        )\n",
    "        \n",
    "        if success:\n",
    "            processed_files += 1\n",
    "            print(f\"✅ ファイル {file_idx} 完了: {config['name']}\")\n",
    "        else:\n",
    "            failed_files.append(config['name'])\n",
    "        \n",
    "        # メモリクリーンアップ\n",
    "        if GPU_AVAILABLE:\n",
    "            cp.get_default_memory_pool().free_all_blocks()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ ファイル {file_idx} 処理エラー: {e}\")\n",
    "        failed_files.append(config['name'])\n",
    "        continue\n",
    "\n",
    "# === 全体処理結果サマリー ===\n",
    "total_elapsed = time.time() - total_start_time\n",
    "\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(f\"🎉 全ファイル直交投影処理完了!\")\n",
    "print(f\"{'='*100}\")\n",
    "print(f\"📊 処理統計:\")\n",
    "print(f\"  ✅ 成功: {processed_files}/{len(orthogonal_configs)} ファイル\")\n",
    "print(f\"  ❌ 失敗: {len(failed_files)} ファイル\")\n",
    "print(f\"⏱️  総処理時間: {total_elapsed/60:.1f}分\")\n",
    "\n",
    "if failed_files:\n",
    "    print(f\"\\n⚠️ 失敗したファイル:\")\n",
    "    for failed_file in failed_files:\n",
    "        print(f\"  • {failed_file}\")\n",
    "\n",
    "print(\"\\n🧹 最終メモリクリーンアップ...\")\n",
    "if GPU_AVAILABLE:\n",
    "    try:\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "        print(\"🧹 GPU メモリクリーンアップ完了\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(\"🎯 全直交投影処理完了!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd10727",
   "metadata": {},
   "source": [
    "For real-time tracking. Save each volume data as TIFF after bleach correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f437691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# === パラメータ ===\n",
    "hdf5_file = r\"I:\\20240508-174849tdTomato-12mW-3_raw_gzip\\20240508-174849tdTomato-12mW-3_corrected_size_gpu_bleachcorrect_top90_mean.h5\"\n",
    "output_path = r\"I:\\20240508-174849tdTomato-12mW-3_raw_gzip\\bleachcorrect\\images_resize\"\n",
    "channel_to_save = 0  # チャンネル0のみ保存\n",
    "max_volumes = 4900  # 保存する最大ボリューム数（0-4899の4900個）\n",
    "chunk_size = 50  # I/O効率化のためのチャンクサイズ\n",
    "\n",
    "# 出力フォルダ作成\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "    print(f\"📁 出力フォルダ作成: {output_path}\")\n",
    "\n",
    "def save_individual_volumes():\n",
    "    \"\"\"チャンネル0の各ボリュームを個別TIFFファイルとして保存（CPU版）\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # ファイル存在確認\n",
    "    if not os.path.exists(hdf5_file):\n",
    "        print(f\"❌ H5ファイルが見つかりません: {hdf5_file}\")\n",
    "        return False\n",
    "    \n",
    "    with h5py.File(hdf5_file, 'r') as file:\n",
    "        dset = file['default']\n",
    "        total_volumes, channels, z, y, x = dset.shape\n",
    "        \n",
    "        # 保存対象ボリューム数を制限\n",
    "        volumes_to_save = min(max_volumes, total_volumes)\n",
    "        \n",
    "        print(f\"📐 データ形状: (T={total_volumes}, C={channels}, Z={z}, Y={y}, X={x})\")\n",
    "        print(f\"🎯 処理対象: チャンネル{channel_to_save} の0-{volumes_to_save-1}ボリューム（{volumes_to_save}個）\")\n",
    "        print(f\"💾 各ボリュームサイズ: ({z}, {y}, {x})\")\n",
    "        \n",
    "        # チャンネル存在確認\n",
    "        if channel_to_save >= channels:\n",
    "            print(f\"❌ チャンネル{channel_to_save}は存在しません（利用可能: 0-{channels-1}）\")\n",
    "            return False\n",
    "        \n",
    "        # チャンク処理でI/O効率化\n",
    "        saved_count = 0\n",
    "        failed_count = 0\n",
    "        \n",
    "        for t_start in tqdm(range(0, volumes_to_save, chunk_size), \n",
    "                           desc=f\"💾 Ch{channel_to_save}ボリューム保存（0-{volumes_to_save-1}）\"):\n",
    "            t_end = min(t_start + chunk_size, volumes_to_save)\n",
    "            \n",
    "            try:\n",
    "                # チャンクデータ読み込み (chunk_size, Z, Y, X)\n",
    "                chunk_data = dset[t_start:t_end, channel_to_save, :, :, :]\n",
    "                \n",
    "                # 各ボリュームを個別に保存\n",
    "                for i, t in enumerate(range(t_start, t_end)):\n",
    "                    volume_data = chunk_data[i]  # (Z, Y, X)\n",
    "                    \n",
    "                    # ファイル名生成（ゼロパディングなし）\n",
    "                    tiff_filename = f\"corrected_volume_t{t}.tiff\"\n",
    "                    tiff_path = os.path.join(output_path, tiff_filename)\n",
    "                    \n",
    "                    try:\n",
    "                        # TIFF保存（CPU処理）\n",
    "                        tiff.imwrite(\n",
    "                            tiff_path,\n",
    "                            volume_data,\n",
    "                            imagej=True,\n",
    "                            metadata={'axes': 'ZYX'},\n",
    "                            compression='zlib'\n",
    "                        )\n",
    "                        \n",
    "                        saved_count += 1\n",
    "                        \n",
    "                        # 進捗情報（詳細）\n",
    "                        if t % 100 == 0:  # 100ボリューム毎に詳細情報表示\n",
    "                            elapsed = time.time() - start_time\n",
    "                            fps = saved_count / elapsed if elapsed > 0 else 0\n",
    "                            remaining = volumes_to_save - saved_count\n",
    "                            eta_minutes = (remaining / fps / 60) if fps > 0 else 0\n",
    "                            \n",
    "                            print(f\"  📊 進捗: {saved_count}/{volumes_to_save} ({100*saved_count/volumes_to_save:.1f}%)\")\n",
    "                            print(f\"  💾 速度: {fps:.1f}ボリューム/秒, ETA: {eta_minutes:.1f}分\")\n",
    "                            print(f\"  📄 最新保存: {tiff_filename}\")\n",
    "                        \n",
    "                    except Exception as save_error:\n",
    "                        print(f\"❌ ボリューム t{t} 保存エラー: {save_error}\")\n",
    "                        failed_count += 1\n",
    "                        continue\n",
    "                \n",
    "                # メモリクリーンアップ\n",
    "                del chunk_data\n",
    "                \n",
    "            except Exception as chunk_error:\n",
    "                print(f\"❌ チャンク t{t_start}-{t_end} 読み込みエラー: {chunk_error}\")\n",
    "                failed_count += chunk_size\n",
    "                continue\n",
    "    \n",
    "    # 処理結果サマリー\n",
    "    total_elapsed = time.time() - start_time\n",
    "    average_fps = saved_count / total_elapsed if total_elapsed > 0 else 0\n",
    "    \n",
    "    print(f\"\\n🎉 個別ボリューム保存完了!\")\n",
    "    print(f\"📊 保存統計:\")\n",
    "    print(f\"  ✅ 成功: {saved_count}/{volumes_to_save} ボリューム\")\n",
    "    print(f\"  ❌ 失敗: {failed_count} ボリューム\")\n",
    "    print(f\"⏱️  総処理時間: {total_elapsed/60:.1f}分\")\n",
    "    print(f\"💾 平均保存速度: {average_fps:.1f}ボリューム/秒\")\n",
    "    print(f\"📁 保存先: {output_path}\")\n",
    "    print(f\"📄 ファイル形式: corrected_volume_t0.tiff ～ corrected_volume_t{volumes_to_save-1}.tiff\")\n",
    "    \n",
    "    # 保存されたファイルのサンプル表示\n",
    "    print(f\"\\n📋 保存ファイル例:\")\n",
    "    sample_files = []\n",
    "    for t in [0, 1, 2, 10, 100, 1000, volumes_to_save//2, volumes_to_save-1]:\n",
    "        if t < volumes_to_save:\n",
    "            filename = f\"corrected_volume_t{t}.tiff\"\n",
    "            filepath = os.path.join(output_path, filename)\n",
    "            if os.path.exists(filepath):\n",
    "                file_size_mb = os.path.getsize(filepath) / (1024**2)\n",
    "                sample_files.append(f\"  📄 {filename} ({file_size_mb:.1f}MB)\")\n",
    "    \n",
    "    for sample in sample_files[:10]:  # 最大10個表示\n",
    "        print(sample)\n",
    "    \n",
    "    if len(sample_files) > 10:\n",
    "        print(f\"  ... 他 {len(sample_files)-10} ファイル\")\n",
    "    \n",
    "    return saved_count == volumes_to_save\n",
    "\n",
    "# === 実行 ===\n",
    "print(f\"🎯 チャンネル0の個別ボリューム保存を開始（0-{max_volumes-1}ボリューム）...\")\n",
    "print(\"💡 CPU版（ファイル保存に最適化）\")\n",
    "success = save_individual_volumes()\n",
    "\n",
    "if success:\n",
    "    print(\"✅ 指定範囲のボリューム保存が正常に完了しました！\")\n",
    "else:\n",
    "    print(\"⚠️ 一部のボリューム保存でエラーが発生しました。ログを確認してください。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745b1666",
   "metadata": {},
   "source": [
    "For spinning disk confocal microscope data. Make voxel size isotropic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c53289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from scipy.ndimage import zoom\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "\n",
    "# GPU可用性チェック（大容量データ処理用）\n",
    "try:\n",
    "    import cupy as cp\n",
    "    from cupyx.scipy.ndimage import zoom as cp_zoom\n",
    "    GPU_AVAILABLE = True\n",
    "    print(\"🚀 GPU処理が利用可能です\")\n",
    "    \n",
    "    # GPU情報表示\n",
    "    gpu_props = cp.cuda.runtime.getDeviceProperties(0)\n",
    "    gpu_name = gpu_props['name'].decode('utf-8')\n",
    "    total_memory_gb = cp.cuda.Device().mem_info[1] / (1024**3)\n",
    "    print(f\"🎮 GPU: {gpu_name}, VRAM: {total_memory_gb:.1f}GB\")\n",
    "    \n",
    "except ImportError:\n",
    "    GPU_AVAILABLE = False\n",
    "    print(\"⚠️ CPU処理を使用します（大容量データの場合時間がかかります）\")\n",
    "\n",
    "# === パラメータ ===\n",
    "input_h5_path = r\"I:\\20240911_cam2_007_raw\\20240911_cam2_007_raw.h5\"\n",
    "output_h5_path = r\"I:\\20240911_cam2_007_raw\\20240911_cam2_007_raw_affine.h5\"\n",
    "\n",
    "# 現在のvoxelサイズ\n",
    "original_voxel_size = {\n",
    "    'x': 0.43,  # μm\n",
    "    'y': 0.43,  # μm  \n",
    "    'z': 2.0    # μm\n",
    "}\n",
    "\n",
    "# 目標voxelサイズ（等方的）\n",
    "target_voxel_size = 0.43  # μm (xyz全て同じ)\n",
    "\n",
    "# チャンクサイズ（メモリ使用量に応じて調整）\n",
    "chunk_size = 20 if GPU_AVAILABLE else 10\n",
    "\n",
    "def calculate_zoom_factors():\n",
    "    \"\"\"ズーム倍率を計算\"\"\"\n",
    "    zoom_factors = {\n",
    "        'x': original_voxel_size['x'] / target_voxel_size,\n",
    "        'y': original_voxel_size['y'] / target_voxel_size,\n",
    "        'z': original_voxel_size['z'] / target_voxel_size\n",
    "    }\n",
    "    \n",
    "    print(f\"📐 元のvoxelサイズ: x={original_voxel_size['x']}μm, y={original_voxel_size['y']}μm, z={original_voxel_size['z']}μm\")\n",
    "    print(f\"🎯 目標voxelサイズ: {target_voxel_size}μm (等方的)\")\n",
    "    print(f\"🔍 ズーム倍率: x={zoom_factors['x']:.3f}, y={zoom_factors['y']:.3f}, z={zoom_factors['z']:.3f}\")\n",
    "    \n",
    "    return zoom_factors\n",
    "\n",
    "def calculate_output_shape(input_shape, zoom_factors):\n",
    "    \"\"\"出力データサイズを計算\"\"\"\n",
    "    t, z, y, x = input_shape\n",
    "    \n",
    "    new_z = int(z * zoom_factors['z'])\n",
    "    new_y = int(y * zoom_factors['y'])\n",
    "    new_x = int(x * zoom_factors['x'])\n",
    "    \n",
    "    print(f\"📏 元のデータ形状: (T={t}, Z={z}, Y={y}, X={x})\")\n",
    "    print(f\"📏 出力データ形状: (T={t}, Z={new_z}, Y={new_y}, X={new_x})\")\n",
    "    print(f\"📊 データサイズ変化: {t*z*y*x:,} → {t*new_z*new_y*new_x:,} voxels ({new_z*new_y*new_x/(z*y*x):.2f}倍)\")\n",
    "    \n",
    "    return (t, new_z, new_y, new_x)\n",
    "\n",
    "def process_volume_gpu(volume_data, zoom_factors):\n",
    "    \"\"\"GPU版ボリューム補間処理\"\"\"\n",
    "    try:\n",
    "        # CPUからGPUへデータ転送\n",
    "        volume_gpu = cp.asarray(volume_data, dtype=cp.float32)\n",
    "        \n",
    "        # 3D線形補間（Z, Y, X軸）\n",
    "        zoom_scales = (zoom_factors['z'], zoom_factors['y'], zoom_factors['x'])\n",
    "        interpolated_gpu = cp_zoom(volume_gpu, zoom_scales, order=1, mode='constant', cval=0)\n",
    "        \n",
    "        # データ型を元に戻してCPUに転送\n",
    "        result = cp.asnumpy(interpolated_gpu.astype(cp.uint16))\n",
    "        \n",
    "        # GPUメモリクリーンアップ\n",
    "        del volume_gpu, interpolated_gpu\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ GPU処理エラー、CPUにフォールバック: {e}\")\n",
    "        return process_volume_cpu(volume_data, zoom_factors)\n",
    "\n",
    "def process_volume_cpu(volume_data, zoom_factors):\n",
    "    \"\"\"CPU版ボリューム補間処理\"\"\"\n",
    "    # 3D線形補間（Z, Y, X軸）\n",
    "    zoom_scales = (zoom_factors['z'], zoom_factors['y'], zoom_factors['x'])\n",
    "    interpolated = zoom(volume_data.astype(np.float32), zoom_scales, order=1, mode='constant', cval=0)\n",
    "    \n",
    "    return interpolated.astype(np.uint16)\n",
    "\n",
    "def create_isotropic_voxel_data():\n",
    "    \"\"\"等方的voxelサイズのHDF5ファイルを作成\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # ファイル存在確認\n",
    "    if not os.path.exists(input_h5_path):\n",
    "        print(f\"❌ 入力ファイルが見つかりません: {input_h5_path}\")\n",
    "        return False\n",
    "    \n",
    "    # ズーム倍率計算\n",
    "    zoom_factors = calculate_zoom_factors()\n",
    "    \n",
    "    with h5py.File(input_h5_path, 'r') as f_in:\n",
    "        dset_in = f_in['/default']\n",
    "        input_shape = dset_in.shape  # (T, Z, Y, X)\n",
    "        \n",
    "        # 出力サイズ計算\n",
    "        output_shape = calculate_output_shape(input_shape, zoom_factors)\n",
    "        t_len, new_z, new_y, new_x = output_shape\n",
    "        \n",
    "        # メモリ使用量推定\n",
    "        input_size_gb = (np.prod(input_shape) * 2) / (1024**3)  # uint16 = 2bytes\n",
    "        output_size_gb = (np.prod(output_shape) * 2) / (1024**3)\n",
    "        \n",
    "        print(f\"💾 推定メモリ使用量:\")\n",
    "        print(f\"  入力データ: {input_size_gb:.2f}GB\")\n",
    "        print(f\"  出力データ: {output_size_gb:.2f}GB\")\n",
    "        print(f\"  処理チャンクサイズ: {chunk_size}フレーム\")\n",
    "        \n",
    "        # 出力ファイル作成\n",
    "        with h5py.File(output_h5_path, 'w') as f_out:\n",
    "            # 出力データセット作成\n",
    "            dset_out = f_out.create_dataset(\n",
    "                '/default',\n",
    "                shape=output_shape,\n",
    "                dtype='uint16',\n",
    "                chunks=(1, new_z, new_y, new_x),\n",
    "                compression='gzip',\n",
    "                compression_opts=1\n",
    "            )\n",
    "            \n",
    "            # メタデータ追加\n",
    "            dset_out.attrs['original_voxel_size_x_um'] = original_voxel_size['x']\n",
    "            dset_out.attrs['original_voxel_size_y_um'] = original_voxel_size['y']\n",
    "            dset_out.attrs['original_voxel_size_z_um'] = original_voxel_size['z']\n",
    "            dset_out.attrs['target_voxel_size_um'] = target_voxel_size\n",
    "            dset_out.attrs['zoom_factor_x'] = zoom_factors['x']\n",
    "            dset_out.attrs['zoom_factor_y'] = zoom_factors['y']\n",
    "            dset_out.attrs['zoom_factor_z'] = zoom_factors['z']\n",
    "            dset_out.attrs['interpolation_method'] = 'linear'\n",
    "            dset_out.attrs['processing_mode'] = 'isotropic_voxel_resampling'\n",
    "            dset_out.attrs['original_shape'] = input_shape\n",
    "            dset_out.attrs['resampled_shape'] = output_shape\n",
    "            \n",
    "            # チャンク処理でメモリ効率化\n",
    "            processed_frames = 0\n",
    "            \n",
    "            for t_start in tqdm(range(0, t_len, chunk_size), \n",
    "                               desc=f\"🔄 等方的voxel変換 ({'GPU' if GPU_AVAILABLE else 'CPU'})\"):\n",
    "                t_end = min(t_start + chunk_size, t_len)\n",
    "                \n",
    "                try:\n",
    "                    # チャンクデータ読み込み\n",
    "                    chunk_data = dset_in[t_start:t_end]  # (chunk_size, Z, Y, X)\n",
    "                    \n",
    "                    # 各フレームを個別に処理\n",
    "                    for i, t in enumerate(range(t_start, t_end)):\n",
    "                        volume = chunk_data[i]  # (Z, Y, X)\n",
    "                        \n",
    "                        # GPU/CPU処理の選択\n",
    "                        if GPU_AVAILABLE:\n",
    "                            resampled_volume = process_volume_gpu(volume, zoom_factors)\n",
    "                        else:\n",
    "                            resampled_volume = process_volume_cpu(volume, zoom_factors)\n",
    "                        \n",
    "                        # 結果保存\n",
    "                        dset_out[t] = resampled_volume\n",
    "                        processed_frames += 1\n",
    "                        \n",
    "                        # 進捗情報（詳細）\n",
    "                        if processed_frames % 50 == 0:\n",
    "                            elapsed = time.time() - start_time\n",
    "                            fps = processed_frames / elapsed if elapsed > 0 else 0\n",
    "                            remaining = t_len - processed_frames\n",
    "                            eta_minutes = (remaining / fps / 60) if fps > 0 else 0\n",
    "                            \n",
    "                            print(f\"  📊 進捗: {processed_frames}/{t_len} ({100*processed_frames/t_len:.1f}%)\")\n",
    "                            print(f\"  🚀 速度: {fps:.1f}フレーム/秒, ETA: {eta_minutes:.1f}分\")\n",
    "                    \n",
    "                    # メモリクリーンアップ\n",
    "                    del chunk_data\n",
    "                    if GPU_AVAILABLE:\n",
    "                        cp.get_default_memory_pool().free_all_blocks()\n",
    "                        \n",
    "                except Exception as chunk_error:\n",
    "                    print(f\"❌ チャンク t{t_start}-{t_end} 処理エラー: {chunk_error}\")\n",
    "                    continue\n",
    "    \n",
    "    # 処理結果サマリー\n",
    "    total_elapsed = time.time() - start_time\n",
    "    average_fps = processed_frames / total_elapsed if total_elapsed > 0 else 0\n",
    "    \n",
    "    print(f\"\\n🎉 等方的voxelサイズ変換完了!\")\n",
    "    print(f\"📊 処理統計:\")\n",
    "    print(f\"  ✅ 処理フレーム数: {processed_frames}/{t_len}\")\n",
    "    print(f\"  ⏱️  総処理時間: {total_elapsed/60:.1f}分\")\n",
    "    print(f\"  🚀 平均処理速度: {average_fps:.1f}フレーム/秒\")\n",
    "    print(f\"  📏 voxelサイズ変更: {original_voxel_size} → {target_voxel_size}μm (等方的)\")\n",
    "    print(f\"  📁 出力ファイル: {output_h5_path}\")\n",
    "    \n",
    "    # 出力ファイルサイズ確認\n",
    "    if os.path.exists(output_h5_path):\n",
    "        file_size_gb = os.path.getsize(output_h5_path) / (1024**3)\n",
    "        print(f\"  💾 出力ファイルサイズ: {file_size_gb:.2f}GB\")\n",
    "    \n",
    "    return processed_frames == t_len\n",
    "\n",
    "# === 実行 ===\n",
    "print(\"🎯 スピニング共焦点データの等方的voxelサイズ変換を開始...\")\n",
    "print(f\"📂 入力: {os.path.basename(input_h5_path)}\")\n",
    "print(f\"📂 出力: {os.path.basename(output_h5_path)}\")\n",
    "\n",
    "success = create_isotropic_voxel_data()\n",
    "\n",
    "if success:\n",
    "    print(\"\\n✅ 等方的voxelサイズ変換が正常に完了しました！\")\n",
    "    print(\"💡 次のステップ:\")\n",
    "    print(\"   1. 変換後データの品質確認\")\n",
    "    print(\"   2. 必要に応じて上位90%平均値の再計算\")\n",
    "    print(\"   3. 褪色補正処理の実行\")\n",
    "else:\n",
    "    print(\"\\n⚠️ 処理中にエラーが発生しました。ログを確認してください。\")\n",
    "\n",
    "# === 最終メモリクリーンアップ ===\n",
    "if GPU_AVAILABLE:\n",
    "    try:\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "        print(\"🧹 GPU メモリクリーンアップ完了\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0fd45e",
   "metadata": {},
   "source": [
    "For spinning disk confocal microscope data. Compute the top 90% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd878e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# GPU可用性チェック\n",
    "try:\n",
    "    import cupy as cp\n",
    "    GPU_AVAILABLE = True\n",
    "    print(\"🚀 GPU処理が利用可能です\")\n",
    "    \n",
    "    # GPU情報表示\n",
    "    gpu_props = cp.cuda.runtime.getDeviceProperties(0)\n",
    "    gpu_name = gpu_props['name'].decode('utf-8')\n",
    "    total_memory_gb = cp.cuda.Device().mem_info[1] / (1024**3)\n",
    "    print(f\"🎮 GPU: {gpu_name}, VRAM: {total_memory_gb:.1f}GB\")\n",
    "    \n",
    "except ImportError:\n",
    "    GPU_AVAILABLE = False\n",
    "    print(\"⚠️ CPU処理を使用します\")\n",
    "\n",
    "# === パラメータ ===\n",
    "h5_path = r\"I:\\20240911_cam2_007_raw\\20240911_cam2_007_raw_affine.h5\"\n",
    "dataset_name = \"/default\"\n",
    "output_csv = os.path.splitext(h5_path)[0] + \"_top90_mean.csv\"\n",
    "\n",
    "# 高速化パラメータ\n",
    "offset_value = 1600\n",
    "exclude_value = -1600\n",
    "chunk_size = 50 if GPU_AVAILABLE else 25  # GPU使用時はより大きなチャンク\n",
    "\n",
    "def process_volume_gpu(vol_chunk, offset_value, exclude_value):\n",
    "    \"\"\"GPU用のボリューム統計処理 (T, Z, Y, X)形状対応\"\"\"\n",
    "    try:\n",
    "        # GPUに転送\n",
    "        vol_gpu = cp.asarray(vol_chunk, dtype=cp.float32)\n",
    "        vol_gpu -= offset_value\n",
    "        \n",
    "        # 各統計の計算\n",
    "        stats = {}\n",
    "        \n",
    "        # -100除外統計\n",
    "        valid_mask = vol_gpu != exclude_value\n",
    "        valid_vals = vol_gpu[valid_mask]\n",
    "        \n",
    "        # 上位90%の平均値\n",
    "        percentiles = [90]\n",
    "        for p in percentiles:\n",
    "            if len(valid_vals) > 0:\n",
    "                thresh = cp.percentile(valid_vals, p)\n",
    "                top_vals = valid_vals[valid_vals >= thresh]\n",
    "                stats[f'top{p}_mean'] = float(cp.mean(top_vals)) if len(top_vals) > 0 else 0.0\n",
    "            else:\n",
    "                stats[f'top{p}_mean'] = 0.0\n",
    "        \n",
    "        # メモリクリーンアップ\n",
    "        del vol_gpu, valid_vals, top_vals, thresh\n",
    "        \n",
    "        return stats\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ GPU処理エラー: {e}\")\n",
    "        # CPUフォールバック\n",
    "        return process_volume_cpu(vol_chunk, offset_value, exclude_value)\n",
    "\n",
    "def process_volume_cpu(vol_chunk, offset_value, exclude_value):\n",
    "    \"\"\"CPU用のボリューム統計処理 (T, Z, Y, X)形状対応\"\"\"\n",
    "    vol = vol_chunk.astype(np.float32)\n",
    "    vol -= offset_value\n",
    "    \n",
    "    stats = {}\n",
    "    \n",
    "    # -100除外統計（ベクトル化）\n",
    "    valid_mask = vol != exclude_value\n",
    "    if np.any(valid_mask):\n",
    "        valid_vals = vol[valid_mask]\n",
    "        \n",
    "        # 上位90%の平均値\n",
    "        percentiles = [90]\n",
    "        for p in percentiles:\n",
    "            thresh = np.percentile(valid_vals, p)\n",
    "            top_vals = valid_vals[valid_vals >= thresh]\n",
    "            stats[f'top{p}_mean'] = float(np.mean(top_vals)) if len(top_vals) > 0 else 0.0\n",
    "    else:\n",
    "        stats['top90_mean'] = 0.0\n",
    "    \n",
    "    return stats\n",
    "\n",
    "def process_statistics_optimized():\n",
    "    \"\"\"最適化された統計処理（チャンク+GPU/CPU）- (T, Z, Y, X)形状対応\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    with h5py.File(h5_path, \"r\") as f:\n",
    "        dset = f[dataset_name]\n",
    "        t_len, z_len, y_len, x_len = dset.shape  # (T, Z, Y, X)\n",
    "        print(f\"📐 Dataset shape: {dset.shape} (T, Z, Y, X)\")\n",
    "        print(f\"🚀 処理モード: {'GPU' if GPU_AVAILABLE else 'CPU'}\")\n",
    "        print(f\"📦 チャンクサイズ: {chunk_size}\")\n",
    "        \n",
    "        # 結果辞書の初期化（チャンネルなし）\n",
    "        result = {\"frame\": list(range(t_len))}\n",
    "        result[\"top90_mean\"] = []\n",
    "        \n",
    "        # チャンク処理でメモリ効率化\n",
    "        for t_start in tqdm(range(0, t_len, chunk_size), desc=\"🎯 統計計算処理\"):\n",
    "            t_end = min(t_start + chunk_size, t_len)\n",
    "            \n",
    "            # 複数フレームを一括読み込み (chunk_size, Z, Y, X)\n",
    "            chunk_data = dset[t_start:t_end]\n",
    "            \n",
    "            for i, t in enumerate(range(t_start, t_end)):\n",
    "                vol_chunk = chunk_data[i]  # shape: (Z, Y, X)\n",
    "                \n",
    "                # GPU/CPU処理の選択\n",
    "                if GPU_AVAILABLE:\n",
    "                    stats = process_volume_gpu(vol_chunk, offset_value, exclude_value)\n",
    "                else:\n",
    "                    stats = process_volume_cpu(vol_chunk, offset_value, exclude_value)\n",
    "                \n",
    "                # 結果の蓄積\n",
    "                result[\"top90_mean\"].append(stats['top90_mean'])\n",
    "            \n",
    "            # 進捗情報表示\n",
    "            if t_start % (chunk_size * 10) == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                processed = t_end\n",
    "                fps = processed / elapsed if elapsed > 0 else 0\n",
    "                remaining = t_len - processed\n",
    "                eta_minutes = (remaining / fps / 60) if fps > 0 else 0\n",
    "                \n",
    "                print(f\"  📊 進捗: {processed}/{t_len} ({100*processed/t_len:.1f}%)\")\n",
    "                print(f\"  🚀 速度: {fps:.1f}フレーム/秒, ETA: {eta_minutes:.1f}分\")\n",
    "            \n",
    "            # GPUメモリクリーンアップ\n",
    "            if GPU_AVAILABLE:\n",
    "                try:\n",
    "                    cp.get_default_memory_pool().free_all_blocks()\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    # 処理結果サマリー\n",
    "    total_elapsed = time.time() - start_time\n",
    "    average_fps = t_len / total_elapsed if total_elapsed > 0 else 0\n",
    "    \n",
    "    print(f\"\\n🎉 統計計算完了!\")\n",
    "    print(f\"📊 処理フレーム数: {t_len}\")\n",
    "    print(f\"🔄 チャンネル数: 1 (単一チャンネル)\")\n",
    "    print(f\"⏱️ 総処理時間: {total_elapsed:.1f}秒 ({total_elapsed/60:.1f}分)\")\n",
    "    print(f\"🚀 平均処理速度: {average_fps:.1f}フレーム/秒\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# === 最適化処理実行 ===\n",
    "print(\"🎯 最適化された統計計算を開始...\")\n",
    "print(f\"📁 処理対象: {os.path.basename(h5_path)}\")\n",
    "result = process_statistics_optimized()\n",
    "\n",
    "# === 保存処理 ===\n",
    "print(\"💾 CSV保存中...\")\n",
    "df = pd.DataFrame(result)\n",
    "\n",
    "try:\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"✅ 最適化統計処理完了: {output_csv}\")\n",
    "    print(f\"📈 出力データ形状: {df.shape}\")\n",
    "    \n",
    "    # データサンプル表示\n",
    "    print(\"\\n📊 データサンプル:\")\n",
    "    print(df.head())\n",
    "    \n",
    "except PermissionError:\n",
    "    print(\"❌ 書き込みに失敗しました。ファイルが開かれているか、書き込み権限がありません:\")\n",
    "    print(\"🔒 ファイルを閉じているか、別の保存先を指定してください。\")\n",
    "    print(\"📄 試行した出力先:\", output_csv)\n",
    "    \n",
    "    # 代替保存先の提案\n",
    "    alternative_path = output_csv.replace(\".csv\", f\"_backup_{int(time.time())}.csv\")\n",
    "    try:\n",
    "        df.to_csv(alternative_path, index=False)\n",
    "        print(f\"✅ 代替パスに保存完了: {alternative_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 代替保存も失敗: {e}\")\n",
    "\n",
    "# === メモリクリーンアップ ===\n",
    "try:\n",
    "    del result, df\n",
    "    if GPU_AVAILABLE:\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "    print(\"🧹 メモリクリーンアップ完了\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cfdb77",
   "metadata": {},
   "source": [
    "For spinning disk confocal microscope data. Bleach correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b86a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import time\n",
    "import cupy as cp\n",
    "from scipy.signal import savgol_filter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === パラメータ ===\n",
    "calc_method = \"_top90_mean\"  # 使用する列のメソッド\n",
    "csv_path = r\"I:\\20240911_cam2_007_raw\\20240911_cam2_007_raw_top90_mean.csv\"\n",
    "h5_input_path = r\"I:\\20240911_cam2_007_raw\\20240911_cam2_007_raw_affine.h5\"\n",
    "h5_output_path = fr\"I:\\20240911_cam2_007_raw\\20240911_cam2_007_raw_bleachcorrect{calc_method}_affine.h5\"\n",
    "offset_value = 1600\n",
    "scale_margin = 1.2\n",
    "chunk_size = 60  # メモリーサイズに応じて設定\n",
    "\n",
    "# === 褪色関数定義 ===\n",
    "def double_exp(t, a, b, c, d):\n",
    "    return a * np.exp(-b * t) + c * np.exp(-d * t)\n",
    "\n",
    "# === 単一チャンネル褪色カーブ推定 ===\n",
    "def estimate_bleach_curves():\n",
    "    \"\"\"単一チャンネルの褪色カーブを推定\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    t = np.arange(len(df))\n",
    "    \n",
    "    bleach_params = {}\n",
    "    scale_factors = {}\n",
    "    \n",
    "    # 単一チャンネル列の検出\n",
    "    column_name = \"top90_mean\"  # (T, Z, Y, X)形状では単一チャンネル\n",
    "    \n",
    "    if column_name not in df.columns:\n",
    "        print(f\"❌ 列 '{column_name}' が見つかりません。\")\n",
    "        return None\n",
    "        \n",
    "    print(f\"\\n--- 単一チャンネル褪色カーブ推定 ---\")\n",
    "    \n",
    "    y_raw = df[column_name].to_numpy()\n",
    "    # SGフィルタ適用（ウィンドウサイズ13, 多項式次数1）\n",
    "    y_smooth = savgol_filter(y_raw, window_length=13, polyorder=1, mode='interp')\n",
    "    \n",
    "    # 初期値と上限の推定\n",
    "    a0 = c0 = y_smooth[0] / 2\n",
    "    p0 = [a0, 0.01, c0, 0.001]\n",
    "    y_max = np.nanmax(y_smooth)\n",
    "    upper_limit = y_max * scale_margin\n",
    "    bounds = ([0, 0, 0, 0], [upper_limit, 1, upper_limit, 1])\n",
    "    \n",
    "    try:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            popt, _ = curve_fit(double_exp, t, y_smooth, p0=p0, bounds=bounds, maxfev=10000)\n",
    "        \n",
    "        fitted = double_exp(t, *popt)\n",
    "        scale = double_exp(0, *popt) / fitted  # t=0で正規化\n",
    "        \n",
    "        bleach_params[0] = popt  # チャンネル0として保存\n",
    "        scale_factors[0] = scale\n",
    "        \n",
    "        # プロット作成・保存（単一チャンネル）\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "        \n",
    "        fit = double_exp(t, *popt)\n",
    "        corrected = y_raw * scale\n",
    "        \n",
    "        ax.plot(t, y_raw, 'o', label='Raw Data', markersize=2, alpha=0.7)\n",
    "        ax.plot(t, fit, '-', label='Fitted Curve', linewidth=2, color='red')\n",
    "        ax.plot(t, corrected, '--', label='Corrected Data', linewidth=2, color='green')\n",
    "        ax.set_title('Single Channel Bleach Curve')\n",
    "        ax.set_xlabel('Time (frames)')\n",
    "        ax.set_ylabel('Intensity')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'bleach_curve_single_channel{calc_method}.png', dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"✅ 褪色補正フィッティング完了: a={popt[0]:.2f}, b={popt[1]:.4f}, c={popt[2]:.2f}, d={popt[3]:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ フィッティング失敗: {e}\")\n",
    "        # フォールバック: スケールファクター=1（補正なし）\n",
    "        scale_factors[0] = np.ones_like(t)\n",
    "    \n",
    "    return scale_factors\n",
    "\n",
    "# 褪色カーブ推定実行\n",
    "scale_factors_all = estimate_bleach_curves()\n",
    "if scale_factors_all:\n",
    "    print(\"\\n✅ 褪色カーブ推定完了\")\n",
    "else:\n",
    "    print(\"\\n❌ 褪色カーブ推定に失敗しました\")\n",
    "\n",
    "# GPU版（単一チャンネル対応）\n",
    "try:\n",
    "    GPU_AVAILABLE = True\n",
    "    print(\"🚀 GPU処理が利用可能です\")\n",
    "    \n",
    "    # GPU情報表示\n",
    "    gpu_props = cp.cuda.runtime.getDeviceProperties(0)\n",
    "    gpu_name = gpu_props['name'].decode('utf-8')\n",
    "    total_memory_gb = cp.cuda.Device().mem_info[1] / (1024**3)\n",
    "    print(f\"🎮 GPU: {gpu_name}\")\n",
    "    print(f\"💾 VRAM: {total_memory_gb:.1f}GB\")\n",
    "    \n",
    "except ImportError:\n",
    "    GPU_AVAILABLE = False\n",
    "    print(\"⚠️ CuPyが利用できません。CPU処理を使用します\")\n",
    "\n",
    "def process_with_gpu_single_channel():\n",
    "    \"\"\"単一チャンネル褪色補正GPU処理（(T, Z, Y, X)形状対応）\"\"\"\n",
    "    if not GPU_AVAILABLE:\n",
    "        print(\"❌ GPU処理をスキップします\")\n",
    "        return\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    with h5py.File(h5_input_path, \"r\") as f_in, h5py.File(h5_output_path, \"w\") as f_out:\n",
    "        dset_in = f_in[\"/default\"]\n",
    "        T_full, Z, Y, X = dset_in.shape  # (T, Z, Y, X)\n",
    "        \n",
    "        print(f\"📐 データ形状: (T={T_full}, Z={Z}, Y={Y}, X={X})\")\n",
    "        print(f\"🎯 処理対象: 全ボリューム（{T_full}フレーム）\")\n",
    "        \n",
    "        # 出力データセット作成（全ボリューム）\n",
    "        dset_out = f_out.create_dataset(\n",
    "            \"/default\", \n",
    "            shape=(T_full, Z, Y, X),  # 単一チャンネル\n",
    "            dtype='uint16',\n",
    "            chunks=(min(chunk_size//4, 20), Z, Y, X),\n",
    "            compression=\"gzip\",\n",
    "            compression_opts=1\n",
    "        )\n",
    "        \n",
    "        # メタデータ追加\n",
    "        dset_out.attrs['processing_mode'] = 'single_channel_bleach_correction_full'\n",
    "        dset_out.attrs['chunk_size'] = chunk_size\n",
    "        dset_out.attrs['offset_value'] = offset_value\n",
    "        dset_out.attrs['processed_frames'] = T_full\n",
    "        dset_out.attrs['frame_range'] = f\"0-{T_full-1}\"\n",
    "        \n",
    "        # スケールファクターの準備\n",
    "        if 0 in scale_factors_all:\n",
    "            scale_factors_gpu = cp.asarray(scale_factors_all[0], dtype=cp.float32)\n",
    "            print(f\"✅ GPU用スケールファクター準備完了（{T_full}フレーム）\")\n",
    "        else:\n",
    "            scale_factors_gpu = cp.ones(T_full, dtype=cp.float32)\n",
    "            print(f\"⚠️ スケールファクターなし（補正スキップ）\")\n",
    "        \n",
    "        # チャンク処理メインループ（全フレーム）\n",
    "        for t_start in tqdm(range(0, T_full, chunk_size), desc=\"🎮 GPU単一チャンネル褪色補正（全ボリューム）\"):\n",
    "            t_end = min(t_start + chunk_size, T_full)\n",
    "            current_chunk_size = t_end - t_start\n",
    "            \n",
    "            try:\n",
    "                # メモリ使用量監視\n",
    "                memory_before = cp.cuda.Device().mem_info[0] / (1024**3)\n",
    "                \n",
    "                # CPUからGPUへデータ転送\n",
    "                vol_chunk = cp.asarray(\n",
    "                    dset_in[t_start:t_end, :, :, :],  # (chunk_size, Z, Y, X)\n",
    "                    dtype=cp.float32\n",
    "                )\n",
    "                \n",
    "                # スケールファクター取得\n",
    "                scale_chunk = scale_factors_gpu[t_start:t_end]\n",
    "                \n",
    "                # GPU上でベクトル化処理\n",
    "                vol_chunk -= offset_value  # オフセット減算\n",
    "                vol_chunk *= scale_chunk.reshape(-1, 1, 1, 1)  # 褪色補正\n",
    "                vol_chunk = cp.clip(vol_chunk, 0, 65535)  # クリッピング\n",
    "                \n",
    "                # 型変換と結果保存\n",
    "                vol_chunk = vol_chunk.astype(cp.uint16)\n",
    "                result = cp.asnumpy(vol_chunk)\n",
    "                dset_out[t_start:t_end, :, :, :] = result\n",
    "                \n",
    "                # メモリクリーンアップ\n",
    "                del vol_chunk, result\n",
    "                cp.cuda.Stream.null.synchronize()\n",
    "                \n",
    "                # 進捗情報表示\n",
    "                if t_start % (chunk_size * 5) == 0:\n",
    "                    elapsed = time.time() - start_time\n",
    "                    processed_frames = t_end\n",
    "                    fps = processed_frames / elapsed if elapsed > 0 else 0\n",
    "                    remaining_frames = T_full - processed_frames\n",
    "                    eta_minutes = (remaining_frames / fps / 60) if fps > 0 else 0\n",
    "                    \n",
    "                    print(f\"  📊 進捗: {processed_frames}/{T_full} ({100*processed_frames/T_full:.1f}%)\")\n",
    "                    print(f\"  🚀 速度: {fps:.1f}fps, VRAM: {memory_before:.1f}GB, ETA: {eta_minutes:.1f}分\")\n",
    "                    \n",
    "            except cp.cuda.memory.OutOfMemoryError:\n",
    "                print(f\"💥 GPU メモリ不足 (chunk_size={chunk_size})\")\n",
    "                cp.get_default_memory_pool().free_all_blocks()\n",
    "                continue\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"❌ 処理エラー (t={t_start}-{t_end}): {e}\")\n",
    "                continue\n",
    "    \n",
    "    # 最終メモリクリーンアップ\n",
    "    try:\n",
    "        del scale_factors_gpu\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "        \n",
    "    except Exception as cleanup_error:\n",
    "        print(f\"⚠️ メモリクリーンアップ中にエラー: {cleanup_error}\")\n",
    "        try:\n",
    "            cp.get_default_memory_pool().free_all_blocks()\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # 処理結果サマリー\n",
    "    total_elapsed = time.time() - start_time\n",
    "    average_fps = T_full / total_elapsed if total_elapsed > 0 else 0\n",
    "    \n",
    "    print(f\"\\n🎉 全ボリューム単一チャンネル褪色補正GPU処理完了!\")\n",
    "    print(f\"📊 処理フレーム数: {T_full}\")\n",
    "    print(f\"🔄 チャンネル数: 1 (単一チャンネル)\")\n",
    "    print(f\"⏱️  総処理時間: {total_elapsed/60:.1f}分\")\n",
    "    print(f\"🚀 平均処理速度: {average_fps:.1f}フレーム/秒\")\n",
    "    print(f\"💾 出力ファイル: {h5_output_path}\")\n",
    "\n",
    "# === 実行 ===\n",
    "if GPU_AVAILABLE and scale_factors_all:\n",
    "    print(\"🎯 単一チャンネル褪色補正GPU処理を開始します（全ボリューム）...\")\n",
    "    process_with_gpu_single_channel()\n",
    "else:\n",
    "    print(\"⚠️ GPU処理またはスケールファクターが利用できません\")\n",
    "    print(f\"GPU利用可能: {GPU_AVAILABLE}\")\n",
    "    print(f\"スケールファクター: {list(scale_factors_all.keys()) if scale_factors_all else 'なし'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eecd143",
   "metadata": {},
   "source": [
    "Create MIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42ec2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(f\"現在の時刻は {time.strftime('%Y-%m-%d %H:%M:%S')} です。\")\n",
    "\n",
    "# GPU可用性チェック\n",
    "try:\n",
    "    import cupy as cp\n",
    "    GPU_AVAILABLE = True\n",
    "    print(\"🚀 GPU処理が利用可能です\")\n",
    "    \n",
    "    # GPU情報表示\n",
    "    gpu_props = cp.cuda.runtime.getDeviceProperties(0)\n",
    "    gpu_name = gpu_props['name'].decode('utf-8')\n",
    "    total_memory_gb = cp.cuda.Device().mem_info[1] / (1024**3)\n",
    "    print(f\"🎮 GPU: {gpu_name}\")\n",
    "    print(f\"💾 VRAM: {total_memory_gb:.1f}GB\")\n",
    "    \n",
    "except ImportError:\n",
    "    GPU_AVAILABLE = False\n",
    "    print(\"⚠️ CPU処理を使用します\")\n",
    "\n",
    "# === パラメータ ===\n",
    "calc_method = \"_top90_mean\"  # 使用する列のメソッド\n",
    "hdf5_file = fr\"I:\\20240911_cam2_007_raw\\20240911_cam2_007_raw_bleachcorrect{calc_method}_affine.h5\"\n",
    "output_path = r\"I:\\20240911_cam2_007_raw\\orthogonal_views\"\n",
    "dirname = os.path.splitext(os.path.basename(hdf5_file))[0]\n",
    "chunk_size = 100 if GPU_AVAILABLE else 50  # GPU使用時はより大きなチャンク\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "# === HDF5ファイル情報取得 ===\n",
    "with h5py.File(hdf5_file, 'r') as file:\n",
    "    array = file['default']\n",
    "    total_volumes, z, y, x = array.shape  # (T, Z, Y, X) - 単一チャンネル\n",
    "    print(f\"📐 データ形状: (T={total_volumes}, Z={z}, Y={y}, X={x})\")\n",
    "    print(f\"🎯 処理対象: 全ボリューム（{total_volumes}フレーム）\")\n",
    "\n",
    "# === 出力配列の準備（全ボリューム・単一チャンネル） ===\n",
    "orthogonal_view = np.zeros((total_volumes, y + z + 3, x + z + 3), dtype='uint16')  # チャンネル次元削除\n",
    "\n",
    "def process_cpu_chunk(chunk_data, t_start, t_end):\n",
    "    \"\"\"CPU処理用のヘルパー関数（単一チャンネル対応）\"\"\"\n",
    "    for i, t in enumerate(range(t_start, t_end)):\n",
    "        data = chunk_data[i]  # (Z, Y, X) - チャンネルループ削除\n",
    "        \n",
    "        # CPU上で最大投影\n",
    "        xy_proj = np.max(data, axis=0)  # (Y, X)\n",
    "        yz_proj = np.max(data, axis=2).T  # (Z, Y)\n",
    "        xz_proj = np.max(data, axis=1)  # (Z, X)\n",
    "        \n",
    "        # 直交ビューへの配置（チャンネル次元なし）\n",
    "        orthogonal_view[t, 0:y, 0:x] = xy_proj\n",
    "        orthogonal_view[t, 0:y, x+3:x+z+3] = yz_proj\n",
    "        orthogonal_view[t, y+3:y+z+3, 0:x] = xz_proj\n",
    "        orthogonal_view[t, y+z+2, x+z+2] = 1000\n",
    "\n",
    "def process_orthogonal_projections():\n",
    "    \"\"\"直交投影処理（CPU/GPU自動選択・全ボリューム・単一チャンネル）\"\"\"\n",
    "    use_gpu = GPU_AVAILABLE  # ローカル変数として処理状態を管理\n",
    "    \n",
    "    with h5py.File(hdf5_file, 'r') as file:\n",
    "        array = file['default']\n",
    "        \n",
    "        for t_start in tqdm(range(0, total_volumes, chunk_size), \n",
    "                           desc=\"🎮 GPU直交投影（全ボリューム・単一チャンネル）\" if use_gpu else \"🖥️ CPU直交投影（全ボリューム・単一チャンネル）\"):\n",
    "            t_end = min(t_start + chunk_size, total_volumes)\n",
    "            \n",
    "            # チャンクデータ読み込み\n",
    "            chunk_data = array[t_start:t_end]  # (chunk_size, Z, Y, X)\n",
    "            \n",
    "            if use_gpu:\n",
    "                # GPU処理を試行\n",
    "                try:\n",
    "                    chunk_gpu = cp.asarray(chunk_data)\n",
    "                    \n",
    "                    for i, t in enumerate(range(t_start, t_end)):\n",
    "                        data_gpu = chunk_gpu[i]  # (Z, Y, X) - チャンネルループ削除\n",
    "                        \n",
    "                        # GPU上で最大投影\n",
    "                        xy_proj = cp.max(data_gpu, axis=0)  # (Y, X)\n",
    "                        yz_proj = cp.max(data_gpu, axis=2).T  # (Z, Y)\n",
    "                        xz_proj = cp.max(data_gpu, axis=1)  # (Z, X)\n",
    "                        \n",
    "                        # CPU側に結果をコピー（チャンネル次元なし）\n",
    "                        orthogonal_view[t, 0:y, 0:x] = cp.asnumpy(xy_proj)\n",
    "                        orthogonal_view[t, 0:y, x+3:x+z+3] = cp.asnumpy(yz_proj)\n",
    "                        orthogonal_view[t, y+3:y+z+3, 0:x] = cp.asnumpy(xz_proj)\n",
    "                        orthogonal_view[t, y+z+2, x+z+2] = 1000\n",
    "                    \n",
    "                    # GPUメモリクリーンアップ\n",
    "                    del chunk_gpu\n",
    "                    cp.get_default_memory_pool().free_all_blocks()\n",
    "                    \n",
    "                    # 進捗情報表示（GPU処理）\n",
    "                    if t_start % (chunk_size * 5) == 0:\n",
    "                        processed = t_end\n",
    "                        remaining = total_volumes - processed\n",
    "                        progress_pct = 100 * processed / total_volumes\n",
    "                        print(f\"  📊 GPU進捗: {processed}/{total_volumes} ({progress_pct:.1f}%)\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ GPU処理エラー、CPUにフォールバック: {e}\")\n",
    "                    use_gpu = False  # 今後のチャンクはCPU処理\n",
    "                    # CPU処理で再試行\n",
    "                    process_cpu_chunk(chunk_data, t_start, t_end)\n",
    "                    \n",
    "            else:\n",
    "                # CPU処理\n",
    "                process_cpu_chunk(chunk_data, t_start, t_end)\n",
    "                \n",
    "                # 進捗情報表示（CPU処理）\n",
    "                if t_start % (chunk_size * 2) == 0:\n",
    "                    processed = t_end\n",
    "                    progress_pct = 100 * processed / total_volumes\n",
    "                    print(f\"  📊 CPU進捗: {processed}/{total_volumes} ({progress_pct:.1f}%)\")\n",
    "\n",
    "# === 処理実行 ===\n",
    "print(f\"🎯 全ボリューム（{total_volumes}フレーム）の単一チャンネル直交投影処理を開始...\")\n",
    "process_orthogonal_projections()\n",
    "print(\"🎉 直交投影処理完了!\")\n",
    "\n",
    "# === TIFF保存（全ボリューム・単一チャンネル） ===\n",
    "file_name = f\"orthogonal_view_{dirname}_full_affine.tif\"\n",
    "output_path2 = os.path.join(output_path, file_name)\n",
    "\n",
    "print(\"💾 TIFF保存中...\")\n",
    "print(f\"📁 保存先: {output_path2}\")\n",
    "print(f\"📊 データサイズ: {orthogonal_view.nbytes / (1024**3):.2f}GB\")\n",
    "\n",
    "try:\n",
    "    tiff.imwrite(\n",
    "        output_path2, \n",
    "        orthogonal_view, \n",
    "        imagej=True, \n",
    "        metadata={'axes': 'TYX'},  # チャンネル次元削除\n",
    "        compression='zlib'\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ 全ボリューム処理完了: {output_path2}\")\n",
    "    print(f\"📈 出力形状: {orthogonal_view.shape}\")\n",
    "    print(f\"📊 処理統計: {total_volumes}/{total_volumes}ボリューム (100%)\")\n",
    "    \n",
    "except Exception as save_error:\n",
    "    print(f\"❌ TIFF保存エラー: {save_error}\")\n",
    "    print(\"💡 メモリ不足の可能性があります。チャンク保存を試します...\")\n",
    "    \n",
    "    # === フォールバック: チャンク保存 ===\n",
    "    save_chunk_size = 500  # 500フレームずつ保存\n",
    "    \n",
    "    for save_start in tqdm(range(0, total_volumes, save_chunk_size), desc=\"📦 チャンク保存\"):\n",
    "        save_end = min(save_start + save_chunk_size, total_volumes)\n",
    "        chunk_name = f\"orthogonal_view_{dirname}_part{save_start:05d}-{save_end:05d}.tif\"\n",
    "        chunk_path = os.path.join(output_path, chunk_name)\n",
    "        \n",
    "        chunk_data = orthogonal_view[save_start:save_end]\n",
    "        tiff.imwrite(\n",
    "            chunk_path,\n",
    "            chunk_data,\n",
    "            imagej=True,\n",
    "            metadata={'axes': 'TYX'},  # チャンネル次元削除\n",
    "            compression='zlib'\n",
    "        )\n",
    "        print(f\"✅ 保存完了: {chunk_name}\")\n",
    "    \n",
    "    print(f\"📦 チャンク保存完了: {output_path}\")\n",
    "\n",
    "# === メモリクリーンアップ ===\n",
    "try:\n",
    "    del orthogonal_view\n",
    "    if GPU_AVAILABLE:\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "    print(\"🧹 メモリクリーンアップ完了\")\n",
    "except:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
